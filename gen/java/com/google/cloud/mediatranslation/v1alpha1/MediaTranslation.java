// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/mediatranslation/v1alpha1/media_translation.proto

package com.google.cloud.mediatranslation.v1alpha1;

public final class MediaTranslation {
  private MediaTranslation() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface TranslateSpeechConfigOrBuilder extends
      // @@protoc_insertion_point(interface_extends:google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Required. Encoding of audio data.
     * Supported formats:
     * - `linear16`
     *   Uncompressed 16-bit signed little-endian samples (Linear PCM).
     * - `flac`
     *   `flac` (Free Lossless Audio Codec) is the recommended encoding
     *   because it is lossless--therefore recognition is not compromised--and
     *   requires only about half the bandwidth of `linear16`.
     * - `mulaw`
     *   8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
     * - `amr`
     *   Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
     * - `amr-wb`
     *   Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
     * - `ogg-opus`
     *   Opus encoded audio frames in Ogg container
     *   ([OggOpus](https://wiki.xiph.org/OggOpus)).
     *   `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
     * - `mp3`
     *   MP3 audio. Support all standard MP3 bitrates (which range from 32-320
     *   kbps). When using this encoding, `sample_rate_hertz` has to match the
     *   sample rate of the file being used.
     * </pre>
     *
     * <code>string audio_encoding = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The audioEncoding.
     */
    java.lang.String getAudioEncoding();
    /**
     * <pre>
     * Required. Encoding of audio data.
     * Supported formats:
     * - `linear16`
     *   Uncompressed 16-bit signed little-endian samples (Linear PCM).
     * - `flac`
     *   `flac` (Free Lossless Audio Codec) is the recommended encoding
     *   because it is lossless--therefore recognition is not compromised--and
     *   requires only about half the bandwidth of `linear16`.
     * - `mulaw`
     *   8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
     * - `amr`
     *   Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
     * - `amr-wb`
     *   Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
     * - `ogg-opus`
     *   Opus encoded audio frames in Ogg container
     *   ([OggOpus](https://wiki.xiph.org/OggOpus)).
     *   `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
     * - `mp3`
     *   MP3 audio. Support all standard MP3 bitrates (which range from 32-320
     *   kbps). When using this encoding, `sample_rate_hertz` has to match the
     *   sample rate of the file being used.
     * </pre>
     *
     * <code>string audio_encoding = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The bytes for audioEncoding.
     */
    com.google.protobuf.ByteString
        getAudioEncodingBytes();

    /**
     * <pre>
     * Required. Source language code (BCP-47) of the input audio.
     * </pre>
     *
     * <code>string source_language_code = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The sourceLanguageCode.
     */
    java.lang.String getSourceLanguageCode();
    /**
     * <pre>
     * Required. Source language code (BCP-47) of the input audio.
     * </pre>
     *
     * <code>string source_language_code = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The bytes for sourceLanguageCode.
     */
    com.google.protobuf.ByteString
        getSourceLanguageCodeBytes();

    /**
     * <pre>
     * Required. Target language code (BCP-47) of the output.
     * </pre>
     *
     * <code>string target_language_code = 3 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The targetLanguageCode.
     */
    java.lang.String getTargetLanguageCode();
    /**
     * <pre>
     * Required. Target language code (BCP-47) of the output.
     * </pre>
     *
     * <code>string target_language_code = 3 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The bytes for targetLanguageCode.
     */
    com.google.protobuf.ByteString
        getTargetLanguageCodeBytes();

    /**
     * <pre>
     * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
     * alternative languages of the supplied audio. If alternative source
     * languages are listed, speech translation result will translate in the most
     * likely language detected including the main source_language_code. The
     * translated result will include the language code of the language detected
     * in the audio.
     * Note:
     * 1. If the provided alternative_source_language_code is not supported
     * by current API version, we will skip that language code.
     * 2. If user only provided one eligible alternative_source_language_codes,
     * the translation will happen between source_language_code and
     * alternative_source_language_codes. The target_language_code will be
     * ignored. It will be useful in conversation mode.
     * </pre>
     *
     * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return A list containing the alternativeSourceLanguageCodes.
     */
    java.util.List<java.lang.String>
        getAlternativeSourceLanguageCodesList();
    /**
     * <pre>
     * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
     * alternative languages of the supplied audio. If alternative source
     * languages are listed, speech translation result will translate in the most
     * likely language detected including the main source_language_code. The
     * translated result will include the language code of the language detected
     * in the audio.
     * Note:
     * 1. If the provided alternative_source_language_code is not supported
     * by current API version, we will skip that language code.
     * 2. If user only provided one eligible alternative_source_language_codes,
     * the translation will happen between source_language_code and
     * alternative_source_language_codes. The target_language_code will be
     * ignored. It will be useful in conversation mode.
     * </pre>
     *
     * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The count of alternativeSourceLanguageCodes.
     */
    int getAlternativeSourceLanguageCodesCount();
    /**
     * <pre>
     * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
     * alternative languages of the supplied audio. If alternative source
     * languages are listed, speech translation result will translate in the most
     * likely language detected including the main source_language_code. The
     * translated result will include the language code of the language detected
     * in the audio.
     * Note:
     * 1. If the provided alternative_source_language_code is not supported
     * by current API version, we will skip that language code.
     * 2. If user only provided one eligible alternative_source_language_codes,
     * the translation will happen between source_language_code and
     * alternative_source_language_codes. The target_language_code will be
     * ignored. It will be useful in conversation mode.
     * </pre>
     *
     * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @param index The index of the element to return.
     * @return The alternativeSourceLanguageCodes at the given index.
     */
    java.lang.String getAlternativeSourceLanguageCodes(int index);
    /**
     * <pre>
     * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
     * alternative languages of the supplied audio. If alternative source
     * languages are listed, speech translation result will translate in the most
     * likely language detected including the main source_language_code. The
     * translated result will include the language code of the language detected
     * in the audio.
     * Note:
     * 1. If the provided alternative_source_language_code is not supported
     * by current API version, we will skip that language code.
     * 2. If user only provided one eligible alternative_source_language_codes,
     * the translation will happen between source_language_code and
     * alternative_source_language_codes. The target_language_code will be
     * ignored. It will be useful in conversation mode.
     * </pre>
     *
     * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @param index The index of the value to return.
     * @return The bytes of the alternativeSourceLanguageCodes at the given index.
     */
    com.google.protobuf.ByteString
        getAlternativeSourceLanguageCodesBytes(int index);

    /**
     * <pre>
     * Optional. Sample rate in Hertz of the audio data. Valid values are:
     * 8000-48000. 16000 is optimal. For best results, set the sampling rate of
     * the audio source to 16000 Hz. If that's not possible, use the native sample
     * rate of the audio source (instead of re-sampling).
     * </pre>
     *
     * <code>int32 sample_rate_hertz = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The sampleRateHertz.
     */
    int getSampleRateHertz();

    /**
     * <pre>
     * Optional.
     * </pre>
     *
     * <code>string model = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The model.
     */
    java.lang.String getModel();
    /**
     * <pre>
     * Optional.
     * </pre>
     *
     * <code>string model = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The bytes for model.
     */
    com.google.protobuf.ByteString
        getModelBytes();
  }
  /**
   * <pre>
   * Provides information to the speech translation that specifies how to process
   * the request.
   * </pre>
   *
   * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig}
   */
  public static final class TranslateSpeechConfig extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig)
      TranslateSpeechConfigOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TranslateSpeechConfig.newBuilder() to construct.
    private TranslateSpeechConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TranslateSpeechConfig() {
      audioEncoding_ = "";
      sourceLanguageCode_ = "";
      targetLanguageCode_ = "";
      alternativeSourceLanguageCodes_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      model_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new TranslateSpeechConfig();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_TranslateSpeechConfig_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_TranslateSpeechConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.Builder.class);
    }

    public static final int AUDIO_ENCODING_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile java.lang.Object audioEncoding_ = "";
    /**
     * <pre>
     * Required. Encoding of audio data.
     * Supported formats:
     * - `linear16`
     *   Uncompressed 16-bit signed little-endian samples (Linear PCM).
     * - `flac`
     *   `flac` (Free Lossless Audio Codec) is the recommended encoding
     *   because it is lossless--therefore recognition is not compromised--and
     *   requires only about half the bandwidth of `linear16`.
     * - `mulaw`
     *   8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
     * - `amr`
     *   Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
     * - `amr-wb`
     *   Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
     * - `ogg-opus`
     *   Opus encoded audio frames in Ogg container
     *   ([OggOpus](https://wiki.xiph.org/OggOpus)).
     *   `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
     * - `mp3`
     *   MP3 audio. Support all standard MP3 bitrates (which range from 32-320
     *   kbps). When using this encoding, `sample_rate_hertz` has to match the
     *   sample rate of the file being used.
     * </pre>
     *
     * <code>string audio_encoding = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The audioEncoding.
     */
    @java.lang.Override
    public java.lang.String getAudioEncoding() {
      java.lang.Object ref = audioEncoding_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        audioEncoding_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Required. Encoding of audio data.
     * Supported formats:
     * - `linear16`
     *   Uncompressed 16-bit signed little-endian samples (Linear PCM).
     * - `flac`
     *   `flac` (Free Lossless Audio Codec) is the recommended encoding
     *   because it is lossless--therefore recognition is not compromised--and
     *   requires only about half the bandwidth of `linear16`.
     * - `mulaw`
     *   8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
     * - `amr`
     *   Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
     * - `amr-wb`
     *   Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
     * - `ogg-opus`
     *   Opus encoded audio frames in Ogg container
     *   ([OggOpus](https://wiki.xiph.org/OggOpus)).
     *   `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
     * - `mp3`
     *   MP3 audio. Support all standard MP3 bitrates (which range from 32-320
     *   kbps). When using this encoding, `sample_rate_hertz` has to match the
     *   sample rate of the file being used.
     * </pre>
     *
     * <code>string audio_encoding = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The bytes for audioEncoding.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getAudioEncodingBytes() {
      java.lang.Object ref = audioEncoding_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        audioEncoding_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int SOURCE_LANGUAGE_CODE_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private volatile java.lang.Object sourceLanguageCode_ = "";
    /**
     * <pre>
     * Required. Source language code (BCP-47) of the input audio.
     * </pre>
     *
     * <code>string source_language_code = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The sourceLanguageCode.
     */
    @java.lang.Override
    public java.lang.String getSourceLanguageCode() {
      java.lang.Object ref = sourceLanguageCode_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        sourceLanguageCode_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Required. Source language code (BCP-47) of the input audio.
     * </pre>
     *
     * <code>string source_language_code = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The bytes for sourceLanguageCode.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getSourceLanguageCodeBytes() {
      java.lang.Object ref = sourceLanguageCode_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        sourceLanguageCode_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int TARGET_LANGUAGE_CODE_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private volatile java.lang.Object targetLanguageCode_ = "";
    /**
     * <pre>
     * Required. Target language code (BCP-47) of the output.
     * </pre>
     *
     * <code>string target_language_code = 3 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The targetLanguageCode.
     */
    @java.lang.Override
    public java.lang.String getTargetLanguageCode() {
      java.lang.Object ref = targetLanguageCode_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        targetLanguageCode_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Required. Target language code (BCP-47) of the output.
     * </pre>
     *
     * <code>string target_language_code = 3 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The bytes for targetLanguageCode.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getTargetLanguageCodeBytes() {
      java.lang.Object ref = targetLanguageCode_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        targetLanguageCode_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int ALTERNATIVE_SOURCE_LANGUAGE_CODES_FIELD_NUMBER = 6;
    @SuppressWarnings("serial")
    private com.google.protobuf.LazyStringList alternativeSourceLanguageCodes_;
    /**
     * <pre>
     * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
     * alternative languages of the supplied audio. If alternative source
     * languages are listed, speech translation result will translate in the most
     * likely language detected including the main source_language_code. The
     * translated result will include the language code of the language detected
     * in the audio.
     * Note:
     * 1. If the provided alternative_source_language_code is not supported
     * by current API version, we will skip that language code.
     * 2. If user only provided one eligible alternative_source_language_codes,
     * the translation will happen between source_language_code and
     * alternative_source_language_codes. The target_language_code will be
     * ignored. It will be useful in conversation mode.
     * </pre>
     *
     * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return A list containing the alternativeSourceLanguageCodes.
     */
    public com.google.protobuf.ProtocolStringList
        getAlternativeSourceLanguageCodesList() {
      return alternativeSourceLanguageCodes_;
    }
    /**
     * <pre>
     * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
     * alternative languages of the supplied audio. If alternative source
     * languages are listed, speech translation result will translate in the most
     * likely language detected including the main source_language_code. The
     * translated result will include the language code of the language detected
     * in the audio.
     * Note:
     * 1. If the provided alternative_source_language_code is not supported
     * by current API version, we will skip that language code.
     * 2. If user only provided one eligible alternative_source_language_codes,
     * the translation will happen between source_language_code and
     * alternative_source_language_codes. The target_language_code will be
     * ignored. It will be useful in conversation mode.
     * </pre>
     *
     * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The count of alternativeSourceLanguageCodes.
     */
    public int getAlternativeSourceLanguageCodesCount() {
      return alternativeSourceLanguageCodes_.size();
    }
    /**
     * <pre>
     * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
     * alternative languages of the supplied audio. If alternative source
     * languages are listed, speech translation result will translate in the most
     * likely language detected including the main source_language_code. The
     * translated result will include the language code of the language detected
     * in the audio.
     * Note:
     * 1. If the provided alternative_source_language_code is not supported
     * by current API version, we will skip that language code.
     * 2. If user only provided one eligible alternative_source_language_codes,
     * the translation will happen between source_language_code and
     * alternative_source_language_codes. The target_language_code will be
     * ignored. It will be useful in conversation mode.
     * </pre>
     *
     * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @param index The index of the element to return.
     * @return The alternativeSourceLanguageCodes at the given index.
     */
    public java.lang.String getAlternativeSourceLanguageCodes(int index) {
      return alternativeSourceLanguageCodes_.get(index);
    }
    /**
     * <pre>
     * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
     * alternative languages of the supplied audio. If alternative source
     * languages are listed, speech translation result will translate in the most
     * likely language detected including the main source_language_code. The
     * translated result will include the language code of the language detected
     * in the audio.
     * Note:
     * 1. If the provided alternative_source_language_code is not supported
     * by current API version, we will skip that language code.
     * 2. If user only provided one eligible alternative_source_language_codes,
     * the translation will happen between source_language_code and
     * alternative_source_language_codes. The target_language_code will be
     * ignored. It will be useful in conversation mode.
     * </pre>
     *
     * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @param index The index of the value to return.
     * @return The bytes of the alternativeSourceLanguageCodes at the given index.
     */
    public com.google.protobuf.ByteString
        getAlternativeSourceLanguageCodesBytes(int index) {
      return alternativeSourceLanguageCodes_.getByteString(index);
    }

    public static final int SAMPLE_RATE_HERTZ_FIELD_NUMBER = 4;
    private int sampleRateHertz_ = 0;
    /**
     * <pre>
     * Optional. Sample rate in Hertz of the audio data. Valid values are:
     * 8000-48000. 16000 is optimal. For best results, set the sampling rate of
     * the audio source to 16000 Hz. If that's not possible, use the native sample
     * rate of the audio source (instead of re-sampling).
     * </pre>
     *
     * <code>int32 sample_rate_hertz = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The sampleRateHertz.
     */
    @java.lang.Override
    public int getSampleRateHertz() {
      return sampleRateHertz_;
    }

    public static final int MODEL_FIELD_NUMBER = 5;
    @SuppressWarnings("serial")
    private volatile java.lang.Object model_ = "";
    /**
     * <pre>
     * Optional.
     * </pre>
     *
     * <code>string model = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The model.
     */
    @java.lang.Override
    public java.lang.String getModel() {
      java.lang.Object ref = model_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        model_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Optional.
     * </pre>
     *
     * <code>string model = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The bytes for model.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getModelBytes() {
      java.lang.Object ref = model_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        model_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(audioEncoding_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, audioEncoding_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(sourceLanguageCode_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, sourceLanguageCode_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(targetLanguageCode_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, targetLanguageCode_);
      }
      if (sampleRateHertz_ != 0) {
        output.writeInt32(4, sampleRateHertz_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(model_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, model_);
      }
      for (int i = 0; i < alternativeSourceLanguageCodes_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 6, alternativeSourceLanguageCodes_.getRaw(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(audioEncoding_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, audioEncoding_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(sourceLanguageCode_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, sourceLanguageCode_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(targetLanguageCode_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, targetLanguageCode_);
      }
      if (sampleRateHertz_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, sampleRateHertz_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(model_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, model_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < alternativeSourceLanguageCodes_.size(); i++) {
          dataSize += computeStringSizeNoTag(alternativeSourceLanguageCodes_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getAlternativeSourceLanguageCodesList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig)) {
        return super.equals(obj);
      }
      com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig other = (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig) obj;

      if (!getAudioEncoding()
          .equals(other.getAudioEncoding())) return false;
      if (!getSourceLanguageCode()
          .equals(other.getSourceLanguageCode())) return false;
      if (!getTargetLanguageCode()
          .equals(other.getTargetLanguageCode())) return false;
      if (!getAlternativeSourceLanguageCodesList()
          .equals(other.getAlternativeSourceLanguageCodesList())) return false;
      if (getSampleRateHertz()
          != other.getSampleRateHertz()) return false;
      if (!getModel()
          .equals(other.getModel())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + AUDIO_ENCODING_FIELD_NUMBER;
      hash = (53 * hash) + getAudioEncoding().hashCode();
      hash = (37 * hash) + SOURCE_LANGUAGE_CODE_FIELD_NUMBER;
      hash = (53 * hash) + getSourceLanguageCode().hashCode();
      hash = (37 * hash) + TARGET_LANGUAGE_CODE_FIELD_NUMBER;
      hash = (53 * hash) + getTargetLanguageCode().hashCode();
      if (getAlternativeSourceLanguageCodesCount() > 0) {
        hash = (37 * hash) + ALTERNATIVE_SOURCE_LANGUAGE_CODES_FIELD_NUMBER;
        hash = (53 * hash) + getAlternativeSourceLanguageCodesList().hashCode();
      }
      hash = (37 * hash) + SAMPLE_RATE_HERTZ_FIELD_NUMBER;
      hash = (53 * hash) + getSampleRateHertz();
      hash = (37 * hash) + MODEL_FIELD_NUMBER;
      hash = (53 * hash) + getModel().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Provides information to the speech translation that specifies how to process
     * the request.
     * </pre>
     *
     * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig)
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfigOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_TranslateSpeechConfig_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_TranslateSpeechConfig_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.Builder.class);
      }

      // Construct using com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        audioEncoding_ = "";
        sourceLanguageCode_ = "";
        targetLanguageCode_ = "";
        alternativeSourceLanguageCodes_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        sampleRateHertz_ = 0;
        model_ = "";
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_TranslateSpeechConfig_descriptor;
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig getDefaultInstanceForType() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.getDefaultInstance();
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig build() {
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig buildPartial() {
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig result = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig result) {
        if (((bitField0_ & 0x00000008) != 0)) {
          alternativeSourceLanguageCodes_ = alternativeSourceLanguageCodes_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000008);
        }
        result.alternativeSourceLanguageCodes_ = alternativeSourceLanguageCodes_;
      }

      private void buildPartial0(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.audioEncoding_ = audioEncoding_;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.sourceLanguageCode_ = sourceLanguageCode_;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.targetLanguageCode_ = targetLanguageCode_;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.sampleRateHertz_ = sampleRateHertz_;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.model_ = model_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig) {
          return mergeFrom((com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig other) {
        if (other == com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.getDefaultInstance()) return this;
        if (!other.getAudioEncoding().isEmpty()) {
          audioEncoding_ = other.audioEncoding_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (!other.getSourceLanguageCode().isEmpty()) {
          sourceLanguageCode_ = other.sourceLanguageCode_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        if (!other.getTargetLanguageCode().isEmpty()) {
          targetLanguageCode_ = other.targetLanguageCode_;
          bitField0_ |= 0x00000004;
          onChanged();
        }
        if (!other.alternativeSourceLanguageCodes_.isEmpty()) {
          if (alternativeSourceLanguageCodes_.isEmpty()) {
            alternativeSourceLanguageCodes_ = other.alternativeSourceLanguageCodes_;
            bitField0_ = (bitField0_ & ~0x00000008);
          } else {
            ensureAlternativeSourceLanguageCodesIsMutable();
            alternativeSourceLanguageCodes_.addAll(other.alternativeSourceLanguageCodes_);
          }
          onChanged();
        }
        if (other.getSampleRateHertz() != 0) {
          setSampleRateHertz(other.getSampleRateHertz());
        }
        if (!other.getModel().isEmpty()) {
          model_ = other.model_;
          bitField0_ |= 0x00000020;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                audioEncoding_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                sourceLanguageCode_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                targetLanguageCode_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                sampleRateHertz_ = input.readInt32();
                bitField0_ |= 0x00000010;
                break;
              } // case 32
              case 42: {
                model_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000020;
                break;
              } // case 42
              case 50: {
                java.lang.String s = input.readStringRequireUtf8();
                ensureAlternativeSourceLanguageCodesIsMutable();
                alternativeSourceLanguageCodes_.add(s);
                break;
              } // case 50
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object audioEncoding_ = "";
      /**
       * <pre>
       * Required. Encoding of audio data.
       * Supported formats:
       * - `linear16`
       *   Uncompressed 16-bit signed little-endian samples (Linear PCM).
       * - `flac`
       *   `flac` (Free Lossless Audio Codec) is the recommended encoding
       *   because it is lossless--therefore recognition is not compromised--and
       *   requires only about half the bandwidth of `linear16`.
       * - `mulaw`
       *   8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
       * - `amr`
       *   Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
       * - `amr-wb`
       *   Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
       * - `ogg-opus`
       *   Opus encoded audio frames in Ogg container
       *   ([OggOpus](https://wiki.xiph.org/OggOpus)).
       *   `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
       * - `mp3`
       *   MP3 audio. Support all standard MP3 bitrates (which range from 32-320
       *   kbps). When using this encoding, `sample_rate_hertz` has to match the
       *   sample rate of the file being used.
       * </pre>
       *
       * <code>string audio_encoding = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       * @return The audioEncoding.
       */
      public java.lang.String getAudioEncoding() {
        java.lang.Object ref = audioEncoding_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          audioEncoding_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Required. Encoding of audio data.
       * Supported formats:
       * - `linear16`
       *   Uncompressed 16-bit signed little-endian samples (Linear PCM).
       * - `flac`
       *   `flac` (Free Lossless Audio Codec) is the recommended encoding
       *   because it is lossless--therefore recognition is not compromised--and
       *   requires only about half the bandwidth of `linear16`.
       * - `mulaw`
       *   8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
       * - `amr`
       *   Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
       * - `amr-wb`
       *   Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
       * - `ogg-opus`
       *   Opus encoded audio frames in Ogg container
       *   ([OggOpus](https://wiki.xiph.org/OggOpus)).
       *   `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
       * - `mp3`
       *   MP3 audio. Support all standard MP3 bitrates (which range from 32-320
       *   kbps). When using this encoding, `sample_rate_hertz` has to match the
       *   sample rate of the file being used.
       * </pre>
       *
       * <code>string audio_encoding = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       * @return The bytes for audioEncoding.
       */
      public com.google.protobuf.ByteString
          getAudioEncodingBytes() {
        java.lang.Object ref = audioEncoding_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          audioEncoding_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Required. Encoding of audio data.
       * Supported formats:
       * - `linear16`
       *   Uncompressed 16-bit signed little-endian samples (Linear PCM).
       * - `flac`
       *   `flac` (Free Lossless Audio Codec) is the recommended encoding
       *   because it is lossless--therefore recognition is not compromised--and
       *   requires only about half the bandwidth of `linear16`.
       * - `mulaw`
       *   8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
       * - `amr`
       *   Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
       * - `amr-wb`
       *   Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
       * - `ogg-opus`
       *   Opus encoded audio frames in Ogg container
       *   ([OggOpus](https://wiki.xiph.org/OggOpus)).
       *   `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
       * - `mp3`
       *   MP3 audio. Support all standard MP3 bitrates (which range from 32-320
       *   kbps). When using this encoding, `sample_rate_hertz` has to match the
       *   sample rate of the file being used.
       * </pre>
       *
       * <code>string audio_encoding = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       * @param value The audioEncoding to set.
       * @return This builder for chaining.
       */
      public Builder setAudioEncoding(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        audioEncoding_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. Encoding of audio data.
       * Supported formats:
       * - `linear16`
       *   Uncompressed 16-bit signed little-endian samples (Linear PCM).
       * - `flac`
       *   `flac` (Free Lossless Audio Codec) is the recommended encoding
       *   because it is lossless--therefore recognition is not compromised--and
       *   requires only about half the bandwidth of `linear16`.
       * - `mulaw`
       *   8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
       * - `amr`
       *   Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
       * - `amr-wb`
       *   Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
       * - `ogg-opus`
       *   Opus encoded audio frames in Ogg container
       *   ([OggOpus](https://wiki.xiph.org/OggOpus)).
       *   `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
       * - `mp3`
       *   MP3 audio. Support all standard MP3 bitrates (which range from 32-320
       *   kbps). When using this encoding, `sample_rate_hertz` has to match the
       *   sample rate of the file being used.
       * </pre>
       *
       * <code>string audio_encoding = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       * @return This builder for chaining.
       */
      public Builder clearAudioEncoding() {
        audioEncoding_ = getDefaultInstance().getAudioEncoding();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. Encoding of audio data.
       * Supported formats:
       * - `linear16`
       *   Uncompressed 16-bit signed little-endian samples (Linear PCM).
       * - `flac`
       *   `flac` (Free Lossless Audio Codec) is the recommended encoding
       *   because it is lossless--therefore recognition is not compromised--and
       *   requires only about half the bandwidth of `linear16`.
       * - `mulaw`
       *   8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
       * - `amr`
       *   Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
       * - `amr-wb`
       *   Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
       * - `ogg-opus`
       *   Opus encoded audio frames in Ogg container
       *   ([OggOpus](https://wiki.xiph.org/OggOpus)).
       *   `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
       * - `mp3`
       *   MP3 audio. Support all standard MP3 bitrates (which range from 32-320
       *   kbps). When using this encoding, `sample_rate_hertz` has to match the
       *   sample rate of the file being used.
       * </pre>
       *
       * <code>string audio_encoding = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       * @param value The bytes for audioEncoding to set.
       * @return This builder for chaining.
       */
      public Builder setAudioEncodingBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        audioEncoding_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private java.lang.Object sourceLanguageCode_ = "";
      /**
       * <pre>
       * Required. Source language code (BCP-47) of the input audio.
       * </pre>
       *
       * <code>string source_language_code = 2 [(.google.api.field_behavior) = REQUIRED];</code>
       * @return The sourceLanguageCode.
       */
      public java.lang.String getSourceLanguageCode() {
        java.lang.Object ref = sourceLanguageCode_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          sourceLanguageCode_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Required. Source language code (BCP-47) of the input audio.
       * </pre>
       *
       * <code>string source_language_code = 2 [(.google.api.field_behavior) = REQUIRED];</code>
       * @return The bytes for sourceLanguageCode.
       */
      public com.google.protobuf.ByteString
          getSourceLanguageCodeBytes() {
        java.lang.Object ref = sourceLanguageCode_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          sourceLanguageCode_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Required. Source language code (BCP-47) of the input audio.
       * </pre>
       *
       * <code>string source_language_code = 2 [(.google.api.field_behavior) = REQUIRED];</code>
       * @param value The sourceLanguageCode to set.
       * @return This builder for chaining.
       */
      public Builder setSourceLanguageCode(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        sourceLanguageCode_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. Source language code (BCP-47) of the input audio.
       * </pre>
       *
       * <code>string source_language_code = 2 [(.google.api.field_behavior) = REQUIRED];</code>
       * @return This builder for chaining.
       */
      public Builder clearSourceLanguageCode() {
        sourceLanguageCode_ = getDefaultInstance().getSourceLanguageCode();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. Source language code (BCP-47) of the input audio.
       * </pre>
       *
       * <code>string source_language_code = 2 [(.google.api.field_behavior) = REQUIRED];</code>
       * @param value The bytes for sourceLanguageCode to set.
       * @return This builder for chaining.
       */
      public Builder setSourceLanguageCodeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        sourceLanguageCode_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }

      private java.lang.Object targetLanguageCode_ = "";
      /**
       * <pre>
       * Required. Target language code (BCP-47) of the output.
       * </pre>
       *
       * <code>string target_language_code = 3 [(.google.api.field_behavior) = REQUIRED];</code>
       * @return The targetLanguageCode.
       */
      public java.lang.String getTargetLanguageCode() {
        java.lang.Object ref = targetLanguageCode_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          targetLanguageCode_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Required. Target language code (BCP-47) of the output.
       * </pre>
       *
       * <code>string target_language_code = 3 [(.google.api.field_behavior) = REQUIRED];</code>
       * @return The bytes for targetLanguageCode.
       */
      public com.google.protobuf.ByteString
          getTargetLanguageCodeBytes() {
        java.lang.Object ref = targetLanguageCode_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          targetLanguageCode_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Required. Target language code (BCP-47) of the output.
       * </pre>
       *
       * <code>string target_language_code = 3 [(.google.api.field_behavior) = REQUIRED];</code>
       * @param value The targetLanguageCode to set.
       * @return This builder for chaining.
       */
      public Builder setTargetLanguageCode(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        targetLanguageCode_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. Target language code (BCP-47) of the output.
       * </pre>
       *
       * <code>string target_language_code = 3 [(.google.api.field_behavior) = REQUIRED];</code>
       * @return This builder for chaining.
       */
      public Builder clearTargetLanguageCode() {
        targetLanguageCode_ = getDefaultInstance().getTargetLanguageCode();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. Target language code (BCP-47) of the output.
       * </pre>
       *
       * <code>string target_language_code = 3 [(.google.api.field_behavior) = REQUIRED];</code>
       * @param value The bytes for targetLanguageCode to set.
       * @return This builder for chaining.
       */
      public Builder setTargetLanguageCodeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        targetLanguageCode_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList alternativeSourceLanguageCodes_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureAlternativeSourceLanguageCodesIsMutable() {
        if (!((bitField0_ & 0x00000008) != 0)) {
          alternativeSourceLanguageCodes_ = new com.google.protobuf.LazyStringArrayList(alternativeSourceLanguageCodes_);
          bitField0_ |= 0x00000008;
         }
      }
      /**
       * <pre>
       * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
       * alternative languages of the supplied audio. If alternative source
       * languages are listed, speech translation result will translate in the most
       * likely language detected including the main source_language_code. The
       * translated result will include the language code of the language detected
       * in the audio.
       * Note:
       * 1. If the provided alternative_source_language_code is not supported
       * by current API version, we will skip that language code.
       * 2. If user only provided one eligible alternative_source_language_codes,
       * the translation will happen between source_language_code and
       * alternative_source_language_codes. The target_language_code will be
       * ignored. It will be useful in conversation mode.
       * </pre>
       *
       * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return A list containing the alternativeSourceLanguageCodes.
       */
      public com.google.protobuf.ProtocolStringList
          getAlternativeSourceLanguageCodesList() {
        return alternativeSourceLanguageCodes_.getUnmodifiableView();
      }
      /**
       * <pre>
       * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
       * alternative languages of the supplied audio. If alternative source
       * languages are listed, speech translation result will translate in the most
       * likely language detected including the main source_language_code. The
       * translated result will include the language code of the language detected
       * in the audio.
       * Note:
       * 1. If the provided alternative_source_language_code is not supported
       * by current API version, we will skip that language code.
       * 2. If user only provided one eligible alternative_source_language_codes,
       * the translation will happen between source_language_code and
       * alternative_source_language_codes. The target_language_code will be
       * ignored. It will be useful in conversation mode.
       * </pre>
       *
       * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return The count of alternativeSourceLanguageCodes.
       */
      public int getAlternativeSourceLanguageCodesCount() {
        return alternativeSourceLanguageCodes_.size();
      }
      /**
       * <pre>
       * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
       * alternative languages of the supplied audio. If alternative source
       * languages are listed, speech translation result will translate in the most
       * likely language detected including the main source_language_code. The
       * translated result will include the language code of the language detected
       * in the audio.
       * Note:
       * 1. If the provided alternative_source_language_code is not supported
       * by current API version, we will skip that language code.
       * 2. If user only provided one eligible alternative_source_language_codes,
       * the translation will happen between source_language_code and
       * alternative_source_language_codes. The target_language_code will be
       * ignored. It will be useful in conversation mode.
       * </pre>
       *
       * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param index The index of the element to return.
       * @return The alternativeSourceLanguageCodes at the given index.
       */
      public java.lang.String getAlternativeSourceLanguageCodes(int index) {
        return alternativeSourceLanguageCodes_.get(index);
      }
      /**
       * <pre>
       * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
       * alternative languages of the supplied audio. If alternative source
       * languages are listed, speech translation result will translate in the most
       * likely language detected including the main source_language_code. The
       * translated result will include the language code of the language detected
       * in the audio.
       * Note:
       * 1. If the provided alternative_source_language_code is not supported
       * by current API version, we will skip that language code.
       * 2. If user only provided one eligible alternative_source_language_codes,
       * the translation will happen between source_language_code and
       * alternative_source_language_codes. The target_language_code will be
       * ignored. It will be useful in conversation mode.
       * </pre>
       *
       * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param index The index of the value to return.
       * @return The bytes of the alternativeSourceLanguageCodes at the given index.
       */
      public com.google.protobuf.ByteString
          getAlternativeSourceLanguageCodesBytes(int index) {
        return alternativeSourceLanguageCodes_.getByteString(index);
      }
      /**
       * <pre>
       * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
       * alternative languages of the supplied audio. If alternative source
       * languages are listed, speech translation result will translate in the most
       * likely language detected including the main source_language_code. The
       * translated result will include the language code of the language detected
       * in the audio.
       * Note:
       * 1. If the provided alternative_source_language_code is not supported
       * by current API version, we will skip that language code.
       * 2. If user only provided one eligible alternative_source_language_codes,
       * the translation will happen between source_language_code and
       * alternative_source_language_codes. The target_language_code will be
       * ignored. It will be useful in conversation mode.
       * </pre>
       *
       * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param index The index to set the value at.
       * @param value The alternativeSourceLanguageCodes to set.
       * @return This builder for chaining.
       */
      public Builder setAlternativeSourceLanguageCodes(
          int index, java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureAlternativeSourceLanguageCodesIsMutable();
        alternativeSourceLanguageCodes_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
       * alternative languages of the supplied audio. If alternative source
       * languages are listed, speech translation result will translate in the most
       * likely language detected including the main source_language_code. The
       * translated result will include the language code of the language detected
       * in the audio.
       * Note:
       * 1. If the provided alternative_source_language_code is not supported
       * by current API version, we will skip that language code.
       * 2. If user only provided one eligible alternative_source_language_codes,
       * the translation will happen between source_language_code and
       * alternative_source_language_codes. The target_language_code will be
       * ignored. It will be useful in conversation mode.
       * </pre>
       *
       * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param value The alternativeSourceLanguageCodes to add.
       * @return This builder for chaining.
       */
      public Builder addAlternativeSourceLanguageCodes(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureAlternativeSourceLanguageCodesIsMutable();
        alternativeSourceLanguageCodes_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
       * alternative languages of the supplied audio. If alternative source
       * languages are listed, speech translation result will translate in the most
       * likely language detected including the main source_language_code. The
       * translated result will include the language code of the language detected
       * in the audio.
       * Note:
       * 1. If the provided alternative_source_language_code is not supported
       * by current API version, we will skip that language code.
       * 2. If user only provided one eligible alternative_source_language_codes,
       * the translation will happen between source_language_code and
       * alternative_source_language_codes. The target_language_code will be
       * ignored. It will be useful in conversation mode.
       * </pre>
       *
       * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param values The alternativeSourceLanguageCodes to add.
       * @return This builder for chaining.
       */
      public Builder addAllAlternativeSourceLanguageCodes(
          java.lang.Iterable<java.lang.String> values) {
        ensureAlternativeSourceLanguageCodesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, alternativeSourceLanguageCodes_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
       * alternative languages of the supplied audio. If alternative source
       * languages are listed, speech translation result will translate in the most
       * likely language detected including the main source_language_code. The
       * translated result will include the language code of the language detected
       * in the audio.
       * Note:
       * 1. If the provided alternative_source_language_code is not supported
       * by current API version, we will skip that language code.
       * 2. If user only provided one eligible alternative_source_language_codes,
       * the translation will happen between source_language_code and
       * alternative_source_language_codes. The target_language_code will be
       * ignored. It will be useful in conversation mode.
       * </pre>
       *
       * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return This builder for chaining.
       */
      public Builder clearAlternativeSourceLanguageCodes() {
        alternativeSourceLanguageCodes_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. A list of up to 3 additional language codes (BCP-47), listing possible
       * alternative languages of the supplied audio. If alternative source
       * languages are listed, speech translation result will translate in the most
       * likely language detected including the main source_language_code. The
       * translated result will include the language code of the language detected
       * in the audio.
       * Note:
       * 1. If the provided alternative_source_language_code is not supported
       * by current API version, we will skip that language code.
       * 2. If user only provided one eligible alternative_source_language_codes,
       * the translation will happen between source_language_code and
       * alternative_source_language_codes. The target_language_code will be
       * ignored. It will be useful in conversation mode.
       * </pre>
       *
       * <code>repeated string alternative_source_language_codes = 6 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param value The bytes of the alternativeSourceLanguageCodes to add.
       * @return This builder for chaining.
       */
      public Builder addAlternativeSourceLanguageCodesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        ensureAlternativeSourceLanguageCodesIsMutable();
        alternativeSourceLanguageCodes_.add(value);
        onChanged();
        return this;
      }

      private int sampleRateHertz_ ;
      /**
       * <pre>
       * Optional. Sample rate in Hertz of the audio data. Valid values are:
       * 8000-48000. 16000 is optimal. For best results, set the sampling rate of
       * the audio source to 16000 Hz. If that's not possible, use the native sample
       * rate of the audio source (instead of re-sampling).
       * </pre>
       *
       * <code>int32 sample_rate_hertz = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return The sampleRateHertz.
       */
      @java.lang.Override
      public int getSampleRateHertz() {
        return sampleRateHertz_;
      }
      /**
       * <pre>
       * Optional. Sample rate in Hertz of the audio data. Valid values are:
       * 8000-48000. 16000 is optimal. For best results, set the sampling rate of
       * the audio source to 16000 Hz. If that's not possible, use the native sample
       * rate of the audio source (instead of re-sampling).
       * </pre>
       *
       * <code>int32 sample_rate_hertz = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param value The sampleRateHertz to set.
       * @return This builder for chaining.
       */
      public Builder setSampleRateHertz(int value) {
        
        sampleRateHertz_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. Sample rate in Hertz of the audio data. Valid values are:
       * 8000-48000. 16000 is optimal. For best results, set the sampling rate of
       * the audio source to 16000 Hz. If that's not possible, use the native sample
       * rate of the audio source (instead of re-sampling).
       * </pre>
       *
       * <code>int32 sample_rate_hertz = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return This builder for chaining.
       */
      public Builder clearSampleRateHertz() {
        bitField0_ = (bitField0_ & ~0x00000010);
        sampleRateHertz_ = 0;
        onChanged();
        return this;
      }

      private java.lang.Object model_ = "";
      /**
       * <pre>
       * Optional.
       * </pre>
       *
       * <code>string model = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return The model.
       */
      public java.lang.String getModel() {
        java.lang.Object ref = model_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          model_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Optional.
       * </pre>
       *
       * <code>string model = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return The bytes for model.
       */
      public com.google.protobuf.ByteString
          getModelBytes() {
        java.lang.Object ref = model_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          model_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Optional.
       * </pre>
       *
       * <code>string model = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param value The model to set.
       * @return This builder for chaining.
       */
      public Builder setModel(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        model_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional.
       * </pre>
       *
       * <code>string model = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return This builder for chaining.
       */
      public Builder clearModel() {
        model_ = getDefaultInstance().getModel();
        bitField0_ = (bitField0_ & ~0x00000020);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional.
       * </pre>
       *
       * <code>string model = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param value The bytes for model to set.
       * @return This builder for chaining.
       */
      public Builder setModelBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        model_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig)
    }

    // @@protoc_insertion_point(class_scope:google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig)
    private static final com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig();
    }

    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<TranslateSpeechConfig>
        PARSER = new com.google.protobuf.AbstractParser<TranslateSpeechConfig>() {
      @java.lang.Override
      public TranslateSpeechConfig parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<TranslateSpeechConfig> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<TranslateSpeechConfig> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingTranslateSpeechConfigOrBuilder extends
      // @@protoc_insertion_point(interface_extends:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Required. The common config for all the following audio contents.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return Whether the audioConfig field is set.
     */
    boolean hasAudioConfig();
    /**
     * <pre>
     * Required. The common config for all the following audio contents.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The audioConfig.
     */
    com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig getAudioConfig();
    /**
     * <pre>
     * Required. The common config for all the following audio contents.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfigOrBuilder getAudioConfigOrBuilder();

    /**
     * <pre>
     * Optional. If `false` or omitted, the system performs
     * continuous translation (continuing to wait for and process audio even if
     * the user pauses speaking) until the client closes the input stream (gRPC
     * API) or until the maximum time limit has been reached. May return multiple
     * `StreamingTranslateSpeechResult`s with the `is_final` flag set to `true`.
     * If `true`, the speech translator will detect a single spoken utterance.
     * When it detects that the user has paused or stopped speaking, it will
     * return an `END_OF_SINGLE_UTTERANCE` event and cease translation.
     * When the client receives `END_OF_SINGLE_UTTERANCE` event, the client should
     * stop sending the requests. However, clients should keep receiving remaining
     * responses until the stream is terminated. To construct the complete
     * sentence in a streaming way, one should override (if `is_final` of previous
     * response is false), or append (if 'is_final' of previous response is true).
     * </pre>
     *
     * <code>bool single_utterance = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The singleUtterance.
     */
    boolean getSingleUtterance();

    /**
     * <pre>
     * Optional. Stability control for the media translation text. The value should be
     * "LOW", "MEDIUM", "HIGH". It applies to text/text_and_audio translation
     * only.
     * For audio translation mode, we only support HIGH stability mode,
     * low/medium stability mode will throw argument error.
     * Default empty string will be treated as "HIGH" in audio translation mode;
     * will be treated as "LOW" in other translation mode.
     * Note that stability and speed would be trade off.
     * 1. "LOW": In low mode, translation service will start to do translation
     * right after getting recognition response. The speed will be faster.
     * 2. "MEDIUM": In medium mode, translation service will
     * check if the recognition response is stable enough or not, and only
     * translate recognition response which is not likely to be changed later.
     * 3. "HIGH": In high mode, translation service will wait for more stable
     * recognition responses, and then start to do translation. Also, the
     * following recognition responses cannot modify previous recognition
     * responses. Thus it may impact quality in some situation. "HIGH" stability
     * will generate "final" responses more frequently.
     * </pre>
     *
     * <code>string stability = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The stability.
     */
    java.lang.String getStability();
    /**
     * <pre>
     * Optional. Stability control for the media translation text. The value should be
     * "LOW", "MEDIUM", "HIGH". It applies to text/text_and_audio translation
     * only.
     * For audio translation mode, we only support HIGH stability mode,
     * low/medium stability mode will throw argument error.
     * Default empty string will be treated as "HIGH" in audio translation mode;
     * will be treated as "LOW" in other translation mode.
     * Note that stability and speed would be trade off.
     * 1. "LOW": In low mode, translation service will start to do translation
     * right after getting recognition response. The speed will be faster.
     * 2. "MEDIUM": In medium mode, translation service will
     * check if the recognition response is stable enough or not, and only
     * translate recognition response which is not likely to be changed later.
     * 3. "HIGH": In high mode, translation service will wait for more stable
     * recognition responses, and then start to do translation. Also, the
     * following recognition responses cannot modify previous recognition
     * responses. Thus it may impact quality in some situation. "HIGH" stability
     * will generate "final" responses more frequently.
     * </pre>
     *
     * <code>string stability = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The bytes for stability.
     */
    com.google.protobuf.ByteString
        getStabilityBytes();

    /**
     * <pre>
     * Optional. Translation mode, the value should be "text", "audio", "text_and_audio".
     * Default empty string will be treated as "text".
     * 1. "text": The response will be text translation. Text translation has a
     * field "is_final". Detailed definition can be found in
     * `TextTranslationResult`.
     * 2. "audio": The response will be audio translation. Audio translation does
     * not have "is_final" field, which means each audio translation response is
     * stable and will not be changed by later response.
     * Translation mode "audio" can only be used with "high" stability mode,
     * 3. "text_and_audio": The response will have a text translation, when
     * "is_final" is true, we will also output its corresponding audio
     * translation. When "is_final" is false, audio_translation field will be
     * empty.
     * </pre>
     *
     * <code>string translation_mode = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The translationMode.
     */
    java.lang.String getTranslationMode();
    /**
     * <pre>
     * Optional. Translation mode, the value should be "text", "audio", "text_and_audio".
     * Default empty string will be treated as "text".
     * 1. "text": The response will be text translation. Text translation has a
     * field "is_final". Detailed definition can be found in
     * `TextTranslationResult`.
     * 2. "audio": The response will be audio translation. Audio translation does
     * not have "is_final" field, which means each audio translation response is
     * stable and will not be changed by later response.
     * Translation mode "audio" can only be used with "high" stability mode,
     * 3. "text_and_audio": The response will have a text translation, when
     * "is_final" is true, we will also output its corresponding audio
     * translation. When "is_final" is false, audio_translation field will be
     * empty.
     * </pre>
     *
     * <code>string translation_mode = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The bytes for translationMode.
     */
    com.google.protobuf.ByteString
        getTranslationModeBytes();

    /**
     * <pre>
     * Optional. If disable_interim_results is true, we will only return "final" responses.
     * Otherwise, we will return all the responses. Default value will be false.
     * User can only set disable_interim_results to be true with "high" stability
     * mode.
     * </pre>
     *
     * <code>bool disable_interim_results = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The disableInterimResults.
     */
    boolean getDisableInterimResults();
  }
  /**
   * <pre>
   * Config used for streaming translation.
   * </pre>
   *
   * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig}
   */
  public static final class StreamingTranslateSpeechConfig extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig)
      StreamingTranslateSpeechConfigOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StreamingTranslateSpeechConfig.newBuilder() to construct.
    private StreamingTranslateSpeechConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingTranslateSpeechConfig() {
      stability_ = "";
      translationMode_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new StreamingTranslateSpeechConfig();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechConfig_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.Builder.class);
    }

    public static final int AUDIO_CONFIG_FIELD_NUMBER = 1;
    private com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig audioConfig_;
    /**
     * <pre>
     * Required. The common config for all the following audio contents.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return Whether the audioConfig field is set.
     */
    @java.lang.Override
    public boolean hasAudioConfig() {
      return audioConfig_ != null;
    }
    /**
     * <pre>
     * Required. The common config for all the following audio contents.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The audioConfig.
     */
    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig getAudioConfig() {
      return audioConfig_ == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.getDefaultInstance() : audioConfig_;
    }
    /**
     * <pre>
     * Required. The common config for all the following audio contents.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfigOrBuilder getAudioConfigOrBuilder() {
      return audioConfig_ == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.getDefaultInstance() : audioConfig_;
    }

    public static final int SINGLE_UTTERANCE_FIELD_NUMBER = 2;
    private boolean singleUtterance_ = false;
    /**
     * <pre>
     * Optional. If `false` or omitted, the system performs
     * continuous translation (continuing to wait for and process audio even if
     * the user pauses speaking) until the client closes the input stream (gRPC
     * API) or until the maximum time limit has been reached. May return multiple
     * `StreamingTranslateSpeechResult`s with the `is_final` flag set to `true`.
     * If `true`, the speech translator will detect a single spoken utterance.
     * When it detects that the user has paused or stopped speaking, it will
     * return an `END_OF_SINGLE_UTTERANCE` event and cease translation.
     * When the client receives `END_OF_SINGLE_UTTERANCE` event, the client should
     * stop sending the requests. However, clients should keep receiving remaining
     * responses until the stream is terminated. To construct the complete
     * sentence in a streaming way, one should override (if `is_final` of previous
     * response is false), or append (if 'is_final' of previous response is true).
     * </pre>
     *
     * <code>bool single_utterance = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The singleUtterance.
     */
    @java.lang.Override
    public boolean getSingleUtterance() {
      return singleUtterance_;
    }

    public static final int STABILITY_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private volatile java.lang.Object stability_ = "";
    /**
     * <pre>
     * Optional. Stability control for the media translation text. The value should be
     * "LOW", "MEDIUM", "HIGH". It applies to text/text_and_audio translation
     * only.
     * For audio translation mode, we only support HIGH stability mode,
     * low/medium stability mode will throw argument error.
     * Default empty string will be treated as "HIGH" in audio translation mode;
     * will be treated as "LOW" in other translation mode.
     * Note that stability and speed would be trade off.
     * 1. "LOW": In low mode, translation service will start to do translation
     * right after getting recognition response. The speed will be faster.
     * 2. "MEDIUM": In medium mode, translation service will
     * check if the recognition response is stable enough or not, and only
     * translate recognition response which is not likely to be changed later.
     * 3. "HIGH": In high mode, translation service will wait for more stable
     * recognition responses, and then start to do translation. Also, the
     * following recognition responses cannot modify previous recognition
     * responses. Thus it may impact quality in some situation. "HIGH" stability
     * will generate "final" responses more frequently.
     * </pre>
     *
     * <code>string stability = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The stability.
     */
    @java.lang.Override
    public java.lang.String getStability() {
      java.lang.Object ref = stability_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        stability_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Optional. Stability control for the media translation text. The value should be
     * "LOW", "MEDIUM", "HIGH". It applies to text/text_and_audio translation
     * only.
     * For audio translation mode, we only support HIGH stability mode,
     * low/medium stability mode will throw argument error.
     * Default empty string will be treated as "HIGH" in audio translation mode;
     * will be treated as "LOW" in other translation mode.
     * Note that stability and speed would be trade off.
     * 1. "LOW": In low mode, translation service will start to do translation
     * right after getting recognition response. The speed will be faster.
     * 2. "MEDIUM": In medium mode, translation service will
     * check if the recognition response is stable enough or not, and only
     * translate recognition response which is not likely to be changed later.
     * 3. "HIGH": In high mode, translation service will wait for more stable
     * recognition responses, and then start to do translation. Also, the
     * following recognition responses cannot modify previous recognition
     * responses. Thus it may impact quality in some situation. "HIGH" stability
     * will generate "final" responses more frequently.
     * </pre>
     *
     * <code>string stability = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The bytes for stability.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getStabilityBytes() {
      java.lang.Object ref = stability_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        stability_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int TRANSLATION_MODE_FIELD_NUMBER = 4;
    @SuppressWarnings("serial")
    private volatile java.lang.Object translationMode_ = "";
    /**
     * <pre>
     * Optional. Translation mode, the value should be "text", "audio", "text_and_audio".
     * Default empty string will be treated as "text".
     * 1. "text": The response will be text translation. Text translation has a
     * field "is_final". Detailed definition can be found in
     * `TextTranslationResult`.
     * 2. "audio": The response will be audio translation. Audio translation does
     * not have "is_final" field, which means each audio translation response is
     * stable and will not be changed by later response.
     * Translation mode "audio" can only be used with "high" stability mode,
     * 3. "text_and_audio": The response will have a text translation, when
     * "is_final" is true, we will also output its corresponding audio
     * translation. When "is_final" is false, audio_translation field will be
     * empty.
     * </pre>
     *
     * <code>string translation_mode = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The translationMode.
     */
    @java.lang.Override
    public java.lang.String getTranslationMode() {
      java.lang.Object ref = translationMode_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        translationMode_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Optional. Translation mode, the value should be "text", "audio", "text_and_audio".
     * Default empty string will be treated as "text".
     * 1. "text": The response will be text translation. Text translation has a
     * field "is_final". Detailed definition can be found in
     * `TextTranslationResult`.
     * 2. "audio": The response will be audio translation. Audio translation does
     * not have "is_final" field, which means each audio translation response is
     * stable and will not be changed by later response.
     * Translation mode "audio" can only be used with "high" stability mode,
     * 3. "text_and_audio": The response will have a text translation, when
     * "is_final" is true, we will also output its corresponding audio
     * translation. When "is_final" is false, audio_translation field will be
     * empty.
     * </pre>
     *
     * <code>string translation_mode = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The bytes for translationMode.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getTranslationModeBytes() {
      java.lang.Object ref = translationMode_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        translationMode_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DISABLE_INTERIM_RESULTS_FIELD_NUMBER = 5;
    private boolean disableInterimResults_ = false;
    /**
     * <pre>
     * Optional. If disable_interim_results is true, we will only return "final" responses.
     * Otherwise, we will return all the responses. Default value will be false.
     * User can only set disable_interim_results to be true with "high" stability
     * mode.
     * </pre>
     *
     * <code>bool disable_interim_results = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The disableInterimResults.
     */
    @java.lang.Override
    public boolean getDisableInterimResults() {
      return disableInterimResults_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (audioConfig_ != null) {
        output.writeMessage(1, getAudioConfig());
      }
      if (singleUtterance_ != false) {
        output.writeBool(2, singleUtterance_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(stability_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, stability_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(translationMode_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, translationMode_);
      }
      if (disableInterimResults_ != false) {
        output.writeBool(5, disableInterimResults_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (audioConfig_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getAudioConfig());
      }
      if (singleUtterance_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, singleUtterance_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(stability_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, stability_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(translationMode_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, translationMode_);
      }
      if (disableInterimResults_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, disableInterimResults_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig)) {
        return super.equals(obj);
      }
      com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig other = (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig) obj;

      if (hasAudioConfig() != other.hasAudioConfig()) return false;
      if (hasAudioConfig()) {
        if (!getAudioConfig()
            .equals(other.getAudioConfig())) return false;
      }
      if (getSingleUtterance()
          != other.getSingleUtterance()) return false;
      if (!getStability()
          .equals(other.getStability())) return false;
      if (!getTranslationMode()
          .equals(other.getTranslationMode())) return false;
      if (getDisableInterimResults()
          != other.getDisableInterimResults()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasAudioConfig()) {
        hash = (37 * hash) + AUDIO_CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getAudioConfig().hashCode();
      }
      hash = (37 * hash) + SINGLE_UTTERANCE_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getSingleUtterance());
      hash = (37 * hash) + STABILITY_FIELD_NUMBER;
      hash = (53 * hash) + getStability().hashCode();
      hash = (37 * hash) + TRANSLATION_MODE_FIELD_NUMBER;
      hash = (53 * hash) + getTranslationMode().hashCode();
      hash = (37 * hash) + DISABLE_INTERIM_RESULTS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getDisableInterimResults());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Config used for streaming translation.
     * </pre>
     *
     * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig)
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfigOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechConfig_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechConfig_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.Builder.class);
      }

      // Construct using com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        audioConfig_ = null;
        if (audioConfigBuilder_ != null) {
          audioConfigBuilder_.dispose();
          audioConfigBuilder_ = null;
        }
        singleUtterance_ = false;
        stability_ = "";
        translationMode_ = "";
        disableInterimResults_ = false;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechConfig_descriptor;
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig getDefaultInstanceForType() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.getDefaultInstance();
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig build() {
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig buildPartial() {
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig result = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.audioConfig_ = audioConfigBuilder_ == null
              ? audioConfig_
              : audioConfigBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.singleUtterance_ = singleUtterance_;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.stability_ = stability_;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.translationMode_ = translationMode_;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.disableInterimResults_ = disableInterimResults_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig) {
          return mergeFrom((com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig other) {
        if (other == com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.getDefaultInstance()) return this;
        if (other.hasAudioConfig()) {
          mergeAudioConfig(other.getAudioConfig());
        }
        if (other.getSingleUtterance() != false) {
          setSingleUtterance(other.getSingleUtterance());
        }
        if (!other.getStability().isEmpty()) {
          stability_ = other.stability_;
          bitField0_ |= 0x00000004;
          onChanged();
        }
        if (!other.getTranslationMode().isEmpty()) {
          translationMode_ = other.translationMode_;
          bitField0_ |= 0x00000008;
          onChanged();
        }
        if (other.getDisableInterimResults() != false) {
          setDisableInterimResults(other.getDisableInterimResults());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getAudioConfigFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                singleUtterance_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 26: {
                stability_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                translationMode_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              case 40: {
                disableInterimResults_ = input.readBool();
                bitField0_ |= 0x00000010;
                break;
              } // case 40
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig audioConfig_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfigOrBuilder> audioConfigBuilder_;
      /**
       * <pre>
       * Required. The common config for all the following audio contents.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       * @return Whether the audioConfig field is set.
       */
      public boolean hasAudioConfig() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * Required. The common config for all the following audio contents.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       * @return The audioConfig.
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig getAudioConfig() {
        if (audioConfigBuilder_ == null) {
          return audioConfig_ == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.getDefaultInstance() : audioConfig_;
        } else {
          return audioConfigBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Required. The common config for all the following audio contents.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       */
      public Builder setAudioConfig(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig value) {
        if (audioConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          audioConfig_ = value;
        } else {
          audioConfigBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. The common config for all the following audio contents.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       */
      public Builder setAudioConfig(
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.Builder builderForValue) {
        if (audioConfigBuilder_ == null) {
          audioConfig_ = builderForValue.build();
        } else {
          audioConfigBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. The common config for all the following audio contents.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       */
      public Builder mergeAudioConfig(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig value) {
        if (audioConfigBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            audioConfig_ != null &&
            audioConfig_ != com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.getDefaultInstance()) {
            getAudioConfigBuilder().mergeFrom(value);
          } else {
            audioConfig_ = value;
          }
        } else {
          audioConfigBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. The common config for all the following audio contents.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       */
      public Builder clearAudioConfig() {
        bitField0_ = (bitField0_ & ~0x00000001);
        audioConfig_ = null;
        if (audioConfigBuilder_ != null) {
          audioConfigBuilder_.dispose();
          audioConfigBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. The common config for all the following audio contents.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.Builder getAudioConfigBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getAudioConfigFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Required. The common config for all the following audio contents.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfigOrBuilder getAudioConfigOrBuilder() {
        if (audioConfigBuilder_ != null) {
          return audioConfigBuilder_.getMessageOrBuilder();
        } else {
          return audioConfig_ == null ?
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.getDefaultInstance() : audioConfig_;
        }
      }
      /**
       * <pre>
       * Required. The common config for all the following audio contents.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.TranslateSpeechConfig audio_config = 1 [(.google.api.field_behavior) = REQUIRED];</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfigOrBuilder> 
          getAudioConfigFieldBuilder() {
        if (audioConfigBuilder_ == null) {
          audioConfigBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfig.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.TranslateSpeechConfigOrBuilder>(
                  getAudioConfig(),
                  getParentForChildren(),
                  isClean());
          audioConfig_ = null;
        }
        return audioConfigBuilder_;
      }

      private boolean singleUtterance_ ;
      /**
       * <pre>
       * Optional. If `false` or omitted, the system performs
       * continuous translation (continuing to wait for and process audio even if
       * the user pauses speaking) until the client closes the input stream (gRPC
       * API) or until the maximum time limit has been reached. May return multiple
       * `StreamingTranslateSpeechResult`s with the `is_final` flag set to `true`.
       * If `true`, the speech translator will detect a single spoken utterance.
       * When it detects that the user has paused or stopped speaking, it will
       * return an `END_OF_SINGLE_UTTERANCE` event and cease translation.
       * When the client receives `END_OF_SINGLE_UTTERANCE` event, the client should
       * stop sending the requests. However, clients should keep receiving remaining
       * responses until the stream is terminated. To construct the complete
       * sentence in a streaming way, one should override (if `is_final` of previous
       * response is false), or append (if 'is_final' of previous response is true).
       * </pre>
       *
       * <code>bool single_utterance = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return The singleUtterance.
       */
      @java.lang.Override
      public boolean getSingleUtterance() {
        return singleUtterance_;
      }
      /**
       * <pre>
       * Optional. If `false` or omitted, the system performs
       * continuous translation (continuing to wait for and process audio even if
       * the user pauses speaking) until the client closes the input stream (gRPC
       * API) or until the maximum time limit has been reached. May return multiple
       * `StreamingTranslateSpeechResult`s with the `is_final` flag set to `true`.
       * If `true`, the speech translator will detect a single spoken utterance.
       * When it detects that the user has paused or stopped speaking, it will
       * return an `END_OF_SINGLE_UTTERANCE` event and cease translation.
       * When the client receives `END_OF_SINGLE_UTTERANCE` event, the client should
       * stop sending the requests. However, clients should keep receiving remaining
       * responses until the stream is terminated. To construct the complete
       * sentence in a streaming way, one should override (if `is_final` of previous
       * response is false), or append (if 'is_final' of previous response is true).
       * </pre>
       *
       * <code>bool single_utterance = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param value The singleUtterance to set.
       * @return This builder for chaining.
       */
      public Builder setSingleUtterance(boolean value) {
        
        singleUtterance_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. If `false` or omitted, the system performs
       * continuous translation (continuing to wait for and process audio even if
       * the user pauses speaking) until the client closes the input stream (gRPC
       * API) or until the maximum time limit has been reached. May return multiple
       * `StreamingTranslateSpeechResult`s with the `is_final` flag set to `true`.
       * If `true`, the speech translator will detect a single spoken utterance.
       * When it detects that the user has paused or stopped speaking, it will
       * return an `END_OF_SINGLE_UTTERANCE` event and cease translation.
       * When the client receives `END_OF_SINGLE_UTTERANCE` event, the client should
       * stop sending the requests. However, clients should keep receiving remaining
       * responses until the stream is terminated. To construct the complete
       * sentence in a streaming way, one should override (if `is_final` of previous
       * response is false), or append (if 'is_final' of previous response is true).
       * </pre>
       *
       * <code>bool single_utterance = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return This builder for chaining.
       */
      public Builder clearSingleUtterance() {
        bitField0_ = (bitField0_ & ~0x00000002);
        singleUtterance_ = false;
        onChanged();
        return this;
      }

      private java.lang.Object stability_ = "";
      /**
       * <pre>
       * Optional. Stability control for the media translation text. The value should be
       * "LOW", "MEDIUM", "HIGH". It applies to text/text_and_audio translation
       * only.
       * For audio translation mode, we only support HIGH stability mode,
       * low/medium stability mode will throw argument error.
       * Default empty string will be treated as "HIGH" in audio translation mode;
       * will be treated as "LOW" in other translation mode.
       * Note that stability and speed would be trade off.
       * 1. "LOW": In low mode, translation service will start to do translation
       * right after getting recognition response. The speed will be faster.
       * 2. "MEDIUM": In medium mode, translation service will
       * check if the recognition response is stable enough or not, and only
       * translate recognition response which is not likely to be changed later.
       * 3. "HIGH": In high mode, translation service will wait for more stable
       * recognition responses, and then start to do translation. Also, the
       * following recognition responses cannot modify previous recognition
       * responses. Thus it may impact quality in some situation. "HIGH" stability
       * will generate "final" responses more frequently.
       * </pre>
       *
       * <code>string stability = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return The stability.
       */
      public java.lang.String getStability() {
        java.lang.Object ref = stability_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          stability_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Optional. Stability control for the media translation text. The value should be
       * "LOW", "MEDIUM", "HIGH". It applies to text/text_and_audio translation
       * only.
       * For audio translation mode, we only support HIGH stability mode,
       * low/medium stability mode will throw argument error.
       * Default empty string will be treated as "HIGH" in audio translation mode;
       * will be treated as "LOW" in other translation mode.
       * Note that stability and speed would be trade off.
       * 1. "LOW": In low mode, translation service will start to do translation
       * right after getting recognition response. The speed will be faster.
       * 2. "MEDIUM": In medium mode, translation service will
       * check if the recognition response is stable enough or not, and only
       * translate recognition response which is not likely to be changed later.
       * 3. "HIGH": In high mode, translation service will wait for more stable
       * recognition responses, and then start to do translation. Also, the
       * following recognition responses cannot modify previous recognition
       * responses. Thus it may impact quality in some situation. "HIGH" stability
       * will generate "final" responses more frequently.
       * </pre>
       *
       * <code>string stability = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return The bytes for stability.
       */
      public com.google.protobuf.ByteString
          getStabilityBytes() {
        java.lang.Object ref = stability_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          stability_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Optional. Stability control for the media translation text. The value should be
       * "LOW", "MEDIUM", "HIGH". It applies to text/text_and_audio translation
       * only.
       * For audio translation mode, we only support HIGH stability mode,
       * low/medium stability mode will throw argument error.
       * Default empty string will be treated as "HIGH" in audio translation mode;
       * will be treated as "LOW" in other translation mode.
       * Note that stability and speed would be trade off.
       * 1. "LOW": In low mode, translation service will start to do translation
       * right after getting recognition response. The speed will be faster.
       * 2. "MEDIUM": In medium mode, translation service will
       * check if the recognition response is stable enough or not, and only
       * translate recognition response which is not likely to be changed later.
       * 3. "HIGH": In high mode, translation service will wait for more stable
       * recognition responses, and then start to do translation. Also, the
       * following recognition responses cannot modify previous recognition
       * responses. Thus it may impact quality in some situation. "HIGH" stability
       * will generate "final" responses more frequently.
       * </pre>
       *
       * <code>string stability = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param value The stability to set.
       * @return This builder for chaining.
       */
      public Builder setStability(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        stability_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. Stability control for the media translation text. The value should be
       * "LOW", "MEDIUM", "HIGH". It applies to text/text_and_audio translation
       * only.
       * For audio translation mode, we only support HIGH stability mode,
       * low/medium stability mode will throw argument error.
       * Default empty string will be treated as "HIGH" in audio translation mode;
       * will be treated as "LOW" in other translation mode.
       * Note that stability and speed would be trade off.
       * 1. "LOW": In low mode, translation service will start to do translation
       * right after getting recognition response. The speed will be faster.
       * 2. "MEDIUM": In medium mode, translation service will
       * check if the recognition response is stable enough or not, and only
       * translate recognition response which is not likely to be changed later.
       * 3. "HIGH": In high mode, translation service will wait for more stable
       * recognition responses, and then start to do translation. Also, the
       * following recognition responses cannot modify previous recognition
       * responses. Thus it may impact quality in some situation. "HIGH" stability
       * will generate "final" responses more frequently.
       * </pre>
       *
       * <code>string stability = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return This builder for chaining.
       */
      public Builder clearStability() {
        stability_ = getDefaultInstance().getStability();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. Stability control for the media translation text. The value should be
       * "LOW", "MEDIUM", "HIGH". It applies to text/text_and_audio translation
       * only.
       * For audio translation mode, we only support HIGH stability mode,
       * low/medium stability mode will throw argument error.
       * Default empty string will be treated as "HIGH" in audio translation mode;
       * will be treated as "LOW" in other translation mode.
       * Note that stability and speed would be trade off.
       * 1. "LOW": In low mode, translation service will start to do translation
       * right after getting recognition response. The speed will be faster.
       * 2. "MEDIUM": In medium mode, translation service will
       * check if the recognition response is stable enough or not, and only
       * translate recognition response which is not likely to be changed later.
       * 3. "HIGH": In high mode, translation service will wait for more stable
       * recognition responses, and then start to do translation. Also, the
       * following recognition responses cannot modify previous recognition
       * responses. Thus it may impact quality in some situation. "HIGH" stability
       * will generate "final" responses more frequently.
       * </pre>
       *
       * <code>string stability = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param value The bytes for stability to set.
       * @return This builder for chaining.
       */
      public Builder setStabilityBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        stability_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }

      private java.lang.Object translationMode_ = "";
      /**
       * <pre>
       * Optional. Translation mode, the value should be "text", "audio", "text_and_audio".
       * Default empty string will be treated as "text".
       * 1. "text": The response will be text translation. Text translation has a
       * field "is_final". Detailed definition can be found in
       * `TextTranslationResult`.
       * 2. "audio": The response will be audio translation. Audio translation does
       * not have "is_final" field, which means each audio translation response is
       * stable and will not be changed by later response.
       * Translation mode "audio" can only be used with "high" stability mode,
       * 3. "text_and_audio": The response will have a text translation, when
       * "is_final" is true, we will also output its corresponding audio
       * translation. When "is_final" is false, audio_translation field will be
       * empty.
       * </pre>
       *
       * <code>string translation_mode = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return The translationMode.
       */
      public java.lang.String getTranslationMode() {
        java.lang.Object ref = translationMode_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          translationMode_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Optional. Translation mode, the value should be "text", "audio", "text_and_audio".
       * Default empty string will be treated as "text".
       * 1. "text": The response will be text translation. Text translation has a
       * field "is_final". Detailed definition can be found in
       * `TextTranslationResult`.
       * 2. "audio": The response will be audio translation. Audio translation does
       * not have "is_final" field, which means each audio translation response is
       * stable and will not be changed by later response.
       * Translation mode "audio" can only be used with "high" stability mode,
       * 3. "text_and_audio": The response will have a text translation, when
       * "is_final" is true, we will also output its corresponding audio
       * translation. When "is_final" is false, audio_translation field will be
       * empty.
       * </pre>
       *
       * <code>string translation_mode = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return The bytes for translationMode.
       */
      public com.google.protobuf.ByteString
          getTranslationModeBytes() {
        java.lang.Object ref = translationMode_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          translationMode_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Optional. Translation mode, the value should be "text", "audio", "text_and_audio".
       * Default empty string will be treated as "text".
       * 1. "text": The response will be text translation. Text translation has a
       * field "is_final". Detailed definition can be found in
       * `TextTranslationResult`.
       * 2. "audio": The response will be audio translation. Audio translation does
       * not have "is_final" field, which means each audio translation response is
       * stable and will not be changed by later response.
       * Translation mode "audio" can only be used with "high" stability mode,
       * 3. "text_and_audio": The response will have a text translation, when
       * "is_final" is true, we will also output its corresponding audio
       * translation. When "is_final" is false, audio_translation field will be
       * empty.
       * </pre>
       *
       * <code>string translation_mode = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param value The translationMode to set.
       * @return This builder for chaining.
       */
      public Builder setTranslationMode(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        translationMode_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. Translation mode, the value should be "text", "audio", "text_and_audio".
       * Default empty string will be treated as "text".
       * 1. "text": The response will be text translation. Text translation has a
       * field "is_final". Detailed definition can be found in
       * `TextTranslationResult`.
       * 2. "audio": The response will be audio translation. Audio translation does
       * not have "is_final" field, which means each audio translation response is
       * stable and will not be changed by later response.
       * Translation mode "audio" can only be used with "high" stability mode,
       * 3. "text_and_audio": The response will have a text translation, when
       * "is_final" is true, we will also output its corresponding audio
       * translation. When "is_final" is false, audio_translation field will be
       * empty.
       * </pre>
       *
       * <code>string translation_mode = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return This builder for chaining.
       */
      public Builder clearTranslationMode() {
        translationMode_ = getDefaultInstance().getTranslationMode();
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. Translation mode, the value should be "text", "audio", "text_and_audio".
       * Default empty string will be treated as "text".
       * 1. "text": The response will be text translation. Text translation has a
       * field "is_final". Detailed definition can be found in
       * `TextTranslationResult`.
       * 2. "audio": The response will be audio translation. Audio translation does
       * not have "is_final" field, which means each audio translation response is
       * stable and will not be changed by later response.
       * Translation mode "audio" can only be used with "high" stability mode,
       * 3. "text_and_audio": The response will have a text translation, when
       * "is_final" is true, we will also output its corresponding audio
       * translation. When "is_final" is false, audio_translation field will be
       * empty.
       * </pre>
       *
       * <code>string translation_mode = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param value The bytes for translationMode to set.
       * @return This builder for chaining.
       */
      public Builder setTranslationModeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        translationMode_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }

      private boolean disableInterimResults_ ;
      /**
       * <pre>
       * Optional. If disable_interim_results is true, we will only return "final" responses.
       * Otherwise, we will return all the responses. Default value will be false.
       * User can only set disable_interim_results to be true with "high" stability
       * mode.
       * </pre>
       *
       * <code>bool disable_interim_results = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return The disableInterimResults.
       */
      @java.lang.Override
      public boolean getDisableInterimResults() {
        return disableInterimResults_;
      }
      /**
       * <pre>
       * Optional. If disable_interim_results is true, we will only return "final" responses.
       * Otherwise, we will return all the responses. Default value will be false.
       * User can only set disable_interim_results to be true with "high" stability
       * mode.
       * </pre>
       *
       * <code>bool disable_interim_results = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @param value The disableInterimResults to set.
       * @return This builder for chaining.
       */
      public Builder setDisableInterimResults(boolean value) {
        
        disableInterimResults_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. If disable_interim_results is true, we will only return "final" responses.
       * Otherwise, we will return all the responses. Default value will be false.
       * User can only set disable_interim_results to be true with "high" stability
       * mode.
       * </pre>
       *
       * <code>bool disable_interim_results = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
       * @return This builder for chaining.
       */
      public Builder clearDisableInterimResults() {
        bitField0_ = (bitField0_ & ~0x00000010);
        disableInterimResults_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig)
    }

    // @@protoc_insertion_point(class_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig)
    private static final com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig();
    }

    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingTranslateSpeechConfig>
        PARSER = new com.google.protobuf.AbstractParser<StreamingTranslateSpeechConfig>() {
      @java.lang.Override
      public StreamingTranslateSpeechConfig parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<StreamingTranslateSpeechConfig> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StreamingTranslateSpeechConfig> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingTranslateSpeechRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingTranslateSpeechRequest` message must contain
     * a `streaming_config` message.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
     * @return Whether the streamingConfig field is set.
     */
    boolean hasStreamingConfig();
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingTranslateSpeechRequest` message must contain
     * a `streaming_config` message.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
     * @return The streamingConfig.
     */
    com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig getStreamingConfig();
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingTranslateSpeechRequest` message must contain
     * a `streaming_config` message.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
     */
    com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfigOrBuilder getStreamingConfigOrBuilder();

    /**
     * <pre>
     * The audio data to be translated. Sequential chunks of audio data are sent
     * in sequential `StreamingTranslateSpeechRequest` messages. The first
     * `StreamingTranslateSpeechRequest` message must not contain
     * `audio_content` data and all subsequent `StreamingTranslateSpeechRequest`
     * messages must contain `audio_content` data. The audio bytes must be
     * encoded as specified in `StreamingTranslateSpeechConfig`. Note: as with
     * all bytes fields, protobuffers use a pure binary representation (not
     * base64).
     * </pre>
     *
     * <code>bytes audio_content = 2;</code>
     * @return Whether the audioContent field is set.
     */
    boolean hasAudioContent();
    /**
     * <pre>
     * The audio data to be translated. Sequential chunks of audio data are sent
     * in sequential `StreamingTranslateSpeechRequest` messages. The first
     * `StreamingTranslateSpeechRequest` message must not contain
     * `audio_content` data and all subsequent `StreamingTranslateSpeechRequest`
     * messages must contain `audio_content` data. The audio bytes must be
     * encoded as specified in `StreamingTranslateSpeechConfig`. Note: as with
     * all bytes fields, protobuffers use a pure binary representation (not
     * base64).
     * </pre>
     *
     * <code>bytes audio_content = 2;</code>
     * @return The audioContent.
     */
    com.google.protobuf.ByteString getAudioContent();

    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest.StreamingRequestCase getStreamingRequestCase();
  }
  /**
   * <pre>
   * The top-level message sent by the client for the `StreamingTranslateSpeech`
   * method. Multiple `StreamingTranslateSpeechRequest` messages are sent. The
   * first message must contain a `streaming_config` message and must not contain
   * `audio_content` data. All subsequent messages must contain `audio_content`
   * data and must not contain a `streaming_config` message.
   * </pre>
   *
   * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechRequest}
   */
  public static final class StreamingTranslateSpeechRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechRequest)
      StreamingTranslateSpeechRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StreamingTranslateSpeechRequest.newBuilder() to construct.
    private StreamingTranslateSpeechRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingTranslateSpeechRequest() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new StreamingTranslateSpeechRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest.Builder.class);
    }

    private int streamingRequestCase_ = 0;
    private java.lang.Object streamingRequest_;
    public enum StreamingRequestCase
        implements com.google.protobuf.Internal.EnumLite,
            com.google.protobuf.AbstractMessage.InternalOneOfEnum {
      STREAMING_CONFIG(1),
      AUDIO_CONTENT(2),
      STREAMINGREQUEST_NOT_SET(0);
      private final int value;
      private StreamingRequestCase(int value) {
        this.value = value;
      }
      /**
       * @param value The number of the enum to look for.
       * @return The enum associated with the given number.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static StreamingRequestCase valueOf(int value) {
        return forNumber(value);
      }

      public static StreamingRequestCase forNumber(int value) {
        switch (value) {
          case 1: return STREAMING_CONFIG;
          case 2: return AUDIO_CONTENT;
          case 0: return STREAMINGREQUEST_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public StreamingRequestCase
    getStreamingRequestCase() {
      return StreamingRequestCase.forNumber(
          streamingRequestCase_);
    }

    public static final int STREAMING_CONFIG_FIELD_NUMBER = 1;
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingTranslateSpeechRequest` message must contain
     * a `streaming_config` message.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
     * @return Whether the streamingConfig field is set.
     */
    @java.lang.Override
    public boolean hasStreamingConfig() {
      return streamingRequestCase_ == 1;
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingTranslateSpeechRequest` message must contain
     * a `streaming_config` message.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
     * @return The streamingConfig.
     */
    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig getStreamingConfig() {
      if (streamingRequestCase_ == 1) {
         return (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig) streamingRequest_;
      }
      return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.getDefaultInstance();
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingTranslateSpeechRequest` message must contain
     * a `streaming_config` message.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
     */
    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfigOrBuilder getStreamingConfigOrBuilder() {
      if (streamingRequestCase_ == 1) {
         return (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig) streamingRequest_;
      }
      return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.getDefaultInstance();
    }

    public static final int AUDIO_CONTENT_FIELD_NUMBER = 2;
    /**
     * <pre>
     * The audio data to be translated. Sequential chunks of audio data are sent
     * in sequential `StreamingTranslateSpeechRequest` messages. The first
     * `StreamingTranslateSpeechRequest` message must not contain
     * `audio_content` data and all subsequent `StreamingTranslateSpeechRequest`
     * messages must contain `audio_content` data. The audio bytes must be
     * encoded as specified in `StreamingTranslateSpeechConfig`. Note: as with
     * all bytes fields, protobuffers use a pure binary representation (not
     * base64).
     * </pre>
     *
     * <code>bytes audio_content = 2;</code>
     * @return Whether the audioContent field is set.
     */
    @java.lang.Override
    public boolean hasAudioContent() {
      return streamingRequestCase_ == 2;
    }
    /**
     * <pre>
     * The audio data to be translated. Sequential chunks of audio data are sent
     * in sequential `StreamingTranslateSpeechRequest` messages. The first
     * `StreamingTranslateSpeechRequest` message must not contain
     * `audio_content` data and all subsequent `StreamingTranslateSpeechRequest`
     * messages must contain `audio_content` data. The audio bytes must be
     * encoded as specified in `StreamingTranslateSpeechConfig`. Note: as with
     * all bytes fields, protobuffers use a pure binary representation (not
     * base64).
     * </pre>
     *
     * <code>bytes audio_content = 2;</code>
     * @return The audioContent.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString getAudioContent() {
      if (streamingRequestCase_ == 2) {
        return (com.google.protobuf.ByteString) streamingRequest_;
      }
      return com.google.protobuf.ByteString.EMPTY;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (streamingRequestCase_ == 1) {
        output.writeMessage(1, (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig) streamingRequest_);
      }
      if (streamingRequestCase_ == 2) {
        output.writeBytes(
            2, (com.google.protobuf.ByteString) streamingRequest_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (streamingRequestCase_ == 1) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig) streamingRequest_);
      }
      if (streamingRequestCase_ == 2) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(
              2, (com.google.protobuf.ByteString) streamingRequest_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest)) {
        return super.equals(obj);
      }
      com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest other = (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest) obj;

      if (!getStreamingRequestCase().equals(other.getStreamingRequestCase())) return false;
      switch (streamingRequestCase_) {
        case 1:
          if (!getStreamingConfig()
              .equals(other.getStreamingConfig())) return false;
          break;
        case 2:
          if (!getAudioContent()
              .equals(other.getAudioContent())) return false;
          break;
        case 0:
        default:
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      switch (streamingRequestCase_) {
        case 1:
          hash = (37 * hash) + STREAMING_CONFIG_FIELD_NUMBER;
          hash = (53 * hash) + getStreamingConfig().hashCode();
          break;
        case 2:
          hash = (37 * hash) + AUDIO_CONTENT_FIELD_NUMBER;
          hash = (53 * hash) + getAudioContent().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * The top-level message sent by the client for the `StreamingTranslateSpeech`
     * method. Multiple `StreamingTranslateSpeechRequest` messages are sent. The
     * first message must contain a `streaming_config` message and must not contain
     * `audio_content` data. All subsequent messages must contain `audio_content`
     * data and must not contain a `streaming_config` message.
     * </pre>
     *
     * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechRequest)
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest.Builder.class);
      }

      // Construct using com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (streamingConfigBuilder_ != null) {
          streamingConfigBuilder_.clear();
        }
        streamingRequestCase_ = 0;
        streamingRequest_ = null;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechRequest_descriptor;
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest getDefaultInstanceForType() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest.getDefaultInstance();
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest build() {
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest buildPartial() {
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest result = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        buildPartialOneofs(result);
        onBuilt();
        return result;
      }

      private void buildPartial0(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest result) {
        int from_bitField0_ = bitField0_;
      }

      private void buildPartialOneofs(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest result) {
        result.streamingRequestCase_ = streamingRequestCase_;
        result.streamingRequest_ = this.streamingRequest_;
        if (streamingRequestCase_ == 1 &&
            streamingConfigBuilder_ != null) {
          result.streamingRequest_ = streamingConfigBuilder_.build();
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest) {
          return mergeFrom((com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest other) {
        if (other == com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest.getDefaultInstance()) return this;
        switch (other.getStreamingRequestCase()) {
          case STREAMING_CONFIG: {
            mergeStreamingConfig(other.getStreamingConfig());
            break;
          }
          case AUDIO_CONTENT: {
            setAudioContent(other.getAudioContent());
            break;
          }
          case STREAMINGREQUEST_NOT_SET: {
            break;
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getStreamingConfigFieldBuilder().getBuilder(),
                    extensionRegistry);
                streamingRequestCase_ = 1;
                break;
              } // case 10
              case 18: {
                streamingRequest_ = input.readBytes();
                streamingRequestCase_ = 2;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int streamingRequestCase_ = 0;
      private java.lang.Object streamingRequest_;
      public StreamingRequestCase
          getStreamingRequestCase() {
        return StreamingRequestCase.forNumber(
            streamingRequestCase_);
      }

      public Builder clearStreamingRequest() {
        streamingRequestCase_ = 0;
        streamingRequest_ = null;
        onChanged();
        return this;
      }

      private int bitField0_;

      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfigOrBuilder> streamingConfigBuilder_;
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingTranslateSpeechRequest` message must contain
       * a `streaming_config` message.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
       * @return Whether the streamingConfig field is set.
       */
      @java.lang.Override
      public boolean hasStreamingConfig() {
        return streamingRequestCase_ == 1;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingTranslateSpeechRequest` message must contain
       * a `streaming_config` message.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
       * @return The streamingConfig.
       */
      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig getStreamingConfig() {
        if (streamingConfigBuilder_ == null) {
          if (streamingRequestCase_ == 1) {
            return (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig) streamingRequest_;
          }
          return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.getDefaultInstance();
        } else {
          if (streamingRequestCase_ == 1) {
            return streamingConfigBuilder_.getMessage();
          }
          return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.getDefaultInstance();
        }
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingTranslateSpeechRequest` message must contain
       * a `streaming_config` message.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
       */
      public Builder setStreamingConfig(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig value) {
        if (streamingConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          streamingRequest_ = value;
          onChanged();
        } else {
          streamingConfigBuilder_.setMessage(value);
        }
        streamingRequestCase_ = 1;
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingTranslateSpeechRequest` message must contain
       * a `streaming_config` message.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
       */
      public Builder setStreamingConfig(
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.Builder builderForValue) {
        if (streamingConfigBuilder_ == null) {
          streamingRequest_ = builderForValue.build();
          onChanged();
        } else {
          streamingConfigBuilder_.setMessage(builderForValue.build());
        }
        streamingRequestCase_ = 1;
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingTranslateSpeechRequest` message must contain
       * a `streaming_config` message.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
       */
      public Builder mergeStreamingConfig(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig value) {
        if (streamingConfigBuilder_ == null) {
          if (streamingRequestCase_ == 1 &&
              streamingRequest_ != com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.getDefaultInstance()) {
            streamingRequest_ = com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.newBuilder((com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig) streamingRequest_)
                .mergeFrom(value).buildPartial();
          } else {
            streamingRequest_ = value;
          }
          onChanged();
        } else {
          if (streamingRequestCase_ == 1) {
            streamingConfigBuilder_.mergeFrom(value);
          } else {
            streamingConfigBuilder_.setMessage(value);
          }
        }
        streamingRequestCase_ = 1;
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingTranslateSpeechRequest` message must contain
       * a `streaming_config` message.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
       */
      public Builder clearStreamingConfig() {
        if (streamingConfigBuilder_ == null) {
          if (streamingRequestCase_ == 1) {
            streamingRequestCase_ = 0;
            streamingRequest_ = null;
            onChanged();
          }
        } else {
          if (streamingRequestCase_ == 1) {
            streamingRequestCase_ = 0;
            streamingRequest_ = null;
          }
          streamingConfigBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingTranslateSpeechRequest` message must contain
       * a `streaming_config` message.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.Builder getStreamingConfigBuilder() {
        return getStreamingConfigFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingTranslateSpeechRequest` message must contain
       * a `streaming_config` message.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
       */
      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfigOrBuilder getStreamingConfigOrBuilder() {
        if ((streamingRequestCase_ == 1) && (streamingConfigBuilder_ != null)) {
          return streamingConfigBuilder_.getMessageOrBuilder();
        } else {
          if (streamingRequestCase_ == 1) {
            return (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig) streamingRequest_;
          }
          return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.getDefaultInstance();
        }
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingTranslateSpeechRequest` message must contain
       * a `streaming_config` message.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechConfig streaming_config = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfigOrBuilder> 
          getStreamingConfigFieldBuilder() {
        if (streamingConfigBuilder_ == null) {
          if (!(streamingRequestCase_ == 1)) {
            streamingRequest_ = com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.getDefaultInstance();
          }
          streamingConfigBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfigOrBuilder>(
                  (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechConfig) streamingRequest_,
                  getParentForChildren(),
                  isClean());
          streamingRequest_ = null;
        }
        streamingRequestCase_ = 1;
        onChanged();
        return streamingConfigBuilder_;
      }

      /**
       * <pre>
       * The audio data to be translated. Sequential chunks of audio data are sent
       * in sequential `StreamingTranslateSpeechRequest` messages. The first
       * `StreamingTranslateSpeechRequest` message must not contain
       * `audio_content` data and all subsequent `StreamingTranslateSpeechRequest`
       * messages must contain `audio_content` data. The audio bytes must be
       * encoded as specified in `StreamingTranslateSpeechConfig`. Note: as with
       * all bytes fields, protobuffers use a pure binary representation (not
       * base64).
       * </pre>
       *
       * <code>bytes audio_content = 2;</code>
       * @return Whether the audioContent field is set.
       */
      public boolean hasAudioContent() {
        return streamingRequestCase_ == 2;
      }
      /**
       * <pre>
       * The audio data to be translated. Sequential chunks of audio data are sent
       * in sequential `StreamingTranslateSpeechRequest` messages. The first
       * `StreamingTranslateSpeechRequest` message must not contain
       * `audio_content` data and all subsequent `StreamingTranslateSpeechRequest`
       * messages must contain `audio_content` data. The audio bytes must be
       * encoded as specified in `StreamingTranslateSpeechConfig`. Note: as with
       * all bytes fields, protobuffers use a pure binary representation (not
       * base64).
       * </pre>
       *
       * <code>bytes audio_content = 2;</code>
       * @return The audioContent.
       */
      public com.google.protobuf.ByteString getAudioContent() {
        if (streamingRequestCase_ == 2) {
          return (com.google.protobuf.ByteString) streamingRequest_;
        }
        return com.google.protobuf.ByteString.EMPTY;
      }
      /**
       * <pre>
       * The audio data to be translated. Sequential chunks of audio data are sent
       * in sequential `StreamingTranslateSpeechRequest` messages. The first
       * `StreamingTranslateSpeechRequest` message must not contain
       * `audio_content` data and all subsequent `StreamingTranslateSpeechRequest`
       * messages must contain `audio_content` data. The audio bytes must be
       * encoded as specified in `StreamingTranslateSpeechConfig`. Note: as with
       * all bytes fields, protobuffers use a pure binary representation (not
       * base64).
       * </pre>
       *
       * <code>bytes audio_content = 2;</code>
       * @param value The audioContent to set.
       * @return This builder for chaining.
       */
      public Builder setAudioContent(com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        streamingRequestCase_ = 2;
        streamingRequest_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The audio data to be translated. Sequential chunks of audio data are sent
       * in sequential `StreamingTranslateSpeechRequest` messages. The first
       * `StreamingTranslateSpeechRequest` message must not contain
       * `audio_content` data and all subsequent `StreamingTranslateSpeechRequest`
       * messages must contain `audio_content` data. The audio bytes must be
       * encoded as specified in `StreamingTranslateSpeechConfig`. Note: as with
       * all bytes fields, protobuffers use a pure binary representation (not
       * base64).
       * </pre>
       *
       * <code>bytes audio_content = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearAudioContent() {
        if (streamingRequestCase_ == 2) {
          streamingRequestCase_ = 0;
          streamingRequest_ = null;
          onChanged();
        }
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechRequest)
    }

    // @@protoc_insertion_point(class_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechRequest)
    private static final com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest();
    }

    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingTranslateSpeechRequest>
        PARSER = new com.google.protobuf.AbstractParser<StreamingTranslateSpeechRequest>() {
      @java.lang.Override
      public StreamingTranslateSpeechRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<StreamingTranslateSpeechRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StreamingTranslateSpeechRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingTranslateSpeechResultOrBuilder extends
      // @@protoc_insertion_point(interface_extends:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Text translation result.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
     * @return Whether the textTranslationResult field is set.
     */
    boolean hasTextTranslationResult();
    /**
     * <pre>
     * Text translation result.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
     * @return The textTranslationResult.
     */
    com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult getTextTranslationResult();
    /**
     * <pre>
     * Text translation result.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
     */
    com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResultOrBuilder getTextTranslationResultOrBuilder();

    /**
     * <pre>
     * Audio translation result.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
     * @return Whether the audioTranslationResult field is set.
     */
    boolean hasAudioTranslationResult();
    /**
     * <pre>
     * Audio translation result.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
     * @return The audioTranslationResult.
     */
    com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult getAudioTranslationResult();
    /**
     * <pre>
     * Audio translation result.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
     */
    com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResultOrBuilder getAudioTranslationResultOrBuilder();

    /**
     * <pre>
     * Output only. The debug only recognition result in original language. This field is debug
     * only and will be set to empty string if not available.
     * This is implementation detail and will not be backward compatible.
     * </pre>
     *
     * <code>string recognition_result = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The recognitionResult.
     */
    java.lang.String getRecognitionResult();
    /**
     * <pre>
     * Output only. The debug only recognition result in original language. This field is debug
     * only and will be set to empty string if not available.
     * This is implementation detail and will not be backward compatible.
     * </pre>
     *
     * <code>string recognition_result = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The bytes for recognitionResult.
     */
    com.google.protobuf.ByteString
        getRecognitionResultBytes();

    /**
     * <pre>
     * Output only.
     * </pre>
     *
     * <code>string detected_source_language_code = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The detectedSourceLanguageCode.
     */
    java.lang.String getDetectedSourceLanguageCode();
    /**
     * <pre>
     * Output only.
     * </pre>
     *
     * <code>string detected_source_language_code = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The bytes for detectedSourceLanguageCode.
     */
    com.google.protobuf.ByteString
        getDetectedSourceLanguageCodeBytes();
  }
  /**
   * <pre>
   * A streaming speech translation result corresponding to a portion of the audio
   * that is currently being processed.
   * </pre>
   *
   * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult}
   */
  public static final class StreamingTranslateSpeechResult extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult)
      StreamingTranslateSpeechResultOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StreamingTranslateSpeechResult.newBuilder() to construct.
    private StreamingTranslateSpeechResult(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingTranslateSpeechResult() {
      recognitionResult_ = "";
      detectedSourceLanguageCode_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new StreamingTranslateSpeechResult();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.Builder.class);
    }

    public interface TextTranslationResultOrBuilder extends
        // @@protoc_insertion_point(interface_extends:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       * Output only. The translated sentence.
       * </pre>
       *
       * <code>string translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The translation.
       */
      java.lang.String getTranslation();
      /**
       * <pre>
       * Output only. The translated sentence.
       * </pre>
       *
       * <code>string translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The bytes for translation.
       */
      com.google.protobuf.ByteString
          getTranslationBytes();

      /**
       * <pre>
       * Output only. If `false`, this `StreamingTranslateSpeechResult` represents
       * an interim result that may change. If `true`, this is the final time the
       * translation service will return this particular
       * `StreamingTranslateSpeechResult`, the streaming translator will not
       * return any further hypotheses for this portion of the transcript and
       * corresponding audio.
       * </pre>
       *
       * <code>bool is_final = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The isFinal.
       */
      boolean getIsFinal();
    }
    /**
     * <pre>
     * Text translation result.
     * </pre>
     *
     * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult}
     */
    public static final class TextTranslationResult extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult)
        TextTranslationResultOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use TextTranslationResult.newBuilder() to construct.
      private TextTranslationResult(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private TextTranslationResult() {
        translation_ = "";
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new TextTranslationResult();
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_TextTranslationResult_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_TextTranslationResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.Builder.class);
      }

      public static final int TRANSLATION_FIELD_NUMBER = 1;
      @SuppressWarnings("serial")
      private volatile java.lang.Object translation_ = "";
      /**
       * <pre>
       * Output only. The translated sentence.
       * </pre>
       *
       * <code>string translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The translation.
       */
      @java.lang.Override
      public java.lang.String getTranslation() {
        java.lang.Object ref = translation_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          com.google.protobuf.ByteString bs = 
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          translation_ = s;
          return s;
        }
      }
      /**
       * <pre>
       * Output only. The translated sentence.
       * </pre>
       *
       * <code>string translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The bytes for translation.
       */
      @java.lang.Override
      public com.google.protobuf.ByteString
          getTranslationBytes() {
        java.lang.Object ref = translation_;
        if (ref instanceof java.lang.String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          translation_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      public static final int IS_FINAL_FIELD_NUMBER = 2;
      private boolean isFinal_ = false;
      /**
       * <pre>
       * Output only. If `false`, this `StreamingTranslateSpeechResult` represents
       * an interim result that may change. If `true`, this is the final time the
       * translation service will return this particular
       * `StreamingTranslateSpeechResult`, the streaming translator will not
       * return any further hypotheses for this portion of the transcript and
       * corresponding audio.
       * </pre>
       *
       * <code>bool is_final = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The isFinal.
       */
      @java.lang.Override
      public boolean getIsFinal() {
        return isFinal_;
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(translation_)) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 1, translation_);
        }
        if (isFinal_ != false) {
          output.writeBool(2, isFinal_);
        }
        getUnknownFields().writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(translation_)) {
          size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, translation_);
        }
        if (isFinal_ != false) {
          size += com.google.protobuf.CodedOutputStream
            .computeBoolSize(2, isFinal_);
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult)) {
          return super.equals(obj);
        }
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult other = (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult) obj;

        if (!getTranslation()
            .equals(other.getTranslation())) return false;
        if (getIsFinal()
            != other.getIsFinal()) return false;
        if (!getUnknownFields().equals(other.getUnknownFields())) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        hash = (37 * hash) + TRANSLATION_FIELD_NUMBER;
        hash = (53 * hash) + getTranslation().hashCode();
        hash = (37 * hash) + IS_FINAL_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getIsFinal());
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       * Text translation result.
       * </pre>
       *
       * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult)
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResultOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_TextTranslationResult_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_TextTranslationResult_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.Builder.class);
        }

        // Construct using com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.newBuilder()
        private Builder() {

        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);

        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          bitField0_ = 0;
          translation_ = "";
          isFinal_ = false;
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_TextTranslationResult_descriptor;
        }

        @java.lang.Override
        public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult getDefaultInstanceForType() {
          return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.getDefaultInstance();
        }

        @java.lang.Override
        public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult build() {
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult buildPartial() {
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult result = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult(this);
          if (bitField0_ != 0) { buildPartial0(result); }
          onBuilt();
          return result;
        }

        private void buildPartial0(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult result) {
          int from_bitField0_ = bitField0_;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            result.translation_ = translation_;
          }
          if (((from_bitField0_ & 0x00000002) != 0)) {
            result.isFinal_ = isFinal_;
          }
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult) {
            return mergeFrom((com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult other) {
          if (other == com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.getDefaultInstance()) return this;
          if (!other.getTranslation().isEmpty()) {
            translation_ = other.translation_;
            bitField0_ |= 0x00000001;
            onChanged();
          }
          if (other.getIsFinal() != false) {
            setIsFinal(other.getIsFinal());
          }
          this.mergeUnknownFields(other.getUnknownFields());
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          if (extensionRegistry == null) {
            throw new java.lang.NullPointerException();
          }
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                case 10: {
                  translation_ = input.readStringRequireUtf8();
                  bitField0_ |= 0x00000001;
                  break;
                } // case 10
                case 16: {
                  isFinal_ = input.readBool();
                  bitField0_ |= 0x00000002;
                  break;
                } // case 16
                default: {
                  if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                    done = true; // was an endgroup tag
                  }
                  break;
                } // default:
              } // switch (tag)
            } // while (!done)
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.unwrapIOException();
          } finally {
            onChanged();
          } // finally
          return this;
        }
        private int bitField0_;

        private java.lang.Object translation_ = "";
        /**
         * <pre>
         * Output only. The translated sentence.
         * </pre>
         *
         * <code>string translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
         * @return The translation.
         */
        public java.lang.String getTranslation() {
          java.lang.Object ref = translation_;
          if (!(ref instanceof java.lang.String)) {
            com.google.protobuf.ByteString bs =
                (com.google.protobuf.ByteString) ref;
            java.lang.String s = bs.toStringUtf8();
            translation_ = s;
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         * <pre>
         * Output only. The translated sentence.
         * </pre>
         *
         * <code>string translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
         * @return The bytes for translation.
         */
        public com.google.protobuf.ByteString
            getTranslationBytes() {
          java.lang.Object ref = translation_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b = 
                com.google.protobuf.ByteString.copyFromUtf8(
                    (java.lang.String) ref);
            translation_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         * <pre>
         * Output only. The translated sentence.
         * </pre>
         *
         * <code>string translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
         * @param value The translation to set.
         * @return This builder for chaining.
         */
        public Builder setTranslation(
            java.lang.String value) {
          if (value == null) { throw new NullPointerException(); }
          translation_ = value;
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         * <pre>
         * Output only. The translated sentence.
         * </pre>
         *
         * <code>string translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
         * @return This builder for chaining.
         */
        public Builder clearTranslation() {
          translation_ = getDefaultInstance().getTranslation();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
          return this;
        }
        /**
         * <pre>
         * Output only. The translated sentence.
         * </pre>
         *
         * <code>string translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
         * @param value The bytes for translation to set.
         * @return This builder for chaining.
         */
        public Builder setTranslationBytes(
            com.google.protobuf.ByteString value) {
          if (value == null) { throw new NullPointerException(); }
          checkByteStringIsUtf8(value);
          translation_ = value;
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }

        private boolean isFinal_ ;
        /**
         * <pre>
         * Output only. If `false`, this `StreamingTranslateSpeechResult` represents
         * an interim result that may change. If `true`, this is the final time the
         * translation service will return this particular
         * `StreamingTranslateSpeechResult`, the streaming translator will not
         * return any further hypotheses for this portion of the transcript and
         * corresponding audio.
         * </pre>
         *
         * <code>bool is_final = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
         * @return The isFinal.
         */
        @java.lang.Override
        public boolean getIsFinal() {
          return isFinal_;
        }
        /**
         * <pre>
         * Output only. If `false`, this `StreamingTranslateSpeechResult` represents
         * an interim result that may change. If `true`, this is the final time the
         * translation service will return this particular
         * `StreamingTranslateSpeechResult`, the streaming translator will not
         * return any further hypotheses for this portion of the transcript and
         * corresponding audio.
         * </pre>
         *
         * <code>bool is_final = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
         * @param value The isFinal to set.
         * @return This builder for chaining.
         */
        public Builder setIsFinal(boolean value) {
          
          isFinal_ = value;
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }
        /**
         * <pre>
         * Output only. If `false`, this `StreamingTranslateSpeechResult` represents
         * an interim result that may change. If `true`, this is the final time the
         * translation service will return this particular
         * `StreamingTranslateSpeechResult`, the streaming translator will not
         * return any further hypotheses for this portion of the transcript and
         * corresponding audio.
         * </pre>
         *
         * <code>bool is_final = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
         * @return This builder for chaining.
         */
        public Builder clearIsFinal() {
          bitField0_ = (bitField0_ & ~0x00000002);
          isFinal_ = false;
          onChanged();
          return this;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult)
      }

      // @@protoc_insertion_point(class_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult)
      private static final com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult();
      }

      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<TextTranslationResult>
          PARSER = new com.google.protobuf.AbstractParser<TextTranslationResult>() {
        @java.lang.Override
        public TextTranslationResult parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          Builder builder = newBuilder();
          try {
            builder.mergeFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.setUnfinishedMessage(builder.buildPartial());
          } catch (com.google.protobuf.UninitializedMessageException e) {
            throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
          } catch (java.io.IOException e) {
            throw new com.google.protobuf.InvalidProtocolBufferException(e)
                .setUnfinishedMessage(builder.buildPartial());
          }
          return builder.buildPartial();
        }
      };

      public static com.google.protobuf.Parser<TextTranslationResult> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<TextTranslationResult> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface AudioTranslationResultOrBuilder extends
        // @@protoc_insertion_point(interface_extends:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       * Output only. The translated audio.
       * </pre>
       *
       * <code>bytes audio_translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The audioTranslation.
       */
      com.google.protobuf.ByteString getAudioTranslation();
    }
    /**
     * <pre>
     * Audio translation result.
     * </pre>
     *
     * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult}
     */
    public static final class AudioTranslationResult extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult)
        AudioTranslationResultOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use AudioTranslationResult.newBuilder() to construct.
      private AudioTranslationResult(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private AudioTranslationResult() {
        audioTranslation_ = com.google.protobuf.ByteString.EMPTY;
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new AudioTranslationResult();
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_AudioTranslationResult_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_AudioTranslationResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.Builder.class);
      }

      public static final int AUDIO_TRANSLATION_FIELD_NUMBER = 1;
      private com.google.protobuf.ByteString audioTranslation_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <pre>
       * Output only. The translated audio.
       * </pre>
       *
       * <code>bytes audio_translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The audioTranslation.
       */
      @java.lang.Override
      public com.google.protobuf.ByteString getAudioTranslation() {
        return audioTranslation_;
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (!audioTranslation_.isEmpty()) {
          output.writeBytes(1, audioTranslation_);
        }
        getUnknownFields().writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (!audioTranslation_.isEmpty()) {
          size += com.google.protobuf.CodedOutputStream
            .computeBytesSize(1, audioTranslation_);
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult)) {
          return super.equals(obj);
        }
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult other = (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult) obj;

        if (!getAudioTranslation()
            .equals(other.getAudioTranslation())) return false;
        if (!getUnknownFields().equals(other.getUnknownFields())) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        hash = (37 * hash) + AUDIO_TRANSLATION_FIELD_NUMBER;
        hash = (53 * hash) + getAudioTranslation().hashCode();
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       * Audio translation result.
       * </pre>
       *
       * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult)
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResultOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_AudioTranslationResult_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_AudioTranslationResult_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.Builder.class);
        }

        // Construct using com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.newBuilder()
        private Builder() {

        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);

        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          bitField0_ = 0;
          audioTranslation_ = com.google.protobuf.ByteString.EMPTY;
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_AudioTranslationResult_descriptor;
        }

        @java.lang.Override
        public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult getDefaultInstanceForType() {
          return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.getDefaultInstance();
        }

        @java.lang.Override
        public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult build() {
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult buildPartial() {
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult result = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult(this);
          if (bitField0_ != 0) { buildPartial0(result); }
          onBuilt();
          return result;
        }

        private void buildPartial0(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult result) {
          int from_bitField0_ = bitField0_;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            result.audioTranslation_ = audioTranslation_;
          }
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult) {
            return mergeFrom((com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult other) {
          if (other == com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.getDefaultInstance()) return this;
          if (other.getAudioTranslation() != com.google.protobuf.ByteString.EMPTY) {
            setAudioTranslation(other.getAudioTranslation());
          }
          this.mergeUnknownFields(other.getUnknownFields());
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          if (extensionRegistry == null) {
            throw new java.lang.NullPointerException();
          }
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                case 10: {
                  audioTranslation_ = input.readBytes();
                  bitField0_ |= 0x00000001;
                  break;
                } // case 10
                default: {
                  if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                    done = true; // was an endgroup tag
                  }
                  break;
                } // default:
              } // switch (tag)
            } // while (!done)
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.unwrapIOException();
          } finally {
            onChanged();
          } // finally
          return this;
        }
        private int bitField0_;

        private com.google.protobuf.ByteString audioTranslation_ = com.google.protobuf.ByteString.EMPTY;
        /**
         * <pre>
         * Output only. The translated audio.
         * </pre>
         *
         * <code>bytes audio_translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
         * @return The audioTranslation.
         */
        @java.lang.Override
        public com.google.protobuf.ByteString getAudioTranslation() {
          return audioTranslation_;
        }
        /**
         * <pre>
         * Output only. The translated audio.
         * </pre>
         *
         * <code>bytes audio_translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
         * @param value The audioTranslation to set.
         * @return This builder for chaining.
         */
        public Builder setAudioTranslation(com.google.protobuf.ByteString value) {
          if (value == null) { throw new NullPointerException(); }
          audioTranslation_ = value;
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         * <pre>
         * Output only. The translated audio.
         * </pre>
         *
         * <code>bytes audio_translation = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
         * @return This builder for chaining.
         */
        public Builder clearAudioTranslation() {
          bitField0_ = (bitField0_ & ~0x00000001);
          audioTranslation_ = getDefaultInstance().getAudioTranslation();
          onChanged();
          return this;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult)
      }

      // @@protoc_insertion_point(class_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult)
      private static final com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult();
      }

      public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<AudioTranslationResult>
          PARSER = new com.google.protobuf.AbstractParser<AudioTranslationResult>() {
        @java.lang.Override
        public AudioTranslationResult parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          Builder builder = newBuilder();
          try {
            builder.mergeFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.setUnfinishedMessage(builder.buildPartial());
          } catch (com.google.protobuf.UninitializedMessageException e) {
            throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
          } catch (java.io.IOException e) {
            throw new com.google.protobuf.InvalidProtocolBufferException(e)
                .setUnfinishedMessage(builder.buildPartial());
          }
          return builder.buildPartial();
        }
      };

      public static com.google.protobuf.Parser<AudioTranslationResult> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<AudioTranslationResult> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public static final int TEXT_TRANSLATION_RESULT_FIELD_NUMBER = 1;
    private com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult textTranslationResult_;
    /**
     * <pre>
     * Text translation result.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
     * @return Whether the textTranslationResult field is set.
     */
    @java.lang.Override
    public boolean hasTextTranslationResult() {
      return textTranslationResult_ != null;
    }
    /**
     * <pre>
     * Text translation result.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
     * @return The textTranslationResult.
     */
    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult getTextTranslationResult() {
      return textTranslationResult_ == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.getDefaultInstance() : textTranslationResult_;
    }
    /**
     * <pre>
     * Text translation result.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
     */
    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResultOrBuilder getTextTranslationResultOrBuilder() {
      return textTranslationResult_ == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.getDefaultInstance() : textTranslationResult_;
    }

    public static final int AUDIO_TRANSLATION_RESULT_FIELD_NUMBER = 2;
    private com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult audioTranslationResult_;
    /**
     * <pre>
     * Audio translation result.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
     * @return Whether the audioTranslationResult field is set.
     */
    @java.lang.Override
    public boolean hasAudioTranslationResult() {
      return audioTranslationResult_ != null;
    }
    /**
     * <pre>
     * Audio translation result.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
     * @return The audioTranslationResult.
     */
    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult getAudioTranslationResult() {
      return audioTranslationResult_ == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.getDefaultInstance() : audioTranslationResult_;
    }
    /**
     * <pre>
     * Audio translation result.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
     */
    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResultOrBuilder getAudioTranslationResultOrBuilder() {
      return audioTranslationResult_ == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.getDefaultInstance() : audioTranslationResult_;
    }

    public static final int RECOGNITION_RESULT_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private volatile java.lang.Object recognitionResult_ = "";
    /**
     * <pre>
     * Output only. The debug only recognition result in original language. This field is debug
     * only and will be set to empty string if not available.
     * This is implementation detail and will not be backward compatible.
     * </pre>
     *
     * <code>string recognition_result = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The recognitionResult.
     */
    @java.lang.Override
    public java.lang.String getRecognitionResult() {
      java.lang.Object ref = recognitionResult_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        recognitionResult_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Output only. The debug only recognition result in original language. This field is debug
     * only and will be set to empty string if not available.
     * This is implementation detail and will not be backward compatible.
     * </pre>
     *
     * <code>string recognition_result = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The bytes for recognitionResult.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getRecognitionResultBytes() {
      java.lang.Object ref = recognitionResult_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        recognitionResult_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DETECTED_SOURCE_LANGUAGE_CODE_FIELD_NUMBER = 4;
    @SuppressWarnings("serial")
    private volatile java.lang.Object detectedSourceLanguageCode_ = "";
    /**
     * <pre>
     * Output only.
     * </pre>
     *
     * <code>string detected_source_language_code = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The detectedSourceLanguageCode.
     */
    @java.lang.Override
    public java.lang.String getDetectedSourceLanguageCode() {
      java.lang.Object ref = detectedSourceLanguageCode_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        detectedSourceLanguageCode_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Output only.
     * </pre>
     *
     * <code>string detected_source_language_code = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The bytes for detectedSourceLanguageCode.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getDetectedSourceLanguageCodeBytes() {
      java.lang.Object ref = detectedSourceLanguageCode_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        detectedSourceLanguageCode_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (textTranslationResult_ != null) {
        output.writeMessage(1, getTextTranslationResult());
      }
      if (audioTranslationResult_ != null) {
        output.writeMessage(2, getAudioTranslationResult());
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(recognitionResult_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, recognitionResult_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(detectedSourceLanguageCode_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, detectedSourceLanguageCode_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (textTranslationResult_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getTextTranslationResult());
      }
      if (audioTranslationResult_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getAudioTranslationResult());
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(recognitionResult_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, recognitionResult_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(detectedSourceLanguageCode_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, detectedSourceLanguageCode_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult)) {
        return super.equals(obj);
      }
      com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult other = (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult) obj;

      if (hasTextTranslationResult() != other.hasTextTranslationResult()) return false;
      if (hasTextTranslationResult()) {
        if (!getTextTranslationResult()
            .equals(other.getTextTranslationResult())) return false;
      }
      if (hasAudioTranslationResult() != other.hasAudioTranslationResult()) return false;
      if (hasAudioTranslationResult()) {
        if (!getAudioTranslationResult()
            .equals(other.getAudioTranslationResult())) return false;
      }
      if (!getRecognitionResult()
          .equals(other.getRecognitionResult())) return false;
      if (!getDetectedSourceLanguageCode()
          .equals(other.getDetectedSourceLanguageCode())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTextTranslationResult()) {
        hash = (37 * hash) + TEXT_TRANSLATION_RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getTextTranslationResult().hashCode();
      }
      if (hasAudioTranslationResult()) {
        hash = (37 * hash) + AUDIO_TRANSLATION_RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getAudioTranslationResult().hashCode();
      }
      hash = (37 * hash) + RECOGNITION_RESULT_FIELD_NUMBER;
      hash = (53 * hash) + getRecognitionResult().hashCode();
      hash = (37 * hash) + DETECTED_SOURCE_LANGUAGE_CODE_FIELD_NUMBER;
      hash = (53 * hash) + getDetectedSourceLanguageCode().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * A streaming speech translation result corresponding to a portion of the audio
     * that is currently being processed.
     * </pre>
     *
     * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult)
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.Builder.class);
      }

      // Construct using com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        textTranslationResult_ = null;
        if (textTranslationResultBuilder_ != null) {
          textTranslationResultBuilder_.dispose();
          textTranslationResultBuilder_ = null;
        }
        audioTranslationResult_ = null;
        if (audioTranslationResultBuilder_ != null) {
          audioTranslationResultBuilder_.dispose();
          audioTranslationResultBuilder_ = null;
        }
        recognitionResult_ = "";
        detectedSourceLanguageCode_ = "";
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_descriptor;
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult getDefaultInstanceForType() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.getDefaultInstance();
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult build() {
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult buildPartial() {
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult result = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.textTranslationResult_ = textTranslationResultBuilder_ == null
              ? textTranslationResult_
              : textTranslationResultBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.audioTranslationResult_ = audioTranslationResultBuilder_ == null
              ? audioTranslationResult_
              : audioTranslationResultBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.recognitionResult_ = recognitionResult_;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.detectedSourceLanguageCode_ = detectedSourceLanguageCode_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult) {
          return mergeFrom((com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult other) {
        if (other == com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.getDefaultInstance()) return this;
        if (other.hasTextTranslationResult()) {
          mergeTextTranslationResult(other.getTextTranslationResult());
        }
        if (other.hasAudioTranslationResult()) {
          mergeAudioTranslationResult(other.getAudioTranslationResult());
        }
        if (!other.getRecognitionResult().isEmpty()) {
          recognitionResult_ = other.recognitionResult_;
          bitField0_ |= 0x00000004;
          onChanged();
        }
        if (!other.getDetectedSourceLanguageCode().isEmpty()) {
          detectedSourceLanguageCode_ = other.detectedSourceLanguageCode_;
          bitField0_ |= 0x00000008;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getTextTranslationResultFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getAudioTranslationResultFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 26: {
                recognitionResult_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 34: {
                detectedSourceLanguageCode_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000008;
                break;
              } // case 34
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult textTranslationResult_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResultOrBuilder> textTranslationResultBuilder_;
      /**
       * <pre>
       * Text translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
       * @return Whether the textTranslationResult field is set.
       */
      public boolean hasTextTranslationResult() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * Text translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
       * @return The textTranslationResult.
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult getTextTranslationResult() {
        if (textTranslationResultBuilder_ == null) {
          return textTranslationResult_ == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.getDefaultInstance() : textTranslationResult_;
        } else {
          return textTranslationResultBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Text translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
       */
      public Builder setTextTranslationResult(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult value) {
        if (textTranslationResultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          textTranslationResult_ = value;
        } else {
          textTranslationResultBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Text translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
       */
      public Builder setTextTranslationResult(
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.Builder builderForValue) {
        if (textTranslationResultBuilder_ == null) {
          textTranslationResult_ = builderForValue.build();
        } else {
          textTranslationResultBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Text translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
       */
      public Builder mergeTextTranslationResult(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult value) {
        if (textTranslationResultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            textTranslationResult_ != null &&
            textTranslationResult_ != com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.getDefaultInstance()) {
            getTextTranslationResultBuilder().mergeFrom(value);
          } else {
            textTranslationResult_ = value;
          }
        } else {
          textTranslationResultBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Text translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
       */
      public Builder clearTextTranslationResult() {
        bitField0_ = (bitField0_ & ~0x00000001);
        textTranslationResult_ = null;
        if (textTranslationResultBuilder_ != null) {
          textTranslationResultBuilder_.dispose();
          textTranslationResultBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Text translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.Builder getTextTranslationResultBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTextTranslationResultFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Text translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResultOrBuilder getTextTranslationResultOrBuilder() {
        if (textTranslationResultBuilder_ != null) {
          return textTranslationResultBuilder_.getMessageOrBuilder();
        } else {
          return textTranslationResult_ == null ?
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.getDefaultInstance() : textTranslationResult_;
        }
      }
      /**
       * <pre>
       * Text translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.TextTranslationResult text_translation_result = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResultOrBuilder> 
          getTextTranslationResultFieldBuilder() {
        if (textTranslationResultBuilder_ == null) {
          textTranslationResultBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResult.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.TextTranslationResultOrBuilder>(
                  getTextTranslationResult(),
                  getParentForChildren(),
                  isClean());
          textTranslationResult_ = null;
        }
        return textTranslationResultBuilder_;
      }

      private com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult audioTranslationResult_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResultOrBuilder> audioTranslationResultBuilder_;
      /**
       * <pre>
       * Audio translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
       * @return Whether the audioTranslationResult field is set.
       */
      public boolean hasAudioTranslationResult() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * Audio translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
       * @return The audioTranslationResult.
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult getAudioTranslationResult() {
        if (audioTranslationResultBuilder_ == null) {
          return audioTranslationResult_ == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.getDefaultInstance() : audioTranslationResult_;
        } else {
          return audioTranslationResultBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Audio translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
       */
      public Builder setAudioTranslationResult(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult value) {
        if (audioTranslationResultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          audioTranslationResult_ = value;
        } else {
          audioTranslationResultBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Audio translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
       */
      public Builder setAudioTranslationResult(
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.Builder builderForValue) {
        if (audioTranslationResultBuilder_ == null) {
          audioTranslationResult_ = builderForValue.build();
        } else {
          audioTranslationResultBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Audio translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
       */
      public Builder mergeAudioTranslationResult(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult value) {
        if (audioTranslationResultBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            audioTranslationResult_ != null &&
            audioTranslationResult_ != com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.getDefaultInstance()) {
            getAudioTranslationResultBuilder().mergeFrom(value);
          } else {
            audioTranslationResult_ = value;
          }
        } else {
          audioTranslationResultBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Audio translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
       */
      public Builder clearAudioTranslationResult() {
        bitField0_ = (bitField0_ & ~0x00000002);
        audioTranslationResult_ = null;
        if (audioTranslationResultBuilder_ != null) {
          audioTranslationResultBuilder_.dispose();
          audioTranslationResultBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Audio translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.Builder getAudioTranslationResultBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getAudioTranslationResultFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Audio translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResultOrBuilder getAudioTranslationResultOrBuilder() {
        if (audioTranslationResultBuilder_ != null) {
          return audioTranslationResultBuilder_.getMessageOrBuilder();
        } else {
          return audioTranslationResult_ == null ?
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.getDefaultInstance() : audioTranslationResult_;
        }
      }
      /**
       * <pre>
       * Audio translation result.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult.AudioTranslationResult audio_translation_result = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResultOrBuilder> 
          getAudioTranslationResultFieldBuilder() {
        if (audioTranslationResultBuilder_ == null) {
          audioTranslationResultBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResult.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.AudioTranslationResultOrBuilder>(
                  getAudioTranslationResult(),
                  getParentForChildren(),
                  isClean());
          audioTranslationResult_ = null;
        }
        return audioTranslationResultBuilder_;
      }

      private java.lang.Object recognitionResult_ = "";
      /**
       * <pre>
       * Output only. The debug only recognition result in original language. This field is debug
       * only and will be set to empty string if not available.
       * This is implementation detail and will not be backward compatible.
       * </pre>
       *
       * <code>string recognition_result = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The recognitionResult.
       */
      public java.lang.String getRecognitionResult() {
        java.lang.Object ref = recognitionResult_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          recognitionResult_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Output only. The debug only recognition result in original language. This field is debug
       * only and will be set to empty string if not available.
       * This is implementation detail and will not be backward compatible.
       * </pre>
       *
       * <code>string recognition_result = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The bytes for recognitionResult.
       */
      public com.google.protobuf.ByteString
          getRecognitionResultBytes() {
        java.lang.Object ref = recognitionResult_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          recognitionResult_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Output only. The debug only recognition result in original language. This field is debug
       * only and will be set to empty string if not available.
       * This is implementation detail and will not be backward compatible.
       * </pre>
       *
       * <code>string recognition_result = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @param value The recognitionResult to set.
       * @return This builder for chaining.
       */
      public Builder setRecognitionResult(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        recognitionResult_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only. The debug only recognition result in original language. This field is debug
       * only and will be set to empty string if not available.
       * This is implementation detail and will not be backward compatible.
       * </pre>
       *
       * <code>string recognition_result = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return This builder for chaining.
       */
      public Builder clearRecognitionResult() {
        recognitionResult_ = getDefaultInstance().getRecognitionResult();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only. The debug only recognition result in original language. This field is debug
       * only and will be set to empty string if not available.
       * This is implementation detail and will not be backward compatible.
       * </pre>
       *
       * <code>string recognition_result = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @param value The bytes for recognitionResult to set.
       * @return This builder for chaining.
       */
      public Builder setRecognitionResultBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        recognitionResult_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }

      private java.lang.Object detectedSourceLanguageCode_ = "";
      /**
       * <pre>
       * Output only.
       * </pre>
       *
       * <code>string detected_source_language_code = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The detectedSourceLanguageCode.
       */
      public java.lang.String getDetectedSourceLanguageCode() {
        java.lang.Object ref = detectedSourceLanguageCode_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          detectedSourceLanguageCode_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Output only.
       * </pre>
       *
       * <code>string detected_source_language_code = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The bytes for detectedSourceLanguageCode.
       */
      public com.google.protobuf.ByteString
          getDetectedSourceLanguageCodeBytes() {
        java.lang.Object ref = detectedSourceLanguageCode_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          detectedSourceLanguageCode_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Output only.
       * </pre>
       *
       * <code>string detected_source_language_code = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @param value The detectedSourceLanguageCode to set.
       * @return This builder for chaining.
       */
      public Builder setDetectedSourceLanguageCode(
          java.lang.String value) {
        if (value == null) { throw new NullPointerException(); }
        detectedSourceLanguageCode_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only.
       * </pre>
       *
       * <code>string detected_source_language_code = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return This builder for chaining.
       */
      public Builder clearDetectedSourceLanguageCode() {
        detectedSourceLanguageCode_ = getDefaultInstance().getDetectedSourceLanguageCode();
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only.
       * </pre>
       *
       * <code>string detected_source_language_code = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @param value The bytes for detectedSourceLanguageCode to set.
       * @return This builder for chaining.
       */
      public Builder setDetectedSourceLanguageCodeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        detectedSourceLanguageCode_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult)
    }

    // @@protoc_insertion_point(class_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult)
    private static final com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult();
    }

    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingTranslateSpeechResult>
        PARSER = new com.google.protobuf.AbstractParser<StreamingTranslateSpeechResult>() {
      @java.lang.Override
      public StreamingTranslateSpeechResult parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<StreamingTranslateSpeechResult> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StreamingTranslateSpeechResult> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingTranslateSpeechResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
     * specifies the error for the operation.
     * </pre>
     *
     * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return Whether the error field is set.
     */
    boolean hasError();
    /**
     * <pre>
     * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
     * specifies the error for the operation.
     * </pre>
     *
     * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The error.
     */
    com.google.rpc.Status getError();
    /**
     * <pre>
     * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
     * specifies the error for the operation.
     * </pre>
     *
     * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     */
    com.google.rpc.StatusOrBuilder getErrorOrBuilder();

    /**
     * <pre>
     * Output only. The translation result that is currently being processed (For text
     * translation, `is_final` could be `true` or `false`.
     * For audio translation, we do not have is_final field, which means each
     * audio response is stable and will not get changed later. For
     * text_and_audio, we still have `is_final` field in text translation, but we
     * only output corresponsding audio when `is_final` is true.).
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return Whether the result field is set.
     */
    boolean hasResult();
    /**
     * <pre>
     * Output only. The translation result that is currently being processed (For text
     * translation, `is_final` could be `true` or `false`.
     * For audio translation, we do not have is_final field, which means each
     * audio response is stable and will not get changed later. For
     * text_and_audio, we still have `is_final` field in text translation, but we
     * only output corresponsding audio when `is_final` is true.).
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The result.
     */
    com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult getResult();
    /**
     * <pre>
     * Output only. The translation result that is currently being processed (For text
     * translation, `is_final` could be `true` or `false`.
     * For audio translation, we do not have is_final field, which means each
     * audio response is stable and will not get changed later. For
     * text_and_audio, we still have `is_final` field in text translation, but we
     * only output corresponsding audio when `is_final` is true.).
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     */
    com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResultOrBuilder getResultOrBuilder();

    /**
     * <pre>
     * Output only. Indicates the type of speech event.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse.SpeechEventType speech_event_type = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The enum numeric value on the wire for speechEventType.
     */
    int getSpeechEventTypeValue();
    /**
     * <pre>
     * Output only. Indicates the type of speech event.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse.SpeechEventType speech_event_type = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The speechEventType.
     */
    com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.SpeechEventType getSpeechEventType();
  }
  /**
   * <pre>
   * A streaming speech translation response corresponding to a portion of
   * the audio currently processed.
   * </pre>
   *
   * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse}
   */
  public static final class StreamingTranslateSpeechResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse)
      StreamingTranslateSpeechResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StreamingTranslateSpeechResponse.newBuilder() to construct.
    private StreamingTranslateSpeechResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingTranslateSpeechResponse() {
      speechEventType_ = 0;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new StreamingTranslateSpeechResponse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.Builder.class);
    }

    /**
     * <pre>
     * Indicates the type of speech event.
     * </pre>
     *
     * Protobuf enum {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse.SpeechEventType}
     */
    public enum SpeechEventType
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       * No speech event specified.
       * </pre>
       *
       * <code>SPEECH_EVENT_TYPE_UNSPECIFIED = 0;</code>
       */
      SPEECH_EVENT_TYPE_UNSPECIFIED(0),
      /**
       * <pre>
       * This event indicates that the server has detected the end of the user's
       * speech utterance and expects no additional speech. Therefore, the server
       * will not process additional audio (although it may subsequently return
       * additional results). When the client receives `END_OF_SINGLE_UTTERANCE`
       * event, the client should stop sending the requests. However, clients
       * should keep receiving remaining responses until the stream is terminated.
       * To construct the complete sentence in a streaming way, one should
       * override (if `is_final` of previous response is `false`), or append (if
       * `is_final` of previous response is `true`). This event is only sent if
       * `single_utterance` was set to `true`, and is not used otherwise.
       * </pre>
       *
       * <code>END_OF_SINGLE_UTTERANCE = 1;</code>
       */
      END_OF_SINGLE_UTTERANCE(1),
      UNRECOGNIZED(-1),
      ;

      /**
       * <pre>
       * No speech event specified.
       * </pre>
       *
       * <code>SPEECH_EVENT_TYPE_UNSPECIFIED = 0;</code>
       */
      public static final int SPEECH_EVENT_TYPE_UNSPECIFIED_VALUE = 0;
      /**
       * <pre>
       * This event indicates that the server has detected the end of the user's
       * speech utterance and expects no additional speech. Therefore, the server
       * will not process additional audio (although it may subsequently return
       * additional results). When the client receives `END_OF_SINGLE_UTTERANCE`
       * event, the client should stop sending the requests. However, clients
       * should keep receiving remaining responses until the stream is terminated.
       * To construct the complete sentence in a streaming way, one should
       * override (if `is_final` of previous response is `false`), or append (if
       * `is_final` of previous response is `true`). This event is only sent if
       * `single_utterance` was set to `true`, and is not used otherwise.
       * </pre>
       *
       * <code>END_OF_SINGLE_UTTERANCE = 1;</code>
       */
      public static final int END_OF_SINGLE_UTTERANCE_VALUE = 1;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static SpeechEventType valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static SpeechEventType forNumber(int value) {
        switch (value) {
          case 0: return SPEECH_EVENT_TYPE_UNSPECIFIED;
          case 1: return END_OF_SINGLE_UTTERANCE;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<SpeechEventType>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          SpeechEventType> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<SpeechEventType>() {
              public SpeechEventType findValueByNumber(int number) {
                return SpeechEventType.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalStateException(
              "Can't get the descriptor of an unrecognized enum value.");
        }
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.getDescriptor().getEnumTypes().get(0);
      }

      private static final SpeechEventType[] VALUES = values();

      public static SpeechEventType valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private SpeechEventType(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse.SpeechEventType)
    }

    public static final int ERROR_FIELD_NUMBER = 1;
    private com.google.rpc.Status error_;
    /**
     * <pre>
     * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
     * specifies the error for the operation.
     * </pre>
     *
     * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return Whether the error field is set.
     */
    @java.lang.Override
    public boolean hasError() {
      return error_ != null;
    }
    /**
     * <pre>
     * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
     * specifies the error for the operation.
     * </pre>
     *
     * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The error.
     */
    @java.lang.Override
    public com.google.rpc.Status getError() {
      return error_ == null ? com.google.rpc.Status.getDefaultInstance() : error_;
    }
    /**
     * <pre>
     * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
     * specifies the error for the operation.
     * </pre>
     *
     * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     */
    @java.lang.Override
    public com.google.rpc.StatusOrBuilder getErrorOrBuilder() {
      return error_ == null ? com.google.rpc.Status.getDefaultInstance() : error_;
    }

    public static final int RESULT_FIELD_NUMBER = 2;
    private com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult result_;
    /**
     * <pre>
     * Output only. The translation result that is currently being processed (For text
     * translation, `is_final` could be `true` or `false`.
     * For audio translation, we do not have is_final field, which means each
     * audio response is stable and will not get changed later. For
     * text_and_audio, we still have `is_final` field in text translation, but we
     * only output corresponsding audio when `is_final` is true.).
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return Whether the result field is set.
     */
    @java.lang.Override
    public boolean hasResult() {
      return result_ != null;
    }
    /**
     * <pre>
     * Output only. The translation result that is currently being processed (For text
     * translation, `is_final` could be `true` or `false`.
     * For audio translation, we do not have is_final field, which means each
     * audio response is stable and will not get changed later. For
     * text_and_audio, we still have `is_final` field in text translation, but we
     * only output corresponsding audio when `is_final` is true.).
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The result.
     */
    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult getResult() {
      return result_ == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.getDefaultInstance() : result_;
    }
    /**
     * <pre>
     * Output only. The translation result that is currently being processed (For text
     * translation, `is_final` could be `true` or `false`.
     * For audio translation, we do not have is_final field, which means each
     * audio response is stable and will not get changed later. For
     * text_and_audio, we still have `is_final` field in text translation, but we
     * only output corresponsding audio when `is_final` is true.).
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     */
    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResultOrBuilder getResultOrBuilder() {
      return result_ == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.getDefaultInstance() : result_;
    }

    public static final int SPEECH_EVENT_TYPE_FIELD_NUMBER = 3;
    private int speechEventType_ = 0;
    /**
     * <pre>
     * Output only. Indicates the type of speech event.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse.SpeechEventType speech_event_type = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The enum numeric value on the wire for speechEventType.
     */
    @java.lang.Override public int getSpeechEventTypeValue() {
      return speechEventType_;
    }
    /**
     * <pre>
     * Output only. Indicates the type of speech event.
     * </pre>
     *
     * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse.SpeechEventType speech_event_type = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     * @return The speechEventType.
     */
    @java.lang.Override public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.SpeechEventType getSpeechEventType() {
      com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.SpeechEventType result = com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.SpeechEventType.forNumber(speechEventType_);
      return result == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.SpeechEventType.UNRECOGNIZED : result;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (error_ != null) {
        output.writeMessage(1, getError());
      }
      if (result_ != null) {
        output.writeMessage(2, getResult());
      }
      if (speechEventType_ != com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.SpeechEventType.SPEECH_EVENT_TYPE_UNSPECIFIED.getNumber()) {
        output.writeEnum(3, speechEventType_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (error_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getError());
      }
      if (result_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getResult());
      }
      if (speechEventType_ != com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.SpeechEventType.SPEECH_EVENT_TYPE_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(3, speechEventType_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse)) {
        return super.equals(obj);
      }
      com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse other = (com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse) obj;

      if (hasError() != other.hasError()) return false;
      if (hasError()) {
        if (!getError()
            .equals(other.getError())) return false;
      }
      if (hasResult() != other.hasResult()) return false;
      if (hasResult()) {
        if (!getResult()
            .equals(other.getResult())) return false;
      }
      if (speechEventType_ != other.speechEventType_) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasError()) {
        hash = (37 * hash) + ERROR_FIELD_NUMBER;
        hash = (53 * hash) + getError().hashCode();
      }
      if (hasResult()) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResult().hashCode();
      }
      hash = (37 * hash) + SPEECH_EVENT_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + speechEventType_;
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * A streaming speech translation response corresponding to a portion of
     * the audio currently processed.
     * </pre>
     *
     * Protobuf type {@code google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse)
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResponse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.class, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.Builder.class);
      }

      // Construct using com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        error_ = null;
        if (errorBuilder_ != null) {
          errorBuilder_.dispose();
          errorBuilder_ = null;
        }
        result_ = null;
        if (resultBuilder_ != null) {
          resultBuilder_.dispose();
          resultBuilder_ = null;
        }
        speechEventType_ = 0;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResponse_descriptor;
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse getDefaultInstanceForType() {
        return com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.getDefaultInstance();
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse build() {
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse buildPartial() {
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse result = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.error_ = errorBuilder_ == null
              ? error_
              : errorBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.result_ = resultBuilder_ == null
              ? result_
              : resultBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.speechEventType_ = speechEventType_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse) {
          return mergeFrom((com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse other) {
        if (other == com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.getDefaultInstance()) return this;
        if (other.hasError()) {
          mergeError(other.getError());
        }
        if (other.hasResult()) {
          mergeResult(other.getResult());
        }
        if (other.speechEventType_ != 0) {
          setSpeechEventTypeValue(other.getSpeechEventTypeValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getErrorFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                input.readMessage(
                    getResultFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              case 24: {
                speechEventType_ = input.readEnum();
                bitField0_ |= 0x00000004;
                break;
              } // case 24
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private com.google.rpc.Status error_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.rpc.Status, com.google.rpc.Status.Builder, com.google.rpc.StatusOrBuilder> errorBuilder_;
      /**
       * <pre>
       * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
       * specifies the error for the operation.
       * </pre>
       *
       * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return Whether the error field is set.
       */
      public boolean hasError() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
       * specifies the error for the operation.
       * </pre>
       *
       * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The error.
       */
      public com.google.rpc.Status getError() {
        if (errorBuilder_ == null) {
          return error_ == null ? com.google.rpc.Status.getDefaultInstance() : error_;
        } else {
          return errorBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
       * specifies the error for the operation.
       * </pre>
       *
       * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      public Builder setError(com.google.rpc.Status value) {
        if (errorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          error_ = value;
        } else {
          errorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
       * specifies the error for the operation.
       * </pre>
       *
       * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      public Builder setError(
          com.google.rpc.Status.Builder builderForValue) {
        if (errorBuilder_ == null) {
          error_ = builderForValue.build();
        } else {
          errorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
       * specifies the error for the operation.
       * </pre>
       *
       * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      public Builder mergeError(com.google.rpc.Status value) {
        if (errorBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            error_ != null &&
            error_ != com.google.rpc.Status.getDefaultInstance()) {
            getErrorBuilder().mergeFrom(value);
          } else {
            error_ = value;
          }
        } else {
          errorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
       * specifies the error for the operation.
       * </pre>
       *
       * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      public Builder clearError() {
        bitField0_ = (bitField0_ & ~0x00000001);
        error_ = null;
        if (errorBuilder_ != null) {
          errorBuilder_.dispose();
          errorBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
       * specifies the error for the operation.
       * </pre>
       *
       * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      public com.google.rpc.Status.Builder getErrorBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getErrorFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
       * specifies the error for the operation.
       * </pre>
       *
       * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      public com.google.rpc.StatusOrBuilder getErrorOrBuilder() {
        if (errorBuilder_ != null) {
          return errorBuilder_.getMessageOrBuilder();
        } else {
          return error_ == null ?
              com.google.rpc.Status.getDefaultInstance() : error_;
        }
      }
      /**
       * <pre>
       * Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
       * specifies the error for the operation.
       * </pre>
       *
       * <code>.google.rpc.Status error = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.rpc.Status, com.google.rpc.Status.Builder, com.google.rpc.StatusOrBuilder> 
          getErrorFieldBuilder() {
        if (errorBuilder_ == null) {
          errorBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.rpc.Status, com.google.rpc.Status.Builder, com.google.rpc.StatusOrBuilder>(
                  getError(),
                  getParentForChildren(),
                  isClean());
          error_ = null;
        }
        return errorBuilder_;
      }

      private com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult result_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResultOrBuilder> resultBuilder_;
      /**
       * <pre>
       * Output only. The translation result that is currently being processed (For text
       * translation, `is_final` could be `true` or `false`.
       * For audio translation, we do not have is_final field, which means each
       * audio response is stable and will not get changed later. For
       * text_and_audio, we still have `is_final` field in text translation, but we
       * only output corresponsding audio when `is_final` is true.).
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return Whether the result field is set.
       */
      public boolean hasResult() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * Output only. The translation result that is currently being processed (For text
       * translation, `is_final` could be `true` or `false`.
       * For audio translation, we do not have is_final field, which means each
       * audio response is stable and will not get changed later. For
       * text_and_audio, we still have `is_final` field in text translation, but we
       * only output corresponsding audio when `is_final` is true.).
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The result.
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult getResult() {
        if (resultBuilder_ == null) {
          return result_ == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.getDefaultInstance() : result_;
        } else {
          return resultBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Output only. The translation result that is currently being processed (For text
       * translation, `is_final` could be `true` or `false`.
       * For audio translation, we do not have is_final field, which means each
       * audio response is stable and will not get changed later. For
       * text_and_audio, we still have `is_final` field in text translation, but we
       * only output corresponsding audio when `is_final` is true.).
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      public Builder setResult(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          result_ = value;
        } else {
          resultBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only. The translation result that is currently being processed (For text
       * translation, `is_final` could be `true` or `false`.
       * For audio translation, we do not have is_final field, which means each
       * audio response is stable and will not get changed later. For
       * text_and_audio, we still have `is_final` field in text translation, but we
       * only output corresponsding audio when `is_final` is true.).
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      public Builder setResult(
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.Builder builderForValue) {
        if (resultBuilder_ == null) {
          result_ = builderForValue.build();
        } else {
          resultBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only. The translation result that is currently being processed (For text
       * translation, `is_final` could be `true` or `false`.
       * For audio translation, we do not have is_final field, which means each
       * audio response is stable and will not get changed later. For
       * text_and_audio, we still have `is_final` field in text translation, but we
       * only output corresponsding audio when `is_final` is true.).
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      public Builder mergeResult(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult value) {
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
            result_ != null &&
            result_ != com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.getDefaultInstance()) {
            getResultBuilder().mergeFrom(value);
          } else {
            result_ = value;
          }
        } else {
          resultBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only. The translation result that is currently being processed (For text
       * translation, `is_final` could be `true` or `false`.
       * For audio translation, we do not have is_final field, which means each
       * audio response is stable and will not get changed later. For
       * text_and_audio, we still have `is_final` field in text translation, but we
       * only output corresponsding audio when `is_final` is true.).
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      public Builder clearResult() {
        bitField0_ = (bitField0_ & ~0x00000002);
        result_ = null;
        if (resultBuilder_ != null) {
          resultBuilder_.dispose();
          resultBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only. The translation result that is currently being processed (For text
       * translation, `is_final` could be `true` or `false`.
       * For audio translation, we do not have is_final field, which means each
       * audio response is stable and will not get changed later. For
       * text_and_audio, we still have `is_final` field in text translation, but we
       * only output corresponsding audio when `is_final` is true.).
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.Builder getResultBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getResultFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Output only. The translation result that is currently being processed (For text
       * translation, `is_final` could be `true` or `false`.
       * For audio translation, we do not have is_final field, which means each
       * audio response is stable and will not get changed later. For
       * text_and_audio, we still have `is_final` field in text translation, but we
       * only output corresponsding audio when `is_final` is true.).
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResultOrBuilder getResultOrBuilder() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilder();
        } else {
          return result_ == null ?
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.getDefaultInstance() : result_;
        }
      }
      /**
       * <pre>
       * Output only. The translation result that is currently being processed (For text
       * translation, `is_final` could be `true` or `false`.
       * For audio translation, we do not have is_final field, which means each
       * audio response is stable and will not get changed later. For
       * text_and_audio, we still have `is_final` field in text translation, but we
       * only output corresponsding audio when `is_final` is true.).
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResult result = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResultOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResult.Builder, com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResultOrBuilder>(
                  getResult(),
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }

      private int speechEventType_ = 0;
      /**
       * <pre>
       * Output only. Indicates the type of speech event.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse.SpeechEventType speech_event_type = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The enum numeric value on the wire for speechEventType.
       */
      @java.lang.Override public int getSpeechEventTypeValue() {
        return speechEventType_;
      }
      /**
       * <pre>
       * Output only. Indicates the type of speech event.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse.SpeechEventType speech_event_type = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @param value The enum numeric value on the wire for speechEventType to set.
       * @return This builder for chaining.
       */
      public Builder setSpeechEventTypeValue(int value) {
        speechEventType_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only. Indicates the type of speech event.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse.SpeechEventType speech_event_type = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return The speechEventType.
       */
      @java.lang.Override
      public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.SpeechEventType getSpeechEventType() {
        com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.SpeechEventType result = com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.SpeechEventType.forNumber(speechEventType_);
        return result == null ? com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.SpeechEventType.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Output only. Indicates the type of speech event.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse.SpeechEventType speech_event_type = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @param value The speechEventType to set.
       * @return This builder for chaining.
       */
      public Builder setSpeechEventType(com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse.SpeechEventType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000004;
        speechEventType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Output only. Indicates the type of speech event.
       * </pre>
       *
       * <code>.google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse.SpeechEventType speech_event_type = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       * @return This builder for chaining.
       */
      public Builder clearSpeechEventType() {
        bitField0_ = (bitField0_ & ~0x00000004);
        speechEventType_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse)
    }

    // @@protoc_insertion_point(class_scope:google.cloud.mediatranslation.v1alpha1.StreamingTranslateSpeechResponse)
    private static final com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse();
    }

    public static com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingTranslateSpeechResponse>
        PARSER = new com.google.protobuf.AbstractParser<StreamingTranslateSpeechResponse>() {
      @java.lang.Override
      public StreamingTranslateSpeechResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<StreamingTranslateSpeechResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StreamingTranslateSpeechResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.cloud.mediatranslation.v1alpha1.MediaTranslation.StreamingTranslateSpeechResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_google_cloud_mediatranslation_v1alpha1_TranslateSpeechConfig_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_google_cloud_mediatranslation_v1alpha1_TranslateSpeechConfig_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechConfig_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechConfig_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_TextTranslationResult_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_TextTranslationResult_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_AudioTranslationResult_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_AudioTranslationResult_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResponse_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n>google/cloud/mediatranslation/v1alpha1" +
      "/media_translation.proto\022&google.cloud.m" +
      "ediatranslation.v1alpha1\032\037google/api/fie" +
      "ld_behavior.proto\032\027google/rpc/status.pro" +
      "to\032\027google/api/client.proto\"\336\001\n\025Translat" +
      "eSpeechConfig\022\033\n\016audio_encoding\030\001 \001(\tB\003\340" +
      "A\002\022!\n\024source_language_code\030\002 \001(\tB\003\340A\002\022!\n" +
      "\024target_language_code\030\003 \001(\tB\003\340A\002\022.\n!alte" +
      "rnative_source_language_codes\030\006 \003(\tB\003\340A\001" +
      "\022\036\n\021sample_rate_hertz\030\004 \001(\005B\003\340A\001\022\022\n\005mode" +
      "l\030\005 \001(\tB\003\340A\001\"\366\001\n\036StreamingTranslateSpeec" +
      "hConfig\022X\n\014audio_config\030\001 \001(\0132=.google.c" +
      "loud.mediatranslation.v1alpha1.Translate" +
      "SpeechConfigB\003\340A\002\022\035\n\020single_utterance\030\002 " +
      "\001(\010B\003\340A\001\022\026\n\tstability\030\003 \001(\tB\003\340A\001\022\035\n\020tran" +
      "slation_mode\030\004 \001(\tB\003\340A\001\022$\n\027disable_inter" +
      "im_results\030\005 \001(\010B\003\340A\001\"\263\001\n\037StreamingTrans" +
      "lateSpeechRequest\022b\n\020streaming_config\030\001 " +
      "\001(\0132F.google.cloud.mediatranslation.v1al" +
      "pha1.StreamingTranslateSpeechConfigH\000\022\027\n" +
      "\raudio_content\030\002 \001(\014H\000B\023\n\021streaming_requ" +
      "est\"\361\003\n\036StreamingTranslateSpeechResult\022}" +
      "\n\027text_translation_result\030\001 \001(\0132\\.google" +
      ".cloud.mediatranslation.v1alpha1.Streami" +
      "ngTranslateSpeechResult.TextTranslationR" +
      "esult\022\177\n\030audio_translation_result\030\002 \001(\0132" +
      "].google.cloud.mediatranslation.v1alpha1" +
      ".StreamingTranslateSpeechResult.AudioTra" +
      "nslationResult\022\037\n\022recognition_result\030\003 \001" +
      "(\tB\003\340A\003\022*\n\035detected_source_language_code" +
      "\030\004 \001(\tB\003\340A\003\032H\n\025TextTranslationResult\022\030\n\013" +
      "translation\030\001 \001(\tB\003\340A\003\022\025\n\010is_final\030\002 \001(\010" +
      "B\003\340A\003\0328\n\026AudioTranslationResult\022\036\n\021audio" +
      "_translation\030\001 \001(\014B\003\340A\003\"\364\002\n StreamingTra" +
      "nslateSpeechResponse\022&\n\005error\030\001 \001(\0132\022.go" +
      "ogle.rpc.StatusB\003\340A\003\022[\n\006result\030\002 \001(\0132F.g" +
      "oogle.cloud.mediatranslation.v1alpha1.St" +
      "reamingTranslateSpeechResultB\003\340A\003\022x\n\021spe" +
      "ech_event_type\030\003 \001(\0162X.google.cloud.medi" +
      "atranslation.v1alpha1.StreamingTranslate" +
      "SpeechResponse.SpeechEventTypeB\003\340A\003\"Q\n\017S" +
      "peechEventType\022!\n\035SPEECH_EVENT_TYPE_UNSP" +
      "ECIFIED\020\000\022\033\n\027END_OF_SINGLE_UTTERANCE\020\0012\245" +
      "\002\n\030SpeechTranslationService\022\263\001\n\030Streamin" +
      "gTranslateSpeech\022G.google.cloud.mediatra" +
      "nslation.v1alpha1.StreamingTranslateSpee" +
      "chRequest\032H.google.cloud.mediatranslatio" +
      "n.v1alpha1.StreamingTranslateSpeechRespo" +
      "nse\"\000(\0010\001\032S\312A\037mediatranslation.googleapi" +
      "s.com\322A.https://www.googleapis.com/auth/" +
      "cloud-platformB\207\001\n*com.google.cloud.medi" +
      "atranslation.v1alpha1ZVgoogle.golang.org" +
      "/genproto/googleapis/cloud/mediatranslat" +
      "ion/v1alpha1;mediatranslation\370\001\001b\006proto3"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          com.google.api.FieldBehaviorProto.getDescriptor(),
          com.google.rpc.StatusProto.getDescriptor(),
          com.google.api.ClientProto.getDescriptor(),
        });
    internal_static_google_cloud_mediatranslation_v1alpha1_TranslateSpeechConfig_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_google_cloud_mediatranslation_v1alpha1_TranslateSpeechConfig_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_google_cloud_mediatranslation_v1alpha1_TranslateSpeechConfig_descriptor,
        new java.lang.String[] { "AudioEncoding", "SourceLanguageCode", "TargetLanguageCode", "AlternativeSourceLanguageCodes", "SampleRateHertz", "Model", });
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechConfig_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechConfig_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechConfig_descriptor,
        new java.lang.String[] { "AudioConfig", "SingleUtterance", "Stability", "TranslationMode", "DisableInterimResults", });
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechRequest_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechRequest_descriptor,
        new java.lang.String[] { "StreamingConfig", "AudioContent", "StreamingRequest", });
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_descriptor,
        new java.lang.String[] { "TextTranslationResult", "AudioTranslationResult", "RecognitionResult", "DetectedSourceLanguageCode", });
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_TextTranslationResult_descriptor =
      internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_descriptor.getNestedTypes().get(0);
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_TextTranslationResult_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_TextTranslationResult_descriptor,
        new java.lang.String[] { "Translation", "IsFinal", });
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_AudioTranslationResult_descriptor =
      internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_descriptor.getNestedTypes().get(1);
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_AudioTranslationResult_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResult_AudioTranslationResult_descriptor,
        new java.lang.String[] { "AudioTranslation", });
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResponse_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_google_cloud_mediatranslation_v1alpha1_StreamingTranslateSpeechResponse_descriptor,
        new java.lang.String[] { "Error", "Result", "SpeechEventType", });
    com.google.protobuf.ExtensionRegistry registry =
        com.google.protobuf.ExtensionRegistry.newInstance();
    registry.add(com.google.api.ClientProto.defaultHost);
    registry.add(com.google.api.FieldBehaviorProto.fieldBehavior);
    registry.add(com.google.api.ClientProto.oauthScopes);
    com.google.protobuf.Descriptors.FileDescriptor
        .internalUpdateFileDescriptor(descriptor, registry);
    com.google.api.FieldBehaviorProto.getDescriptor();
    com.google.rpc.StatusProto.getDescriptor();
    com.google.api.ClientProto.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
