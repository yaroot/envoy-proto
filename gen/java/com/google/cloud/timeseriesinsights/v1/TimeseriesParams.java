// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/timeseriesinsights/v1/timeseries_insights.proto

package com.google.cloud.timeseriesinsights.v1;

/**
 * <pre>
 * Parameters that control how we construct the time series for each slice.
 * </pre>
 *
 * Protobuf type {@code google.cloud.timeseriesinsights.v1.TimeseriesParams}
 */
public final class TimeseriesParams extends
    com.google.protobuf.GeneratedMessageV3 implements
    // @@protoc_insertion_point(message_implements:google.cloud.timeseriesinsights.v1.TimeseriesParams)
    TimeseriesParamsOrBuilder {
private static final long serialVersionUID = 0L;
  // Use TimeseriesParams.newBuilder() to construct.
  private TimeseriesParams(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }
  private TimeseriesParams() {
    metric_ = "";
    metricAggregationMethod_ = 0;
  }

  @java.lang.Override
  @SuppressWarnings({"unused"})
  protected java.lang.Object newInstance(
      UnusedPrivateParameter unused) {
    return new TimeseriesParams();
  }

  @java.lang.Override
  public final com.google.protobuf.UnknownFieldSet
  getUnknownFields() {
    return this.unknownFields;
  }
  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return com.google.cloud.timeseriesinsights.v1.TimeseriesInsightsProto.internal_static_google_cloud_timeseriesinsights_v1_TimeseriesParams_descriptor;
  }

  @java.lang.Override
  protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return com.google.cloud.timeseriesinsights.v1.TimeseriesInsightsProto.internal_static_google_cloud_timeseriesinsights_v1_TimeseriesParams_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            com.google.cloud.timeseriesinsights.v1.TimeseriesParams.class, com.google.cloud.timeseriesinsights.v1.TimeseriesParams.Builder.class);
  }

  /**
   * <pre>
   * Methods by which we can aggregate multiple events by a given
   * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric].
   * </pre>
   *
   * Protobuf enum {@code google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod}
   */
  public enum AggregationMethod
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <pre>
     * Unspecified.
     * </pre>
     *
     * <code>AGGREGATION_METHOD_UNSPECIFIED = 0;</code>
     */
    AGGREGATION_METHOD_UNSPECIFIED(0),
    /**
     * <pre>
     * Aggregate multiple events by summing up the values found in the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] dimension.
     * </pre>
     *
     * <code>SUM = 1;</code>
     */
    SUM(1),
    /**
     * <pre>
     * Aggregate multiple events by averaging out the values found in the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] dimension.
     * </pre>
     *
     * <code>AVERAGE = 2;</code>
     */
    AVERAGE(2),
    UNRECOGNIZED(-1),
    ;

    /**
     * <pre>
     * Unspecified.
     * </pre>
     *
     * <code>AGGREGATION_METHOD_UNSPECIFIED = 0;</code>
     */
    public static final int AGGREGATION_METHOD_UNSPECIFIED_VALUE = 0;
    /**
     * <pre>
     * Aggregate multiple events by summing up the values found in the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] dimension.
     * </pre>
     *
     * <code>SUM = 1;</code>
     */
    public static final int SUM_VALUE = 1;
    /**
     * <pre>
     * Aggregate multiple events by averaging out the values found in the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] dimension.
     * </pre>
     *
     * <code>AVERAGE = 2;</code>
     */
    public static final int AVERAGE_VALUE = 2;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static AggregationMethod valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static AggregationMethod forNumber(int value) {
      switch (value) {
        case 0: return AGGREGATION_METHOD_UNSPECIFIED;
        case 1: return SUM;
        case 2: return AVERAGE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<AggregationMethod>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        AggregationMethod> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<AggregationMethod>() {
            public AggregationMethod findValueByNumber(int number) {
              return AggregationMethod.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalStateException(
            "Can't get the descriptor of an unrecognized enum value.");
      }
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return com.google.cloud.timeseriesinsights.v1.TimeseriesParams.getDescriptor().getEnumTypes().get(0);
    }

    private static final AggregationMethod[] VALUES = values();

    public static AggregationMethod valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private AggregationMethod(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod)
  }

  private int bitField0_;
  public static final int FORECAST_HISTORY_FIELD_NUMBER = 1;
  private com.google.protobuf.Duration forecastHistory_;
  /**
   * <pre>
   * Required. How long should we go in the past when fetching the timeline used for
   * forecasting each slice.
   * This is used in combination with the
   * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
   * The time series we construct will have the following time range:
   * `[detectionTime - forecastHistory, detectionTime + granularity]`.
   * The forecast history might be rounded up, so that a multiple of
   * `granularity` is used to process the query.
   * Note: If there are not enough events in the
   * `[detectionTime - forecastHistory, detectionTime + granularity]` time
   * interval, the slice evaluation can fail. For more information, see
   * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
   * </pre>
   *
   * <code>.google.protobuf.Duration forecast_history = 1 [(.google.api.field_behavior) = REQUIRED];</code>
   * @return Whether the forecastHistory field is set.
   */
  @java.lang.Override
  public boolean hasForecastHistory() {
    return forecastHistory_ != null;
  }
  /**
   * <pre>
   * Required. How long should we go in the past when fetching the timeline used for
   * forecasting each slice.
   * This is used in combination with the
   * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
   * The time series we construct will have the following time range:
   * `[detectionTime - forecastHistory, detectionTime + granularity]`.
   * The forecast history might be rounded up, so that a multiple of
   * `granularity` is used to process the query.
   * Note: If there are not enough events in the
   * `[detectionTime - forecastHistory, detectionTime + granularity]` time
   * interval, the slice evaluation can fail. For more information, see
   * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
   * </pre>
   *
   * <code>.google.protobuf.Duration forecast_history = 1 [(.google.api.field_behavior) = REQUIRED];</code>
   * @return The forecastHistory.
   */
  @java.lang.Override
  public com.google.protobuf.Duration getForecastHistory() {
    return forecastHistory_ == null ? com.google.protobuf.Duration.getDefaultInstance() : forecastHistory_;
  }
  /**
   * <pre>
   * Required. How long should we go in the past when fetching the timeline used for
   * forecasting each slice.
   * This is used in combination with the
   * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
   * The time series we construct will have the following time range:
   * `[detectionTime - forecastHistory, detectionTime + granularity]`.
   * The forecast history might be rounded up, so that a multiple of
   * `granularity` is used to process the query.
   * Note: If there are not enough events in the
   * `[detectionTime - forecastHistory, detectionTime + granularity]` time
   * interval, the slice evaluation can fail. For more information, see
   * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
   * </pre>
   *
   * <code>.google.protobuf.Duration forecast_history = 1 [(.google.api.field_behavior) = REQUIRED];</code>
   */
  @java.lang.Override
  public com.google.protobuf.DurationOrBuilder getForecastHistoryOrBuilder() {
    return forecastHistory_ == null ? com.google.protobuf.Duration.getDefaultInstance() : forecastHistory_;
  }

  public static final int GRANULARITY_FIELD_NUMBER = 2;
  private com.google.protobuf.Duration granularity_;
  /**
   * <pre>
   * Required. The time granularity of the time series (on the x-axis). Each time series
   * point starting at time T will aggregate all events for a particular slice
   * in *[T, T + granularity)* time windows.
   * Note: The aggregation is decided based on the
   * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
   * This granularity defines the query-time aggregation windows and is not
   * necessarily related to any event time granularity in the raw data (though
   * we do recommend that the query-time granularity is not finer than the
   * ingestion-time one).
   * Currently, the minimal supported granularity is 10 seconds.
   * </pre>
   *
   * <code>.google.protobuf.Duration granularity = 2 [(.google.api.field_behavior) = REQUIRED];</code>
   * @return Whether the granularity field is set.
   */
  @java.lang.Override
  public boolean hasGranularity() {
    return granularity_ != null;
  }
  /**
   * <pre>
   * Required. The time granularity of the time series (on the x-axis). Each time series
   * point starting at time T will aggregate all events for a particular slice
   * in *[T, T + granularity)* time windows.
   * Note: The aggregation is decided based on the
   * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
   * This granularity defines the query-time aggregation windows and is not
   * necessarily related to any event time granularity in the raw data (though
   * we do recommend that the query-time granularity is not finer than the
   * ingestion-time one).
   * Currently, the minimal supported granularity is 10 seconds.
   * </pre>
   *
   * <code>.google.protobuf.Duration granularity = 2 [(.google.api.field_behavior) = REQUIRED];</code>
   * @return The granularity.
   */
  @java.lang.Override
  public com.google.protobuf.Duration getGranularity() {
    return granularity_ == null ? com.google.protobuf.Duration.getDefaultInstance() : granularity_;
  }
  /**
   * <pre>
   * Required. The time granularity of the time series (on the x-axis). Each time series
   * point starting at time T will aggregate all events for a particular slice
   * in *[T, T + granularity)* time windows.
   * Note: The aggregation is decided based on the
   * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
   * This granularity defines the query-time aggregation windows and is not
   * necessarily related to any event time granularity in the raw data (though
   * we do recommend that the query-time granularity is not finer than the
   * ingestion-time one).
   * Currently, the minimal supported granularity is 10 seconds.
   * </pre>
   *
   * <code>.google.protobuf.Duration granularity = 2 [(.google.api.field_behavior) = REQUIRED];</code>
   */
  @java.lang.Override
  public com.google.protobuf.DurationOrBuilder getGranularityOrBuilder() {
    return granularity_ == null ? com.google.protobuf.Duration.getDefaultInstance() : granularity_;
  }

  public static final int METRIC_FIELD_NUMBER = 4;
  @SuppressWarnings("serial")
  private volatile java.lang.Object metric_ = "";
  /**
   * <pre>
   * Optional. Denotes the [name][google.cloud.timeseriesinsights.v1.EventDimension.name] of a numerical
   * dimension that will have its values aggregated to compute the y-axis of the
   * time series.
   * The aggregation method must also be specified by setting the
   * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
   * field.
   * Note: Currently, if the aggregation method is unspecified, we will
   * default to SUM for backward compatibility reasons, but new implementations
   * should set the
   * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
   * explicitly.
   * If the metric is unspecified, we will use the number of events that each
   * time series point contains as the point value.
   * Example: Let's assume we have the following three events in our dataset:
   * ```json
   * {
   *   eventTime: "2020-12-27T00:00:00Z",
   *   dimensions: [
   *     { name: "d1" stringVal: "v1" },
   *     { name: "d2" stringVal: "v2" }
   *     { name: "m1" longVal: 100 }
   *     { name: "m2" longVal: 11 }
   *   ]
   * },
   * {
   *   eventTime: "2020-12-27T00:10:00Z",
   *   dimensions: [
   *     { name: "d1" stringVal: "v1" },
   *     { name: "d2" stringVal: "v2" }
   *     { name: "m1" longVal: 200 }
   *     { name: "m2" longVal: 22 }
   *   ]
   * },
   * {
   *   eventTime: "2020-12-27T00:20:00Z",
   *   dimensions: [
   *     { name: "d1" stringVal: "v1" },
   *     { name: "d2" stringVal: "v2" }
   *     { name: "m1" longVal: 300 }
   *     { name: "m2" longVal: 33 }
   *   ]
   * }
   * ```
   * These events are all within the same hour, spaced 10 minutes between each
   * of them. Assuming our [QueryDataSetRequest][google.cloud.timeseriesinsights.v1.QueryDataSetRequest] had set
   * [slicingParams.dimensionNames][google.cloud.timeseriesinsights.v1.SlicingParams.dimension_names] to ["d1",
   * "d2"] and [timeseries_params.granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity] to
   * "3600s", then all the previous events will be aggregated into the same
   * [timeseries point][google.cloud.timeseriesinsights.v1.TimeseriesPoint].
   * The time series point that they're all part of will have the
   * [time][google.cloud.timeseriesinsights.v1.TimeseriesPoint.time] set to "2020-12-27T00:00:00Z" and the
   * [value][google.cloud.timeseriesinsights.v1.TimeseriesPoint.value] populated based on this metric field:
   * - If the metric is set to "m1" and metric_aggregation_method to SUM, then
   * the value of the point will be 600.
   * - If the metric is set to "m2" and metric_aggregation_method to SUM, then
   * the value of the point will be 66.
   * - If the metric is set to "m1" and metric_aggregation_method to AVERAGE,
   * then the value of the point will be 200.
   * - If the metric is set to "m2" and metric_aggregation_method to AVERAGE,
   * then the value of the point will be 22.
   * - If the metric field is "" or unspecified, then the value of the point
   * will be 3, as we will simply count the events.
   * </pre>
   *
   * <code>optional string metric = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
   * @return Whether the metric field is set.
   */
  @java.lang.Override
  public boolean hasMetric() {
    return ((bitField0_ & 0x00000001) != 0);
  }
  /**
   * <pre>
   * Optional. Denotes the [name][google.cloud.timeseriesinsights.v1.EventDimension.name] of a numerical
   * dimension that will have its values aggregated to compute the y-axis of the
   * time series.
   * The aggregation method must also be specified by setting the
   * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
   * field.
   * Note: Currently, if the aggregation method is unspecified, we will
   * default to SUM for backward compatibility reasons, but new implementations
   * should set the
   * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
   * explicitly.
   * If the metric is unspecified, we will use the number of events that each
   * time series point contains as the point value.
   * Example: Let's assume we have the following three events in our dataset:
   * ```json
   * {
   *   eventTime: "2020-12-27T00:00:00Z",
   *   dimensions: [
   *     { name: "d1" stringVal: "v1" },
   *     { name: "d2" stringVal: "v2" }
   *     { name: "m1" longVal: 100 }
   *     { name: "m2" longVal: 11 }
   *   ]
   * },
   * {
   *   eventTime: "2020-12-27T00:10:00Z",
   *   dimensions: [
   *     { name: "d1" stringVal: "v1" },
   *     { name: "d2" stringVal: "v2" }
   *     { name: "m1" longVal: 200 }
   *     { name: "m2" longVal: 22 }
   *   ]
   * },
   * {
   *   eventTime: "2020-12-27T00:20:00Z",
   *   dimensions: [
   *     { name: "d1" stringVal: "v1" },
   *     { name: "d2" stringVal: "v2" }
   *     { name: "m1" longVal: 300 }
   *     { name: "m2" longVal: 33 }
   *   ]
   * }
   * ```
   * These events are all within the same hour, spaced 10 minutes between each
   * of them. Assuming our [QueryDataSetRequest][google.cloud.timeseriesinsights.v1.QueryDataSetRequest] had set
   * [slicingParams.dimensionNames][google.cloud.timeseriesinsights.v1.SlicingParams.dimension_names] to ["d1",
   * "d2"] and [timeseries_params.granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity] to
   * "3600s", then all the previous events will be aggregated into the same
   * [timeseries point][google.cloud.timeseriesinsights.v1.TimeseriesPoint].
   * The time series point that they're all part of will have the
   * [time][google.cloud.timeseriesinsights.v1.TimeseriesPoint.time] set to "2020-12-27T00:00:00Z" and the
   * [value][google.cloud.timeseriesinsights.v1.TimeseriesPoint.value] populated based on this metric field:
   * - If the metric is set to "m1" and metric_aggregation_method to SUM, then
   * the value of the point will be 600.
   * - If the metric is set to "m2" and metric_aggregation_method to SUM, then
   * the value of the point will be 66.
   * - If the metric is set to "m1" and metric_aggregation_method to AVERAGE,
   * then the value of the point will be 200.
   * - If the metric is set to "m2" and metric_aggregation_method to AVERAGE,
   * then the value of the point will be 22.
   * - If the metric field is "" or unspecified, then the value of the point
   * will be 3, as we will simply count the events.
   * </pre>
   *
   * <code>optional string metric = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
   * @return The metric.
   */
  @java.lang.Override
  public java.lang.String getMetric() {
    java.lang.Object ref = metric_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      metric_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * Optional. Denotes the [name][google.cloud.timeseriesinsights.v1.EventDimension.name] of a numerical
   * dimension that will have its values aggregated to compute the y-axis of the
   * time series.
   * The aggregation method must also be specified by setting the
   * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
   * field.
   * Note: Currently, if the aggregation method is unspecified, we will
   * default to SUM for backward compatibility reasons, but new implementations
   * should set the
   * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
   * explicitly.
   * If the metric is unspecified, we will use the number of events that each
   * time series point contains as the point value.
   * Example: Let's assume we have the following three events in our dataset:
   * ```json
   * {
   *   eventTime: "2020-12-27T00:00:00Z",
   *   dimensions: [
   *     { name: "d1" stringVal: "v1" },
   *     { name: "d2" stringVal: "v2" }
   *     { name: "m1" longVal: 100 }
   *     { name: "m2" longVal: 11 }
   *   ]
   * },
   * {
   *   eventTime: "2020-12-27T00:10:00Z",
   *   dimensions: [
   *     { name: "d1" stringVal: "v1" },
   *     { name: "d2" stringVal: "v2" }
   *     { name: "m1" longVal: 200 }
   *     { name: "m2" longVal: 22 }
   *   ]
   * },
   * {
   *   eventTime: "2020-12-27T00:20:00Z",
   *   dimensions: [
   *     { name: "d1" stringVal: "v1" },
   *     { name: "d2" stringVal: "v2" }
   *     { name: "m1" longVal: 300 }
   *     { name: "m2" longVal: 33 }
   *   ]
   * }
   * ```
   * These events are all within the same hour, spaced 10 minutes between each
   * of them. Assuming our [QueryDataSetRequest][google.cloud.timeseriesinsights.v1.QueryDataSetRequest] had set
   * [slicingParams.dimensionNames][google.cloud.timeseriesinsights.v1.SlicingParams.dimension_names] to ["d1",
   * "d2"] and [timeseries_params.granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity] to
   * "3600s", then all the previous events will be aggregated into the same
   * [timeseries point][google.cloud.timeseriesinsights.v1.TimeseriesPoint].
   * The time series point that they're all part of will have the
   * [time][google.cloud.timeseriesinsights.v1.TimeseriesPoint.time] set to "2020-12-27T00:00:00Z" and the
   * [value][google.cloud.timeseriesinsights.v1.TimeseriesPoint.value] populated based on this metric field:
   * - If the metric is set to "m1" and metric_aggregation_method to SUM, then
   * the value of the point will be 600.
   * - If the metric is set to "m2" and metric_aggregation_method to SUM, then
   * the value of the point will be 66.
   * - If the metric is set to "m1" and metric_aggregation_method to AVERAGE,
   * then the value of the point will be 200.
   * - If the metric is set to "m2" and metric_aggregation_method to AVERAGE,
   * then the value of the point will be 22.
   * - If the metric field is "" or unspecified, then the value of the point
   * will be 3, as we will simply count the events.
   * </pre>
   *
   * <code>optional string metric = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
   * @return The bytes for metric.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString
      getMetricBytes() {
    java.lang.Object ref = metric_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      metric_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int METRIC_AGGREGATION_METHOD_FIELD_NUMBER = 5;
  private int metricAggregationMethod_ = 0;
  /**
   * <pre>
   * Optional. Together with the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] field, specifies how
   * we will aggregate multiple events to obtain the value of a time series
   * point. See the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] documentation for more
   * details.
   * If the metric is not specified or "", then this field will be ignored.
   * </pre>
   *
   * <code>.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod metric_aggregation_method = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
   * @return The enum numeric value on the wire for metricAggregationMethod.
   */
  @java.lang.Override public int getMetricAggregationMethodValue() {
    return metricAggregationMethod_;
  }
  /**
   * <pre>
   * Optional. Together with the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] field, specifies how
   * we will aggregate multiple events to obtain the value of a time series
   * point. See the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] documentation for more
   * details.
   * If the metric is not specified or "", then this field will be ignored.
   * </pre>
   *
   * <code>.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod metric_aggregation_method = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
   * @return The metricAggregationMethod.
   */
  @java.lang.Override public com.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod getMetricAggregationMethod() {
    com.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod result = com.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod.forNumber(metricAggregationMethod_);
    return result == null ? com.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod.UNRECOGNIZED : result;
  }

  private byte memoizedIsInitialized = -1;
  @java.lang.Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  @java.lang.Override
  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (forecastHistory_ != null) {
      output.writeMessage(1, getForecastHistory());
    }
    if (granularity_ != null) {
      output.writeMessage(2, getGranularity());
    }
    if (((bitField0_ & 0x00000001) != 0)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 4, metric_);
    }
    if (metricAggregationMethod_ != com.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod.AGGREGATION_METHOD_UNSPECIFIED.getNumber()) {
      output.writeEnum(5, metricAggregationMethod_);
    }
    getUnknownFields().writeTo(output);
  }

  @java.lang.Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (forecastHistory_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(1, getForecastHistory());
    }
    if (granularity_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(2, getGranularity());
    }
    if (((bitField0_ & 0x00000001) != 0)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, metric_);
    }
    if (metricAggregationMethod_ != com.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod.AGGREGATION_METHOD_UNSPECIFIED.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(5, metricAggregationMethod_);
    }
    size += getUnknownFields().getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
     return true;
    }
    if (!(obj instanceof com.google.cloud.timeseriesinsights.v1.TimeseriesParams)) {
      return super.equals(obj);
    }
    com.google.cloud.timeseriesinsights.v1.TimeseriesParams other = (com.google.cloud.timeseriesinsights.v1.TimeseriesParams) obj;

    if (hasForecastHistory() != other.hasForecastHistory()) return false;
    if (hasForecastHistory()) {
      if (!getForecastHistory()
          .equals(other.getForecastHistory())) return false;
    }
    if (hasGranularity() != other.hasGranularity()) return false;
    if (hasGranularity()) {
      if (!getGranularity()
          .equals(other.getGranularity())) return false;
    }
    if (hasMetric() != other.hasMetric()) return false;
    if (hasMetric()) {
      if (!getMetric()
          .equals(other.getMetric())) return false;
    }
    if (metricAggregationMethod_ != other.metricAggregationMethod_) return false;
    if (!getUnknownFields().equals(other.getUnknownFields())) return false;
    return true;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    if (hasForecastHistory()) {
      hash = (37 * hash) + FORECAST_HISTORY_FIELD_NUMBER;
      hash = (53 * hash) + getForecastHistory().hashCode();
    }
    if (hasGranularity()) {
      hash = (37 * hash) + GRANULARITY_FIELD_NUMBER;
      hash = (53 * hash) + getGranularity().hashCode();
    }
    if (hasMetric()) {
      hash = (37 * hash) + METRIC_FIELD_NUMBER;
      hash = (53 * hash) + getMetric().hashCode();
    }
    hash = (37 * hash) + METRIC_AGGREGATION_METHOD_FIELD_NUMBER;
    hash = (53 * hash) + metricAggregationMethod_;
    hash = (29 * hash) + getUnknownFields().hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams parseFrom(
      java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams parseFrom(
      java.nio.ByteBuffer data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }
  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input);
  }
  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  @java.lang.Override
  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(com.google.cloud.timeseriesinsights.v1.TimeseriesParams prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  @java.lang.Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(
      com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * <pre>
   * Parameters that control how we construct the time series for each slice.
   * </pre>
   *
   * Protobuf type {@code google.cloud.timeseriesinsights.v1.TimeseriesParams}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:google.cloud.timeseriesinsights.v1.TimeseriesParams)
      com.google.cloud.timeseriesinsights.v1.TimeseriesParamsOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.google.cloud.timeseriesinsights.v1.TimeseriesInsightsProto.internal_static_google_cloud_timeseriesinsights_v1_TimeseriesParams_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.timeseriesinsights.v1.TimeseriesInsightsProto.internal_static_google_cloud_timeseriesinsights_v1_TimeseriesParams_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.timeseriesinsights.v1.TimeseriesParams.class, com.google.cloud.timeseriesinsights.v1.TimeseriesParams.Builder.class);
    }

    // Construct using com.google.cloud.timeseriesinsights.v1.TimeseriesParams.newBuilder()
    private Builder() {

    }

    private Builder(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      super(parent);

    }
    @java.lang.Override
    public Builder clear() {
      super.clear();
      bitField0_ = 0;
      forecastHistory_ = null;
      if (forecastHistoryBuilder_ != null) {
        forecastHistoryBuilder_.dispose();
        forecastHistoryBuilder_ = null;
      }
      granularity_ = null;
      if (granularityBuilder_ != null) {
        granularityBuilder_.dispose();
        granularityBuilder_ = null;
      }
      metric_ = "";
      metricAggregationMethod_ = 0;
      return this;
    }

    @java.lang.Override
    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return com.google.cloud.timeseriesinsights.v1.TimeseriesInsightsProto.internal_static_google_cloud_timeseriesinsights_v1_TimeseriesParams_descriptor;
    }

    @java.lang.Override
    public com.google.cloud.timeseriesinsights.v1.TimeseriesParams getDefaultInstanceForType() {
      return com.google.cloud.timeseriesinsights.v1.TimeseriesParams.getDefaultInstance();
    }

    @java.lang.Override
    public com.google.cloud.timeseriesinsights.v1.TimeseriesParams build() {
      com.google.cloud.timeseriesinsights.v1.TimeseriesParams result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @java.lang.Override
    public com.google.cloud.timeseriesinsights.v1.TimeseriesParams buildPartial() {
      com.google.cloud.timeseriesinsights.v1.TimeseriesParams result = new com.google.cloud.timeseriesinsights.v1.TimeseriesParams(this);
      if (bitField0_ != 0) { buildPartial0(result); }
      onBuilt();
      return result;
    }

    private void buildPartial0(com.google.cloud.timeseriesinsights.v1.TimeseriesParams result) {
      int from_bitField0_ = bitField0_;
      if (((from_bitField0_ & 0x00000001) != 0)) {
        result.forecastHistory_ = forecastHistoryBuilder_ == null
            ? forecastHistory_
            : forecastHistoryBuilder_.build();
      }
      if (((from_bitField0_ & 0x00000002) != 0)) {
        result.granularity_ = granularityBuilder_ == null
            ? granularity_
            : granularityBuilder_.build();
      }
      int to_bitField0_ = 0;
      if (((from_bitField0_ & 0x00000004) != 0)) {
        result.metric_ = metric_;
        to_bitField0_ |= 0x00000001;
      }
      if (((from_bitField0_ & 0x00000008) != 0)) {
        result.metricAggregationMethod_ = metricAggregationMethod_;
      }
      result.bitField0_ |= to_bitField0_;
    }

    @java.lang.Override
    public Builder clone() {
      return super.clone();
    }
    @java.lang.Override
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return super.setField(field, value);
    }
    @java.lang.Override
    public Builder clearField(
        com.google.protobuf.Descriptors.FieldDescriptor field) {
      return super.clearField(field);
    }
    @java.lang.Override
    public Builder clearOneof(
        com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return super.clearOneof(oneof);
    }
    @java.lang.Override
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        int index, java.lang.Object value) {
      return super.setRepeatedField(field, index, value);
    }
    @java.lang.Override
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return super.addRepeatedField(field, value);
    }
    @java.lang.Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof com.google.cloud.timeseriesinsights.v1.TimeseriesParams) {
        return mergeFrom((com.google.cloud.timeseriesinsights.v1.TimeseriesParams)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(com.google.cloud.timeseriesinsights.v1.TimeseriesParams other) {
      if (other == com.google.cloud.timeseriesinsights.v1.TimeseriesParams.getDefaultInstance()) return this;
      if (other.hasForecastHistory()) {
        mergeForecastHistory(other.getForecastHistory());
      }
      if (other.hasGranularity()) {
        mergeGranularity(other.getGranularity());
      }
      if (other.hasMetric()) {
        metric_ = other.metric_;
        bitField0_ |= 0x00000004;
        onChanged();
      }
      if (other.metricAggregationMethod_ != 0) {
        setMetricAggregationMethodValue(other.getMetricAggregationMethodValue());
      }
      this.mergeUnknownFields(other.getUnknownFields());
      onChanged();
      return this;
    }

    @java.lang.Override
    public final boolean isInitialized() {
      return true;
    }

    @java.lang.Override
    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              input.readMessage(
                  getForecastHistoryFieldBuilder().getBuilder(),
                  extensionRegistry);
              bitField0_ |= 0x00000001;
              break;
            } // case 10
            case 18: {
              input.readMessage(
                  getGranularityFieldBuilder().getBuilder(),
                  extensionRegistry);
              bitField0_ |= 0x00000002;
              break;
            } // case 18
            case 34: {
              metric_ = input.readStringRequireUtf8();
              bitField0_ |= 0x00000004;
              break;
            } // case 34
            case 40: {
              metricAggregationMethod_ = input.readEnum();
              bitField0_ |= 0x00000008;
              break;
            } // case 40
            default: {
              if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                done = true; // was an endgroup tag
              }
              break;
            } // default:
          } // switch (tag)
        } // while (!done)
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.unwrapIOException();
      } finally {
        onChanged();
      } // finally
      return this;
    }
    private int bitField0_;

    private com.google.protobuf.Duration forecastHistory_;
    private com.google.protobuf.SingleFieldBuilderV3<
        com.google.protobuf.Duration, com.google.protobuf.Duration.Builder, com.google.protobuf.DurationOrBuilder> forecastHistoryBuilder_;
    /**
     * <pre>
     * Required. How long should we go in the past when fetching the timeline used for
     * forecasting each slice.
     * This is used in combination with the
     * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
     * The time series we construct will have the following time range:
     * `[detectionTime - forecastHistory, detectionTime + granularity]`.
     * The forecast history might be rounded up, so that a multiple of
     * `granularity` is used to process the query.
     * Note: If there are not enough events in the
     * `[detectionTime - forecastHistory, detectionTime + granularity]` time
     * interval, the slice evaluation can fail. For more information, see
     * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
     * </pre>
     *
     * <code>.google.protobuf.Duration forecast_history = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return Whether the forecastHistory field is set.
     */
    public boolean hasForecastHistory() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * Required. How long should we go in the past when fetching the timeline used for
     * forecasting each slice.
     * This is used in combination with the
     * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
     * The time series we construct will have the following time range:
     * `[detectionTime - forecastHistory, detectionTime + granularity]`.
     * The forecast history might be rounded up, so that a multiple of
     * `granularity` is used to process the query.
     * Note: If there are not enough events in the
     * `[detectionTime - forecastHistory, detectionTime + granularity]` time
     * interval, the slice evaluation can fail. For more information, see
     * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
     * </pre>
     *
     * <code>.google.protobuf.Duration forecast_history = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The forecastHistory.
     */
    public com.google.protobuf.Duration getForecastHistory() {
      if (forecastHistoryBuilder_ == null) {
        return forecastHistory_ == null ? com.google.protobuf.Duration.getDefaultInstance() : forecastHistory_;
      } else {
        return forecastHistoryBuilder_.getMessage();
      }
    }
    /**
     * <pre>
     * Required. How long should we go in the past when fetching the timeline used for
     * forecasting each slice.
     * This is used in combination with the
     * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
     * The time series we construct will have the following time range:
     * `[detectionTime - forecastHistory, detectionTime + granularity]`.
     * The forecast history might be rounded up, so that a multiple of
     * `granularity` is used to process the query.
     * Note: If there are not enough events in the
     * `[detectionTime - forecastHistory, detectionTime + granularity]` time
     * interval, the slice evaluation can fail. For more information, see
     * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
     * </pre>
     *
     * <code>.google.protobuf.Duration forecast_history = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public Builder setForecastHistory(com.google.protobuf.Duration value) {
      if (forecastHistoryBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        forecastHistory_ = value;
      } else {
        forecastHistoryBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Required. How long should we go in the past when fetching the timeline used for
     * forecasting each slice.
     * This is used in combination with the
     * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
     * The time series we construct will have the following time range:
     * `[detectionTime - forecastHistory, detectionTime + granularity]`.
     * The forecast history might be rounded up, so that a multiple of
     * `granularity` is used to process the query.
     * Note: If there are not enough events in the
     * `[detectionTime - forecastHistory, detectionTime + granularity]` time
     * interval, the slice evaluation can fail. For more information, see
     * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
     * </pre>
     *
     * <code>.google.protobuf.Duration forecast_history = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public Builder setForecastHistory(
        com.google.protobuf.Duration.Builder builderForValue) {
      if (forecastHistoryBuilder_ == null) {
        forecastHistory_ = builderForValue.build();
      } else {
        forecastHistoryBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Required. How long should we go in the past when fetching the timeline used for
     * forecasting each slice.
     * This is used in combination with the
     * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
     * The time series we construct will have the following time range:
     * `[detectionTime - forecastHistory, detectionTime + granularity]`.
     * The forecast history might be rounded up, so that a multiple of
     * `granularity` is used to process the query.
     * Note: If there are not enough events in the
     * `[detectionTime - forecastHistory, detectionTime + granularity]` time
     * interval, the slice evaluation can fail. For more information, see
     * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
     * </pre>
     *
     * <code>.google.protobuf.Duration forecast_history = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public Builder mergeForecastHistory(com.google.protobuf.Duration value) {
      if (forecastHistoryBuilder_ == null) {
        if (((bitField0_ & 0x00000001) != 0) &&
          forecastHistory_ != null &&
          forecastHistory_ != com.google.protobuf.Duration.getDefaultInstance()) {
          getForecastHistoryBuilder().mergeFrom(value);
        } else {
          forecastHistory_ = value;
        }
      } else {
        forecastHistoryBuilder_.mergeFrom(value);
      }
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Required. How long should we go in the past when fetching the timeline used for
     * forecasting each slice.
     * This is used in combination with the
     * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
     * The time series we construct will have the following time range:
     * `[detectionTime - forecastHistory, detectionTime + granularity]`.
     * The forecast history might be rounded up, so that a multiple of
     * `granularity` is used to process the query.
     * Note: If there are not enough events in the
     * `[detectionTime - forecastHistory, detectionTime + granularity]` time
     * interval, the slice evaluation can fail. For more information, see
     * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
     * </pre>
     *
     * <code>.google.protobuf.Duration forecast_history = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public Builder clearForecastHistory() {
      bitField0_ = (bitField0_ & ~0x00000001);
      forecastHistory_ = null;
      if (forecastHistoryBuilder_ != null) {
        forecastHistoryBuilder_.dispose();
        forecastHistoryBuilder_ = null;
      }
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Required. How long should we go in the past when fetching the timeline used for
     * forecasting each slice.
     * This is used in combination with the
     * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
     * The time series we construct will have the following time range:
     * `[detectionTime - forecastHistory, detectionTime + granularity]`.
     * The forecast history might be rounded up, so that a multiple of
     * `granularity` is used to process the query.
     * Note: If there are not enough events in the
     * `[detectionTime - forecastHistory, detectionTime + granularity]` time
     * interval, the slice evaluation can fail. For more information, see
     * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
     * </pre>
     *
     * <code>.google.protobuf.Duration forecast_history = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public com.google.protobuf.Duration.Builder getForecastHistoryBuilder() {
      bitField0_ |= 0x00000001;
      onChanged();
      return getForecastHistoryFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * Required. How long should we go in the past when fetching the timeline used for
     * forecasting each slice.
     * This is used in combination with the
     * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
     * The time series we construct will have the following time range:
     * `[detectionTime - forecastHistory, detectionTime + granularity]`.
     * The forecast history might be rounded up, so that a multiple of
     * `granularity` is used to process the query.
     * Note: If there are not enough events in the
     * `[detectionTime - forecastHistory, detectionTime + granularity]` time
     * interval, the slice evaluation can fail. For more information, see
     * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
     * </pre>
     *
     * <code>.google.protobuf.Duration forecast_history = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public com.google.protobuf.DurationOrBuilder getForecastHistoryOrBuilder() {
      if (forecastHistoryBuilder_ != null) {
        return forecastHistoryBuilder_.getMessageOrBuilder();
      } else {
        return forecastHistory_ == null ?
            com.google.protobuf.Duration.getDefaultInstance() : forecastHistory_;
      }
    }
    /**
     * <pre>
     * Required. How long should we go in the past when fetching the timeline used for
     * forecasting each slice.
     * This is used in combination with the
     * [detectionTime][google.cloud.timeseriesinsights.v1.QueryDataSetRequest.detection_time] parameter.
     * The time series we construct will have the following time range:
     * `[detectionTime - forecastHistory, detectionTime + granularity]`.
     * The forecast history might be rounded up, so that a multiple of
     * `granularity` is used to process the query.
     * Note: If there are not enough events in the
     * `[detectionTime - forecastHistory, detectionTime + granularity]` time
     * interval, the slice evaluation can fail. For more information, see
     * [EvaluatedSlice.status][google.cloud.timeseriesinsights.v1.EvaluatedSlice.status].
     * </pre>
     *
     * <code>.google.protobuf.Duration forecast_history = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        com.google.protobuf.Duration, com.google.protobuf.Duration.Builder, com.google.protobuf.DurationOrBuilder> 
        getForecastHistoryFieldBuilder() {
      if (forecastHistoryBuilder_ == null) {
        forecastHistoryBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            com.google.protobuf.Duration, com.google.protobuf.Duration.Builder, com.google.protobuf.DurationOrBuilder>(
                getForecastHistory(),
                getParentForChildren(),
                isClean());
        forecastHistory_ = null;
      }
      return forecastHistoryBuilder_;
    }

    private com.google.protobuf.Duration granularity_;
    private com.google.protobuf.SingleFieldBuilderV3<
        com.google.protobuf.Duration, com.google.protobuf.Duration.Builder, com.google.protobuf.DurationOrBuilder> granularityBuilder_;
    /**
     * <pre>
     * Required. The time granularity of the time series (on the x-axis). Each time series
     * point starting at time T will aggregate all events for a particular slice
     * in *[T, T + granularity)* time windows.
     * Note: The aggregation is decided based on the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
     * This granularity defines the query-time aggregation windows and is not
     * necessarily related to any event time granularity in the raw data (though
     * we do recommend that the query-time granularity is not finer than the
     * ingestion-time one).
     * Currently, the minimal supported granularity is 10 seconds.
     * </pre>
     *
     * <code>.google.protobuf.Duration granularity = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return Whether the granularity field is set.
     */
    public boolean hasGranularity() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * Required. The time granularity of the time series (on the x-axis). Each time series
     * point starting at time T will aggregate all events for a particular slice
     * in *[T, T + granularity)* time windows.
     * Note: The aggregation is decided based on the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
     * This granularity defines the query-time aggregation windows and is not
     * necessarily related to any event time granularity in the raw data (though
     * we do recommend that the query-time granularity is not finer than the
     * ingestion-time one).
     * Currently, the minimal supported granularity is 10 seconds.
     * </pre>
     *
     * <code>.google.protobuf.Duration granularity = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     * @return The granularity.
     */
    public com.google.protobuf.Duration getGranularity() {
      if (granularityBuilder_ == null) {
        return granularity_ == null ? com.google.protobuf.Duration.getDefaultInstance() : granularity_;
      } else {
        return granularityBuilder_.getMessage();
      }
    }
    /**
     * <pre>
     * Required. The time granularity of the time series (on the x-axis). Each time series
     * point starting at time T will aggregate all events for a particular slice
     * in *[T, T + granularity)* time windows.
     * Note: The aggregation is decided based on the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
     * This granularity defines the query-time aggregation windows and is not
     * necessarily related to any event time granularity in the raw data (though
     * we do recommend that the query-time granularity is not finer than the
     * ingestion-time one).
     * Currently, the minimal supported granularity is 10 seconds.
     * </pre>
     *
     * <code>.google.protobuf.Duration granularity = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public Builder setGranularity(com.google.protobuf.Duration value) {
      if (granularityBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        granularity_ = value;
      } else {
        granularityBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Required. The time granularity of the time series (on the x-axis). Each time series
     * point starting at time T will aggregate all events for a particular slice
     * in *[T, T + granularity)* time windows.
     * Note: The aggregation is decided based on the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
     * This granularity defines the query-time aggregation windows and is not
     * necessarily related to any event time granularity in the raw data (though
     * we do recommend that the query-time granularity is not finer than the
     * ingestion-time one).
     * Currently, the minimal supported granularity is 10 seconds.
     * </pre>
     *
     * <code>.google.protobuf.Duration granularity = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public Builder setGranularity(
        com.google.protobuf.Duration.Builder builderForValue) {
      if (granularityBuilder_ == null) {
        granularity_ = builderForValue.build();
      } else {
        granularityBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Required. The time granularity of the time series (on the x-axis). Each time series
     * point starting at time T will aggregate all events for a particular slice
     * in *[T, T + granularity)* time windows.
     * Note: The aggregation is decided based on the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
     * This granularity defines the query-time aggregation windows and is not
     * necessarily related to any event time granularity in the raw data (though
     * we do recommend that the query-time granularity is not finer than the
     * ingestion-time one).
     * Currently, the minimal supported granularity is 10 seconds.
     * </pre>
     *
     * <code>.google.protobuf.Duration granularity = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public Builder mergeGranularity(com.google.protobuf.Duration value) {
      if (granularityBuilder_ == null) {
        if (((bitField0_ & 0x00000002) != 0) &&
          granularity_ != null &&
          granularity_ != com.google.protobuf.Duration.getDefaultInstance()) {
          getGranularityBuilder().mergeFrom(value);
        } else {
          granularity_ = value;
        }
      } else {
        granularityBuilder_.mergeFrom(value);
      }
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Required. The time granularity of the time series (on the x-axis). Each time series
     * point starting at time T will aggregate all events for a particular slice
     * in *[T, T + granularity)* time windows.
     * Note: The aggregation is decided based on the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
     * This granularity defines the query-time aggregation windows and is not
     * necessarily related to any event time granularity in the raw data (though
     * we do recommend that the query-time granularity is not finer than the
     * ingestion-time one).
     * Currently, the minimal supported granularity is 10 seconds.
     * </pre>
     *
     * <code>.google.protobuf.Duration granularity = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public Builder clearGranularity() {
      bitField0_ = (bitField0_ & ~0x00000002);
      granularity_ = null;
      if (granularityBuilder_ != null) {
        granularityBuilder_.dispose();
        granularityBuilder_ = null;
      }
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Required. The time granularity of the time series (on the x-axis). Each time series
     * point starting at time T will aggregate all events for a particular slice
     * in *[T, T + granularity)* time windows.
     * Note: The aggregation is decided based on the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
     * This granularity defines the query-time aggregation windows and is not
     * necessarily related to any event time granularity in the raw data (though
     * we do recommend that the query-time granularity is not finer than the
     * ingestion-time one).
     * Currently, the minimal supported granularity is 10 seconds.
     * </pre>
     *
     * <code>.google.protobuf.Duration granularity = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public com.google.protobuf.Duration.Builder getGranularityBuilder() {
      bitField0_ |= 0x00000002;
      onChanged();
      return getGranularityFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * Required. The time granularity of the time series (on the x-axis). Each time series
     * point starting at time T will aggregate all events for a particular slice
     * in *[T, T + granularity)* time windows.
     * Note: The aggregation is decided based on the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
     * This granularity defines the query-time aggregation windows and is not
     * necessarily related to any event time granularity in the raw data (though
     * we do recommend that the query-time granularity is not finer than the
     * ingestion-time one).
     * Currently, the minimal supported granularity is 10 seconds.
     * </pre>
     *
     * <code>.google.protobuf.Duration granularity = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public com.google.protobuf.DurationOrBuilder getGranularityOrBuilder() {
      if (granularityBuilder_ != null) {
        return granularityBuilder_.getMessageOrBuilder();
      } else {
        return granularity_ == null ?
            com.google.protobuf.Duration.getDefaultInstance() : granularity_;
      }
    }
    /**
     * <pre>
     * Required. The time granularity of the time series (on the x-axis). Each time series
     * point starting at time T will aggregate all events for a particular slice
     * in *[T, T + granularity)* time windows.
     * Note: The aggregation is decided based on the
     * [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] parameter.
     * This granularity defines the query-time aggregation windows and is not
     * necessarily related to any event time granularity in the raw data (though
     * we do recommend that the query-time granularity is not finer than the
     * ingestion-time one).
     * Currently, the minimal supported granularity is 10 seconds.
     * </pre>
     *
     * <code>.google.protobuf.Duration granularity = 2 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        com.google.protobuf.Duration, com.google.protobuf.Duration.Builder, com.google.protobuf.DurationOrBuilder> 
        getGranularityFieldBuilder() {
      if (granularityBuilder_ == null) {
        granularityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            com.google.protobuf.Duration, com.google.protobuf.Duration.Builder, com.google.protobuf.DurationOrBuilder>(
                getGranularity(),
                getParentForChildren(),
                isClean());
        granularity_ = null;
      }
      return granularityBuilder_;
    }

    private java.lang.Object metric_ = "";
    /**
     * <pre>
     * Optional. Denotes the [name][google.cloud.timeseriesinsights.v1.EventDimension.name] of a numerical
     * dimension that will have its values aggregated to compute the y-axis of the
     * time series.
     * The aggregation method must also be specified by setting the
     * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
     * field.
     * Note: Currently, if the aggregation method is unspecified, we will
     * default to SUM for backward compatibility reasons, but new implementations
     * should set the
     * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
     * explicitly.
     * If the metric is unspecified, we will use the number of events that each
     * time series point contains as the point value.
     * Example: Let's assume we have the following three events in our dataset:
     * ```json
     * {
     *   eventTime: "2020-12-27T00:00:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 100 }
     *     { name: "m2" longVal: 11 }
     *   ]
     * },
     * {
     *   eventTime: "2020-12-27T00:10:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 200 }
     *     { name: "m2" longVal: 22 }
     *   ]
     * },
     * {
     *   eventTime: "2020-12-27T00:20:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 300 }
     *     { name: "m2" longVal: 33 }
     *   ]
     * }
     * ```
     * These events are all within the same hour, spaced 10 minutes between each
     * of them. Assuming our [QueryDataSetRequest][google.cloud.timeseriesinsights.v1.QueryDataSetRequest] had set
     * [slicingParams.dimensionNames][google.cloud.timeseriesinsights.v1.SlicingParams.dimension_names] to ["d1",
     * "d2"] and [timeseries_params.granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity] to
     * "3600s", then all the previous events will be aggregated into the same
     * [timeseries point][google.cloud.timeseriesinsights.v1.TimeseriesPoint].
     * The time series point that they're all part of will have the
     * [time][google.cloud.timeseriesinsights.v1.TimeseriesPoint.time] set to "2020-12-27T00:00:00Z" and the
     * [value][google.cloud.timeseriesinsights.v1.TimeseriesPoint.value] populated based on this metric field:
     * - If the metric is set to "m1" and metric_aggregation_method to SUM, then
     * the value of the point will be 600.
     * - If the metric is set to "m2" and metric_aggregation_method to SUM, then
     * the value of the point will be 66.
     * - If the metric is set to "m1" and metric_aggregation_method to AVERAGE,
     * then the value of the point will be 200.
     * - If the metric is set to "m2" and metric_aggregation_method to AVERAGE,
     * then the value of the point will be 22.
     * - If the metric field is "" or unspecified, then the value of the point
     * will be 3, as we will simply count the events.
     * </pre>
     *
     * <code>optional string metric = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return Whether the metric field is set.
     */
    public boolean hasMetric() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * Optional. Denotes the [name][google.cloud.timeseriesinsights.v1.EventDimension.name] of a numerical
     * dimension that will have its values aggregated to compute the y-axis of the
     * time series.
     * The aggregation method must also be specified by setting the
     * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
     * field.
     * Note: Currently, if the aggregation method is unspecified, we will
     * default to SUM for backward compatibility reasons, but new implementations
     * should set the
     * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
     * explicitly.
     * If the metric is unspecified, we will use the number of events that each
     * time series point contains as the point value.
     * Example: Let's assume we have the following three events in our dataset:
     * ```json
     * {
     *   eventTime: "2020-12-27T00:00:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 100 }
     *     { name: "m2" longVal: 11 }
     *   ]
     * },
     * {
     *   eventTime: "2020-12-27T00:10:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 200 }
     *     { name: "m2" longVal: 22 }
     *   ]
     * },
     * {
     *   eventTime: "2020-12-27T00:20:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 300 }
     *     { name: "m2" longVal: 33 }
     *   ]
     * }
     * ```
     * These events are all within the same hour, spaced 10 minutes between each
     * of them. Assuming our [QueryDataSetRequest][google.cloud.timeseriesinsights.v1.QueryDataSetRequest] had set
     * [slicingParams.dimensionNames][google.cloud.timeseriesinsights.v1.SlicingParams.dimension_names] to ["d1",
     * "d2"] and [timeseries_params.granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity] to
     * "3600s", then all the previous events will be aggregated into the same
     * [timeseries point][google.cloud.timeseriesinsights.v1.TimeseriesPoint].
     * The time series point that they're all part of will have the
     * [time][google.cloud.timeseriesinsights.v1.TimeseriesPoint.time] set to "2020-12-27T00:00:00Z" and the
     * [value][google.cloud.timeseriesinsights.v1.TimeseriesPoint.value] populated based on this metric field:
     * - If the metric is set to "m1" and metric_aggregation_method to SUM, then
     * the value of the point will be 600.
     * - If the metric is set to "m2" and metric_aggregation_method to SUM, then
     * the value of the point will be 66.
     * - If the metric is set to "m1" and metric_aggregation_method to AVERAGE,
     * then the value of the point will be 200.
     * - If the metric is set to "m2" and metric_aggregation_method to AVERAGE,
     * then the value of the point will be 22.
     * - If the metric field is "" or unspecified, then the value of the point
     * will be 3, as we will simply count the events.
     * </pre>
     *
     * <code>optional string metric = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The metric.
     */
    public java.lang.String getMetric() {
      java.lang.Object ref = metric_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        metric_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <pre>
     * Optional. Denotes the [name][google.cloud.timeseriesinsights.v1.EventDimension.name] of a numerical
     * dimension that will have its values aggregated to compute the y-axis of the
     * time series.
     * The aggregation method must also be specified by setting the
     * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
     * field.
     * Note: Currently, if the aggregation method is unspecified, we will
     * default to SUM for backward compatibility reasons, but new implementations
     * should set the
     * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
     * explicitly.
     * If the metric is unspecified, we will use the number of events that each
     * time series point contains as the point value.
     * Example: Let's assume we have the following three events in our dataset:
     * ```json
     * {
     *   eventTime: "2020-12-27T00:00:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 100 }
     *     { name: "m2" longVal: 11 }
     *   ]
     * },
     * {
     *   eventTime: "2020-12-27T00:10:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 200 }
     *     { name: "m2" longVal: 22 }
     *   ]
     * },
     * {
     *   eventTime: "2020-12-27T00:20:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 300 }
     *     { name: "m2" longVal: 33 }
     *   ]
     * }
     * ```
     * These events are all within the same hour, spaced 10 minutes between each
     * of them. Assuming our [QueryDataSetRequest][google.cloud.timeseriesinsights.v1.QueryDataSetRequest] had set
     * [slicingParams.dimensionNames][google.cloud.timeseriesinsights.v1.SlicingParams.dimension_names] to ["d1",
     * "d2"] and [timeseries_params.granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity] to
     * "3600s", then all the previous events will be aggregated into the same
     * [timeseries point][google.cloud.timeseriesinsights.v1.TimeseriesPoint].
     * The time series point that they're all part of will have the
     * [time][google.cloud.timeseriesinsights.v1.TimeseriesPoint.time] set to "2020-12-27T00:00:00Z" and the
     * [value][google.cloud.timeseriesinsights.v1.TimeseriesPoint.value] populated based on this metric field:
     * - If the metric is set to "m1" and metric_aggregation_method to SUM, then
     * the value of the point will be 600.
     * - If the metric is set to "m2" and metric_aggregation_method to SUM, then
     * the value of the point will be 66.
     * - If the metric is set to "m1" and metric_aggregation_method to AVERAGE,
     * then the value of the point will be 200.
     * - If the metric is set to "m2" and metric_aggregation_method to AVERAGE,
     * then the value of the point will be 22.
     * - If the metric field is "" or unspecified, then the value of the point
     * will be 3, as we will simply count the events.
     * </pre>
     *
     * <code>optional string metric = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The bytes for metric.
     */
    public com.google.protobuf.ByteString
        getMetricBytes() {
      java.lang.Object ref = metric_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        metric_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * Optional. Denotes the [name][google.cloud.timeseriesinsights.v1.EventDimension.name] of a numerical
     * dimension that will have its values aggregated to compute the y-axis of the
     * time series.
     * The aggregation method must also be specified by setting the
     * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
     * field.
     * Note: Currently, if the aggregation method is unspecified, we will
     * default to SUM for backward compatibility reasons, but new implementations
     * should set the
     * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
     * explicitly.
     * If the metric is unspecified, we will use the number of events that each
     * time series point contains as the point value.
     * Example: Let's assume we have the following three events in our dataset:
     * ```json
     * {
     *   eventTime: "2020-12-27T00:00:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 100 }
     *     { name: "m2" longVal: 11 }
     *   ]
     * },
     * {
     *   eventTime: "2020-12-27T00:10:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 200 }
     *     { name: "m2" longVal: 22 }
     *   ]
     * },
     * {
     *   eventTime: "2020-12-27T00:20:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 300 }
     *     { name: "m2" longVal: 33 }
     *   ]
     * }
     * ```
     * These events are all within the same hour, spaced 10 minutes between each
     * of them. Assuming our [QueryDataSetRequest][google.cloud.timeseriesinsights.v1.QueryDataSetRequest] had set
     * [slicingParams.dimensionNames][google.cloud.timeseriesinsights.v1.SlicingParams.dimension_names] to ["d1",
     * "d2"] and [timeseries_params.granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity] to
     * "3600s", then all the previous events will be aggregated into the same
     * [timeseries point][google.cloud.timeseriesinsights.v1.TimeseriesPoint].
     * The time series point that they're all part of will have the
     * [time][google.cloud.timeseriesinsights.v1.TimeseriesPoint.time] set to "2020-12-27T00:00:00Z" and the
     * [value][google.cloud.timeseriesinsights.v1.TimeseriesPoint.value] populated based on this metric field:
     * - If the metric is set to "m1" and metric_aggregation_method to SUM, then
     * the value of the point will be 600.
     * - If the metric is set to "m2" and metric_aggregation_method to SUM, then
     * the value of the point will be 66.
     * - If the metric is set to "m1" and metric_aggregation_method to AVERAGE,
     * then the value of the point will be 200.
     * - If the metric is set to "m2" and metric_aggregation_method to AVERAGE,
     * then the value of the point will be 22.
     * - If the metric field is "" or unspecified, then the value of the point
     * will be 3, as we will simply count the events.
     * </pre>
     *
     * <code>optional string metric = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @param value The metric to set.
     * @return This builder for chaining.
     */
    public Builder setMetric(
        java.lang.String value) {
      if (value == null) { throw new NullPointerException(); }
      metric_ = value;
      bitField0_ |= 0x00000004;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optional. Denotes the [name][google.cloud.timeseriesinsights.v1.EventDimension.name] of a numerical
     * dimension that will have its values aggregated to compute the y-axis of the
     * time series.
     * The aggregation method must also be specified by setting the
     * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
     * field.
     * Note: Currently, if the aggregation method is unspecified, we will
     * default to SUM for backward compatibility reasons, but new implementations
     * should set the
     * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
     * explicitly.
     * If the metric is unspecified, we will use the number of events that each
     * time series point contains as the point value.
     * Example: Let's assume we have the following three events in our dataset:
     * ```json
     * {
     *   eventTime: "2020-12-27T00:00:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 100 }
     *     { name: "m2" longVal: 11 }
     *   ]
     * },
     * {
     *   eventTime: "2020-12-27T00:10:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 200 }
     *     { name: "m2" longVal: 22 }
     *   ]
     * },
     * {
     *   eventTime: "2020-12-27T00:20:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 300 }
     *     { name: "m2" longVal: 33 }
     *   ]
     * }
     * ```
     * These events are all within the same hour, spaced 10 minutes between each
     * of them. Assuming our [QueryDataSetRequest][google.cloud.timeseriesinsights.v1.QueryDataSetRequest] had set
     * [slicingParams.dimensionNames][google.cloud.timeseriesinsights.v1.SlicingParams.dimension_names] to ["d1",
     * "d2"] and [timeseries_params.granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity] to
     * "3600s", then all the previous events will be aggregated into the same
     * [timeseries point][google.cloud.timeseriesinsights.v1.TimeseriesPoint].
     * The time series point that they're all part of will have the
     * [time][google.cloud.timeseriesinsights.v1.TimeseriesPoint.time] set to "2020-12-27T00:00:00Z" and the
     * [value][google.cloud.timeseriesinsights.v1.TimeseriesPoint.value] populated based on this metric field:
     * - If the metric is set to "m1" and metric_aggregation_method to SUM, then
     * the value of the point will be 600.
     * - If the metric is set to "m2" and metric_aggregation_method to SUM, then
     * the value of the point will be 66.
     * - If the metric is set to "m1" and metric_aggregation_method to AVERAGE,
     * then the value of the point will be 200.
     * - If the metric is set to "m2" and metric_aggregation_method to AVERAGE,
     * then the value of the point will be 22.
     * - If the metric field is "" or unspecified, then the value of the point
     * will be 3, as we will simply count the events.
     * </pre>
     *
     * <code>optional string metric = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return This builder for chaining.
     */
    public Builder clearMetric() {
      metric_ = getDefaultInstance().getMetric();
      bitField0_ = (bitField0_ & ~0x00000004);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optional. Denotes the [name][google.cloud.timeseriesinsights.v1.EventDimension.name] of a numerical
     * dimension that will have its values aggregated to compute the y-axis of the
     * time series.
     * The aggregation method must also be specified by setting the
     * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
     * field.
     * Note: Currently, if the aggregation method is unspecified, we will
     * default to SUM for backward compatibility reasons, but new implementations
     * should set the
     * [metricAggregationMethod][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric_aggregation_method]
     * explicitly.
     * If the metric is unspecified, we will use the number of events that each
     * time series point contains as the point value.
     * Example: Let's assume we have the following three events in our dataset:
     * ```json
     * {
     *   eventTime: "2020-12-27T00:00:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 100 }
     *     { name: "m2" longVal: 11 }
     *   ]
     * },
     * {
     *   eventTime: "2020-12-27T00:10:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 200 }
     *     { name: "m2" longVal: 22 }
     *   ]
     * },
     * {
     *   eventTime: "2020-12-27T00:20:00Z",
     *   dimensions: [
     *     { name: "d1" stringVal: "v1" },
     *     { name: "d2" stringVal: "v2" }
     *     { name: "m1" longVal: 300 }
     *     { name: "m2" longVal: 33 }
     *   ]
     * }
     * ```
     * These events are all within the same hour, spaced 10 minutes between each
     * of them. Assuming our [QueryDataSetRequest][google.cloud.timeseriesinsights.v1.QueryDataSetRequest] had set
     * [slicingParams.dimensionNames][google.cloud.timeseriesinsights.v1.SlicingParams.dimension_names] to ["d1",
     * "d2"] and [timeseries_params.granularity][google.cloud.timeseriesinsights.v1.TimeseriesParams.granularity] to
     * "3600s", then all the previous events will be aggregated into the same
     * [timeseries point][google.cloud.timeseriesinsights.v1.TimeseriesPoint].
     * The time series point that they're all part of will have the
     * [time][google.cloud.timeseriesinsights.v1.TimeseriesPoint.time] set to "2020-12-27T00:00:00Z" and the
     * [value][google.cloud.timeseriesinsights.v1.TimeseriesPoint.value] populated based on this metric field:
     * - If the metric is set to "m1" and metric_aggregation_method to SUM, then
     * the value of the point will be 600.
     * - If the metric is set to "m2" and metric_aggregation_method to SUM, then
     * the value of the point will be 66.
     * - If the metric is set to "m1" and metric_aggregation_method to AVERAGE,
     * then the value of the point will be 200.
     * - If the metric is set to "m2" and metric_aggregation_method to AVERAGE,
     * then the value of the point will be 22.
     * - If the metric field is "" or unspecified, then the value of the point
     * will be 3, as we will simply count the events.
     * </pre>
     *
     * <code>optional string metric = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @param value The bytes for metric to set.
     * @return This builder for chaining.
     */
    public Builder setMetricBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) { throw new NullPointerException(); }
      checkByteStringIsUtf8(value);
      metric_ = value;
      bitField0_ |= 0x00000004;
      onChanged();
      return this;
    }

    private int metricAggregationMethod_ = 0;
    /**
     * <pre>
     * Optional. Together with the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] field, specifies how
     * we will aggregate multiple events to obtain the value of a time series
     * point. See the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] documentation for more
     * details.
     * If the metric is not specified or "", then this field will be ignored.
     * </pre>
     *
     * <code>.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod metric_aggregation_method = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The enum numeric value on the wire for metricAggregationMethod.
     */
    @java.lang.Override public int getMetricAggregationMethodValue() {
      return metricAggregationMethod_;
    }
    /**
     * <pre>
     * Optional. Together with the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] field, specifies how
     * we will aggregate multiple events to obtain the value of a time series
     * point. See the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] documentation for more
     * details.
     * If the metric is not specified or "", then this field will be ignored.
     * </pre>
     *
     * <code>.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod metric_aggregation_method = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @param value The enum numeric value on the wire for metricAggregationMethod to set.
     * @return This builder for chaining.
     */
    public Builder setMetricAggregationMethodValue(int value) {
      metricAggregationMethod_ = value;
      bitField0_ |= 0x00000008;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optional. Together with the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] field, specifies how
     * we will aggregate multiple events to obtain the value of a time series
     * point. See the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] documentation for more
     * details.
     * If the metric is not specified or "", then this field will be ignored.
     * </pre>
     *
     * <code>.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod metric_aggregation_method = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return The metricAggregationMethod.
     */
    @java.lang.Override
    public com.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod getMetricAggregationMethod() {
      com.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod result = com.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod.forNumber(metricAggregationMethod_);
      return result == null ? com.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Optional. Together with the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] field, specifies how
     * we will aggregate multiple events to obtain the value of a time series
     * point. See the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] documentation for more
     * details.
     * If the metric is not specified or "", then this field will be ignored.
     * </pre>
     *
     * <code>.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod metric_aggregation_method = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @param value The metricAggregationMethod to set.
     * @return This builder for chaining.
     */
    public Builder setMetricAggregationMethod(com.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod value) {
      if (value == null) {
        throw new NullPointerException();
      }
      bitField0_ |= 0x00000008;
      metricAggregationMethod_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optional. Together with the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] field, specifies how
     * we will aggregate multiple events to obtain the value of a time series
     * point. See the [metric][google.cloud.timeseriesinsights.v1.TimeseriesParams.metric] documentation for more
     * details.
     * If the metric is not specified or "", then this field will be ignored.
     * </pre>
     *
     * <code>.google.cloud.timeseriesinsights.v1.TimeseriesParams.AggregationMethod metric_aggregation_method = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     * @return This builder for chaining.
     */
    public Builder clearMetricAggregationMethod() {
      bitField0_ = (bitField0_ & ~0x00000008);
      metricAggregationMethod_ = 0;
      onChanged();
      return this;
    }
    @java.lang.Override
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFields(unknownFields);
    }

    @java.lang.Override
    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }


    // @@protoc_insertion_point(builder_scope:google.cloud.timeseriesinsights.v1.TimeseriesParams)
  }

  // @@protoc_insertion_point(class_scope:google.cloud.timeseriesinsights.v1.TimeseriesParams)
  private static final com.google.cloud.timeseriesinsights.v1.TimeseriesParams DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new com.google.cloud.timeseriesinsights.v1.TimeseriesParams();
  }

  public static com.google.cloud.timeseriesinsights.v1.TimeseriesParams getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<TimeseriesParams>
      PARSER = new com.google.protobuf.AbstractParser<TimeseriesParams>() {
    @java.lang.Override
    public TimeseriesParams parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      Builder builder = newBuilder();
      try {
        builder.mergeFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(builder.buildPartial());
      } catch (com.google.protobuf.UninitializedMessageException e) {
        throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(e)
            .setUnfinishedMessage(builder.buildPartial());
      }
      return builder.buildPartial();
    }
  };

  public static com.google.protobuf.Parser<TimeseriesParams> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<TimeseriesParams> getParserForType() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.cloud.timeseriesinsights.v1.TimeseriesParams getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

