# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: google/cloud/aiplatform/v1beta1/schema/trainingjob/definition/automl_video_action_recognition.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import builder as _builder
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\ncgoogle/cloud/aiplatform/v1beta1/schema/trainingjob/definition/automl_video_action_recognition.proto\x12=google.cloud.aiplatform.v1beta1.schema.trainingjob.definition\x1a\x1cgoogle/api/annotations.proto\"\x91\x01\n\x1c\x41utoMlVideoActionRecognition\x12q\n\x06inputs\x18\x01 \x01(\x0b\x32\x61.google.cloud.aiplatform.v1beta1.schema.trainingjob.definition.AutoMlVideoActionRecognitionInputs\"\xaf\x02\n\"AutoMlVideoActionRecognitionInputs\x12\x7f\n\nmodel_type\x18\x01 \x01(\x0e\x32k.google.cloud.aiplatform.v1beta1.schema.trainingjob.definition.AutoMlVideoActionRecognitionInputs.ModelType\"\x87\x01\n\tModelType\x12\x1a\n\x16MODEL_TYPE_UNSPECIFIED\x10\x00\x12\t\n\x05\x43LOUD\x10\x01\x12\x16\n\x12MOBILE_VERSATILE_1\x10\x02\x12\x1d\n\x19MOBILE_JETSON_VERSATILE_1\x10\x03\x12\x1c\n\x18MOBILE_CORAL_VERSATILE_1\x10\x04\x42\x97\x03\nAcom.google.cloud.aiplatform.v1beta1.schema.trainingjob.definitionB!AutoMLVideoActionRecognitionProtoP\x01Zggoogle.golang.org/genproto/googleapis/cloud/aiplatform/v1beta1/schema/trainingjob/definition;definition\xaa\x02=Google.Cloud.AIPlatform.V1Beta1.Schema.TrainingJob.Definition\xca\x02=Google\\Cloud\\AIPlatform\\V1beta1\\Schema\\TrainingJob\\Definition\xea\x02\x43Google::Cloud::AIPlatform::V1beta1::Schema::TrainingJob::Definitionb\x06proto3')

_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'google.cloud.aiplatform.v1beta1.schema.trainingjob.definition.automl_video_action_recognition_pb2', globals())
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'\nAcom.google.cloud.aiplatform.v1beta1.schema.trainingjob.definitionB!AutoMLVideoActionRecognitionProtoP\001Zggoogle.golang.org/genproto/googleapis/cloud/aiplatform/v1beta1/schema/trainingjob/definition;definition\252\002=Google.Cloud.AIPlatform.V1Beta1.Schema.TrainingJob.Definition\312\002=Google\\Cloud\\AIPlatform\\V1beta1\\Schema\\TrainingJob\\Definition\352\002CGoogle::Cloud::AIPlatform::V1beta1::Schema::TrainingJob::Definition'
  _AUTOMLVIDEOACTIONRECOGNITION._serialized_start=197
  _AUTOMLVIDEOACTIONRECOGNITION._serialized_end=342
  _AUTOMLVIDEOACTIONRECOGNITIONINPUTS._serialized_start=345
  _AUTOMLVIDEOACTIONRECOGNITIONINPUTS._serialized_end=648
  _AUTOMLVIDEOACTIONRECOGNITIONINPUTS_MODELTYPE._serialized_start=513
  _AUTOMLVIDEOACTIONRECOGNITIONINPUTS_MODELTYPE._serialized_end=648
# @@protoc_insertion_point(module_scope)
